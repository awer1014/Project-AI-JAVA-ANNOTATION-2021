{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYUKhZvccQ_H"
   },
   "source": [
    "# 新增區段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c2810c1"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niZVQMJnP565",
    "outputId": "60ff0661-fc50-4a03-8c15-3472c567bf15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6916674"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Final_Edition_include_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-JMBpEFcJWh"
   },
   "source": [
    "## 安裝程式及更新版本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7GxzpELTBDJ",
    "outputId": "3e893a04-7f3b-4526-82f6-021a6bb1be54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-pos-embd\n",
      "  Downloading keras-pos-embd-0.12.0.tar.gz (6.0 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-pos-embd) (1.19.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-pos-embd) (2.4.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-pos-embd) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-pos-embd) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-pos-embd) (3.13)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-pos-embd) (1.5.2)\n",
      "Building wheels for collected packages: keras-pos-embd\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.12.0-py3-none-any.whl size=7470 sha256=717bd2dd57e89deb2df364ae303b383a7b4b1f7a708cd28f797fc27754802103\n",
      "  Stored in directory: /root/.cache/pip/wheels/77/99/fd/dd98f4876c3ebbef7aab0dbfbd37bca41d7db37d3a28b2cb09\n",
      "Successfully built keras-pos-embd\n",
      "Installing collected packages: keras-pos-embd\n",
      "Successfully installed keras-pos-embd-0.12.0\n",
      "Collecting keras-multi-head\n",
      "  Downloading keras-multi-head-0.28.0.tar.gz (14 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-multi-head) (1.19.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-multi-head) (2.4.3)\n",
      "Collecting keras-self-attention>=0.50.0\n",
      "  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-multi-head) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-multi-head) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-multi-head) (3.1.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-multi-head) (1.5.2)\n",
      "Building wheels for collected packages: keras-multi-head, keras-self-attention\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.28.0-py3-none-any.whl size=15560 sha256=4b9e518ad63725a4d3f70895e8abcbbcfa9b2488e5f33e960ca1576bafb758b3\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/4a/ea/9503ab5a02201dfb8635ba2cc8f30844661623c684a5b44472\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19415 sha256=31abe5ad44a591d0341655ea41ba267ce07e37d42f510ce469b0e3134ead6d75\n",
      "  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n",
      "Successfully built keras-multi-head keras-self-attention\n",
      "Installing collected packages: keras-self-attention, keras-multi-head\n",
      "Successfully installed keras-multi-head-0.28.0 keras-self-attention-0.50.0\n",
      "Collecting keras-layer-normalization\n",
      "  Downloading keras-layer-normalization-0.15.0.tar.gz (4.2 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-layer-normalization) (1.19.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-layer-normalization) (2.4.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-layer-normalization) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-layer-normalization) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-layer-normalization) (1.4.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-layer-normalization) (1.5.2)\n",
      "Building wheels for collected packages: keras-layer-normalization\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.15.0-py3-none-any.whl size=5224 sha256=e9593485836edb27375d7b01794c42ab0f429c40e8ad260614ad5b3957f6025c\n",
      "  Stored in directory: /root/.cache/pip/wheels/4d/be/fe/55422f77ac11fe6ddcb471198038de8a26b5a4dd1557883c1e\n",
      "Successfully built keras-layer-normalization\n",
      "Installing collected packages: keras-layer-normalization\n",
      "Successfully installed keras-layer-normalization-0.15.0\n",
      "Collecting keras-embed-sim\n",
      "  Downloading keras-embed-sim-0.9.0.tar.gz (4.1 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-embed-sim) (1.19.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-embed-sim) (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-embed-sim) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-embed-sim) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-embed-sim) (3.1.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-embed-sim) (1.5.2)\n",
      "Building wheels for collected packages: keras-embed-sim\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.9.0-py3-none-any.whl size=4506 sha256=dcc13b5bb528eb08a84f4426397f55196443c964b623b0b11a4988026c29c9bc\n",
      "  Stored in directory: /root/.cache/pip/wheels/a8/1e/d2/9bc15513dd2f8b9de3e628b3aa9d2de49e721deef6bbd1497e\n",
      "Successfully built keras-embed-sim\n",
      "Installing collected packages: keras-embed-sim\n",
      "Successfully installed keras-embed-sim-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-pos-embd\n",
    "!pip install keras-multi-head\n",
    "!pip install keras-layer-normalization\n",
    "!pip install keras-embed-sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aoCWFJjEgBpW",
    "outputId": "056e1d23-59a1-4039-aed0-6169637be822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.5.0rc0\n",
      "  Downloading tensorflow-2.5.0rc0-cp37-cp37m-manylinux2010_x86_64.whl (454.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 454.2 MB 17 kB/s \n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 41.5 MB/s \n",
      "\u001b[?25hCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 39.8 MB/s \n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.9 MB/s \n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8 MB 167 kB/s \n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tf-estimator-nightly==2.5.0.dev2021032501\n",
      "  Downloading tf_estimator_nightly-2.5.0.dev2021032501-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 55.6 MB/s \n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
      "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 45.4 MB/s \n",
      "\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 57.4 MB/s \n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 69.5 MB/s \n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 41.3 MB/s \n",
      "\u001b[?25hCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 6.4 MB/s \n",
      "\u001b[?25hCollecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 50.8 MB/s \n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 38.1 MB/s \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 54.9 MB/s \n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.34.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 72.2 MB/s \n",
      "\u001b[?25hCollecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 7.7 MB/s \n",
      "\u001b[?25hCollecting setuptools>=41.0.0\n",
      "  Downloading setuptools-57.4.0-py3-none-any.whl (819 kB)\n",
      "\u001b[K     |████████████████████████████████| 819 kB 56.0 MB/s \n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 68.4 MB/s \n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.6.1-py3-none-any.whl (17 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 6.7 MB/s \n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 7.7 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 65.3 MB/s \n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 62.2 MB/s \n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.3-py3-none-any.whl (35 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 71.7 MB/s \n",
      "\u001b[?25hCollecting zipp>=0.5\n",
      "  Downloading zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=7debbf092ac4e97358a42fbc53e1620fac01fe003ea62d016ee014824b82eced\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68717 sha256=f767684f3983f22fdd42d665c42d09dca48ec6619b59730f75745a433aa7a909\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, zipp, typing-extensions, six, setuptools, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, cached-property, absl-py, wrapt, tf-estimator-nightly, termcolor, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.4.8\n",
      "    Uninstalling pyasn1-0.4.8:\n",
      "      Successfully uninstalled pyasn1-0.4.8\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n",
      "      Successfully uninstalled idna-2.10\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.2\n",
      "    Uninstalling charset-normalizer-2.0.2:\n",
      "      Successfully uninstalled charset-normalizer-2.0.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.5.30\n",
      "    Uninstalling certifi-2021.5.30:\n",
      "      Successfully uninstalled certifi-2021.5.30\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.5.0\n",
      "    Uninstalling zipp-3.5.0:\n",
      "      Successfully uninstalled zipp-3.5.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 57.2.0\n",
      "    Uninstalling setuptools-57.2.0:\n",
      "      Successfully uninstalled setuptools-57.2.0\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.7.2\n",
      "    Uninstalling rsa-4.7.2:\n",
      "      Successfully uninstalled rsa-4.7.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: pyasn1-modules\n",
      "    Found existing installation: pyasn1-modules 0.2.8\n",
      "    Uninstalling pyasn1-modules-0.2.8:\n",
      "      Successfully uninstalled pyasn1-modules-0.2.8\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.1.1\n",
      "    Uninstalling oauthlib-3.1.1:\n",
      "      Successfully uninstalled oauthlib-3.1.1\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 4.2.2\n",
      "    Uninstalling cachetools-4.2.2:\n",
      "      Successfully uninstalled cachetools-4.2.2\n",
      "  Attempting uninstall: requests-oauthlib\n",
      "    Found existing installation: requests-oauthlib 1.3.0\n",
      "    Uninstalling requests-oauthlib-1.3.0:\n",
      "      Successfully uninstalled requests-oauthlib-1.3.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.6.1\n",
      "    Uninstalling importlib-metadata-4.6.1:\n",
      "      Successfully uninstalled importlib-metadata-4.6.1\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.32.1\n",
      "    Uninstalling google-auth-1.32.1:\n",
      "      Successfully uninstalled google-auth-1.32.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.36.2\n",
      "    Uninstalling wheel-0.36.2:\n",
      "      Successfully uninstalled wheel-0.36.2\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: tensorboard-plugin-wit\n",
      "    Found existing installation: tensorboard-plugin-wit 1.8.0\n",
      "    Uninstalling tensorboard-plugin-wit-1.8.0:\n",
      "      Successfully uninstalled tensorboard-plugin-wit-1.8.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.17.3\n",
      "    Uninstalling protobuf-3.17.3:\n",
      "      Successfully uninstalled protobuf-3.17.3\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.3.4\n",
      "    Uninstalling Markdown-3.3.4:\n",
      "      Successfully uninstalled Markdown-3.3.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.34.1\n",
      "    Uninstalling grpcio-1.34.1:\n",
      "      Successfully uninstalled grpcio-1.34.1\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.4\n",
      "    Uninstalling google-auth-oauthlib-0.4.4:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.4\n",
      "  Attempting uninstall: cached-property\n",
      "    Found existing installation: cached-property 1.5.2\n",
      "    Uninstalling cached-property-1.5.2:\n",
      "      Successfully uninstalled cached-property-1.5.2\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: keras-nightly\n",
      "    Found existing installation: keras-nightly 2.5.0.dev2021032900\n",
      "    Uninstalling keras-nightly-2.5.0.dev2021032900:\n",
      "      Successfully uninstalled keras-nightly-2.5.0.dev2021032900\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: astunparse\n",
      "    Found existing installation: astunparse 1.6.3\n",
      "    Uninstalling astunparse-1.6.3:\n",
      "      Successfully uninstalled astunparse-1.6.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-metadata 1.1.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.13.0 which is incompatible.\n",
      "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
      "flask 1.1.4 requires Werkzeug<2.0,>=0.15, but you have werkzeug 2.0.1 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.2 certifi-2021.5.30 charset-normalizer-2.0.3 flatbuffers-1.12 gast-0.4.0 google-auth-1.34.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 idna-3.2 importlib-metadata-4.6.1 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 setuptools-57.4.0 six-1.15.0 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0rc0 termcolor-1.1.0 tf-estimator-nightly-2.5.0.dev2021032501 typing-extensions-3.7.4.3 urllib3-1.26.6 werkzeug-2.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.5.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "google",
         "numpy",
         "pkg_resources",
         "six"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.5.0rc0\n",
      "  Downloading tensorflow_gpu-2.5.0rc0-cp37-cp37m-manylinux2010_x86_64.whl (454.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 454.2 MB 17 kB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (3.17.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (0.36.2)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (1.34.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (3.3.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (1.19.5)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (2.5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (1.12.1)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.5.0.dev2021032501 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (2.5.0.dev2021032501)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (1.15.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (3.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (0.13.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.5.0rc0) (0.4.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-gpu==2.5.0rc0) (1.5.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (57.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (1.34.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (4.6.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (2.0.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.5.0rc0) (3.5.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.5.0rc0\n",
      "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.4.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.3) (1.5.2)\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "!pip install tensorflow==2.5.0rc0 --upgrade --force-reinstall\n",
    "!pip install tensorflow-gpu==2.5.0rc0\n",
    "#!pip install tensorflow\n",
    "!pip install keras==2.4.3\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4STfS4EQpUAP",
    "outputId": "32c45ee6-71d4-4d5e-ce6e-491b21c882f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.5.0rc0\n",
      "  Downloading keras-2.5.0rc0-py2.py3-none-any.whl (1.2 MB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10 kB 7.7 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 20 kB 12.2 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30 kB 12.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 40 kB 12.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 51 kB 14.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 61 kB 16.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 71 kB 15.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 81 kB 16.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 92 kB 17.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 102 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 112 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 122 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 133 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 143 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 153 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 163 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 174 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 184 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 194 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 204 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 215 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 225 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 235 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 245 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 256 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 266 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 276 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 286 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 296 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 307 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 317 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 327 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 337 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 348 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 358 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 368 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 378 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 389 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 399 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 409 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 419 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 430 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 440 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 450 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 460 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 471 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 481 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 491 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 501 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 512 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 522 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 532 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 542 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 552 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 563 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 573 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 583 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 593 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 604 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 614 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 624 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 634 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 645 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 655 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 665 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 675 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 686 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 696 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 706 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 716 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 727 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 737 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 747 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 757 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 768 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 778 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 788 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 798 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 808 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 819 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 829 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 839 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 849 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 860 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 870 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 880 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 890 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 901 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 911 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 921 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 931 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 942 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 952 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 962 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 972 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 983 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 993 kB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.0 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.0 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 1.0 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.0 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.0 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 1.1 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.2 MB 18.9 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.2 MB 18.9 MB/s \n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "Successfully installed keras-2.5.0rc0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "keras"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "#keep doing that\n",
    "!pip install keras==2.5.0rc0\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "#stop at here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_yvWYZqo83Q",
    "outputId": "145e5f95-7c7b-4408-bd5a-861a94b5ee00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.4.3\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.4.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.3) (1.5.2)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.5.0rc0\n",
      "    Uninstalling keras-2.5.0rc0:\n",
      "      Successfully uninstalled keras-2.5.0rc0\n",
      "Successfully installed keras-2.4.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "keras"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "#reset and run this\n",
    "#!pip install keras --user --upgrade --force-reinstall\n",
    "!pip install keras==2.4.3\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYuf0XA5ranZ",
    "outputId": "f3529b96-379f-4468-e423-26ca078aa2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ql8xsG7HcVNP"
   },
   "source": [
    "## 執行程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d94ffe56",
    "outputId": "1249cd6b-bff9-44bc-f32e-212835586c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import unittest\n",
    "import numpy as np\n",
    "from keras_performer import performer as tfr\n",
    "import nltk\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "9b54d338",
    "outputId": "805aecc7-247e-4761-a0f1-f2ac4bb1e054"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ndef solve_cudnn_error():\\n    import tensorflow as tf\\n    gpus = tf.config.experimental.list_physical_devices(\\'GPU\\')\\n    if gpus:\\n        try:\\n            # Currently, memory growth needs to be the same across GPUs\\n            for gpu in gpus:\\n                tf.config.experimental.set_memory_growth(gpu, True)\\n            logical_gpus = tf.config.experimental.list_logical_devices(\\'GPU\\')\\n            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\\n        except RuntimeError as e:\\n            # Memory growth must be set before GPUs have been initialized\\n            print(e)\\n            \\nsolve_cudnn_error()\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def solve_cudnn_error():\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "            \n",
    "solve_cudnn_error()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22361e8f"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def readCSV(file_name):\n",
    "  errlist=[]\n",
    "  LBlist=[]\n",
    "  with open(file_name, newline='') as csvfile:\n",
    "\n",
    "  # 讀取 CSV 檔內容，將每一列轉成一個 dictionary\n",
    "\n",
    "    rows = csv.DictReader(csvfile)\n",
    "    for row in rows: \n",
    "      RL=list(row.values())\n",
    "\n",
    "      RL = list(map(int, RL))\n",
    "      errs=RL[1:37]\n",
    "      LB=RL[37:]\n",
    "      errlist.append(errs)\n",
    "      LBlist.append(LB)\n",
    "  return errlist,LBlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b92cf71a"
   },
   "outputs": [],
   "source": [
    "def find_first_sublist(seq, sublist, start=0):\n",
    "    length = len(sublist)\n",
    "    for index in range(start, len(seq)):\n",
    "        if seq[index:index+length] == sublist:\n",
    "            return index, index+length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1b88909b"
   },
   "outputs": [],
   "source": [
    "def replace_sublist(seq, sublist, replacement):\n",
    "    length = len(replacement)\n",
    "    index = 0\n",
    "    for start, end in iter(lambda: find_first_sublist(seq, sublist, index), None):\n",
    "        seq[start:end] = replacement\n",
    "        index = start + length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abb41dde"
   },
   "outputs": [],
   "source": [
    "def replaceTAGS(x):\n",
    "    replace_sublist(x, ['<', 'BOC', '>'], [\"<BOC>\"])\n",
    "    replace_sublist(x, ['<', 'EOC', '>'], [\"<EOC>\"])\n",
    "    replace_sublist(x, ['<', 'BOTM', '>'], [\"<BOTM>\"])\n",
    "    replace_sublist(x, ['<', 'BOT', '>'], [\"<BOT>\"])\n",
    "    replace_sublist(x, ['<', 'EOT', '>'], [\"<EOT>\"])\n",
    "    replace_sublist(x, ['<', 'BOM', '>'], [\"<BOM>\"])\n",
    "    replace_sublist(x, ['<', 'EOM', '>'], [\"<EOM>\"])\n",
    "    replace_sublist(x, ['<', 'EOTM', '>'], [\"<EOTM>\"])\n",
    "    replace_sublist(x, ['<', 'CR', '>'], [\"<CR>\"])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0db5e0b1"
   },
   "outputs": [],
   "source": [
    "def parseSentence(x):\t\n",
    "\ttokenizer = RegexpTokenizer(r\"[\\w']+|[].,:!?;=+-\\\\*/@#$%^&_(){}~|\\\"[]\")\n",
    "\ttokens=[]\n",
    "\tstate=\"START\"\n",
    "\tchrs=\"\"\n",
    "\tfor i in range(len(x)):\n",
    "\t\t#print(ord(x[i]))\n",
    "\t\tif (ord(x[i])>255):\n",
    "\t\t\tinp=\"U\"\n",
    "\t\telse:\n",
    "\t\t\tinp=\"E\"\n",
    "\t\n",
    "\t\tif state==\"START\":\n",
    "\t\t\tif inp==\"E\":\n",
    "\t\t\t\tstate=\"ASCII\"\n",
    "\t\t\t\tchrs=x[i]\n",
    "\t\t\telse:\n",
    "\t\t\t\tstate=\"UNICODE\"\n",
    "\t\t\t\ttokens.append(x[i])\n",
    "\t\t\t\n",
    "\t\telif state==\"ASCII\":\n",
    "\t\t\tif inp==\"E\":\n",
    "\t\t\t\tchrs += x[i]\n",
    "\t\t\telse:#U\n",
    "\t\t\t\tstate=\"UNICODE\"\n",
    "\t\t\t\ttokens += tokenizer.tokenize(chrs) #wordpunct_tokenize(chrs)  #nltk.word_tokenize(chrs)\n",
    "\t\t\t\tchrs=\"\"\n",
    "\t\t\t\ttokens.append(x[i])\n",
    "\t\n",
    "\t\telif state==\"UNICODE\":\n",
    "\t\t\tif inp==\"E\":\n",
    "\t\t\t\tstate=\"ASCII\"\n",
    "\t\t\t\tchrs=x[i]\n",
    "\t\t\telse:\n",
    "\t\t\t\tstate=\"UNICODE\"\n",
    "\t\t\t\ttokens.append(x[i])\n",
    "\tif len(chrs)>0:\n",
    "\t\ttokens += tokenizer.tokenize(chrs) #wordpunct_tokenize(chrs)  # nltk.word_tokenize(chrs) \n",
    "\treturn tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e88de533"
   },
   "outputs": [],
   "source": [
    "def readcode(fname):\n",
    "    with open(fname,encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1JYt9ELGe5Z"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plotTrainingLoss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ec120d95"
   },
   "outputs": [],
   "source": [
    "class TestTranslate(unittest.TestCase):\n",
    " \n",
    "    @staticmethod\n",
    "    def _build_token_dict(token_list):\n",
    "        token_dict = {\n",
    "            '<PAD>': 0,\n",
    "            '<START>': 1,\n",
    "            '<END>': 2,\n",
    "            '<BOC>': 3,\n",
    "            '<EOC>': 4,\n",
    "            '<BOTM>': 5,\n",
    "            '<BOT>': 6,\n",
    "            '<EOT>': 7,\n",
    "            '<BOM>': 8,\n",
    "            '<EOM>': 9,\n",
    "            '<EOTM>': 10,\n",
    "            '<CR>': 11,\n",
    "        }\n",
    "        for tokens in token_list:\n",
    "            for token in tokens:\n",
    "                if token not in token_dict:\n",
    "                    token_dict[token] = len(token_dict)\n",
    "        return token_dict\n",
    " \n",
    "    def test_translate(self):\n",
    "        print(\"i am here: \" )\n",
    "        max_javaline_length=150  #Max number of lines \n",
    "        source_tokens = []\n",
    "        target_errors=[]\n",
    "        target_LB=[]\n",
    "        #source_file=[]\n",
    "        \n",
    "        Input_Path = \"/content/drive/MyDrive/AI_JAVA_ANNOTATION_PROJ_2021/論文+程式/乙班_Performer/Final Edition include model /Trianing/InputTxt\"\n",
    "        Location_Output_Path = \"/content/drive/MyDrive/AI_JAVA_ANNOTATION_PROJ_2021/論文+程式/乙班_Performer/Final Edition include model /Trianing/InputCSV\"\n",
    "        '''\n",
    "        Input_Path = \"Performer/Perfomer_local/Trianing/InputTxt\"\n",
    "        Location_Output_Path = \"Performer/Perfomer_local/Trianing/InputCSV\"\n",
    "        '''\n",
    " \n",
    "        InputFiles = sorted(listdir(Input_Path))\n",
    "        OutputFiles = sorted(listdir(Location_Output_Path))\n",
    "        #max_files =10\n",
    "        for f in InputFiles:\n",
    "          fullpath = join(Input_Path, f)\n",
    "          #source_file=fullpath\n",
    "          if isfile(fullpath):\n",
    "            source_tokens.append(parseSentence(readcode(fullpath)))\n",
    "            #if len(source_tokens)>max_files: break\n",
    "        for f in OutputFiles:\n",
    "          fullpath = join(Location_Output_Path, f)\n",
    "          #source_file=fullpath\n",
    "          if isfile(fullpath):\n",
    "            err,lb = readCSV(fullpath)\n",
    "            target_errors.append(err)\n",
    "            target_LB.append(lb)\n",
    "            #if len(source_tokens)>max_files: break\n",
    "        dd=np.asarray(target_errors)\n",
    "        print(\"AAAA: \", dd.shape)\n",
    "        print(\"aaaa: \" , type(target_errors[0][0]))\n",
    "        target_errors=target_errors[0]  \n",
    "        target_LB=target_LB[0]     \n",
    "        print(\"XXXX: \" , len(source_tokens))\n",
    "        print(\"YYYY: \" , type(target_errors[0][0]))\n",
    "        print(\"ZZZZ: \" , len(target_LB))\n",
    "        print(\"ZZZZ len(target_LB[0]): \" , len(target_LB[0]))\n",
    "\n",
    " \n",
    "        source_tokens2 = []\n",
    "        target_errors2= []\n",
    "        target_LB2=[]\n",
    "\n",
    "        THRESHOLD_FILE_LEN = 64000000\n",
    " \n",
    "        for i in range(len(source_tokens)): \n",
    "          #print (i)\n",
    "          src = source_tokens[i]\n",
    "          err = target_errors[i]   \n",
    "          lb = target_LB[i]                   \n",
    "          if (len(src)<=THRESHOLD_FILE_LEN):\n",
    "            source_tokens2.append(src)\n",
    "            target_errors2.append(err)\n",
    "            target_LB2.append(lb) \n",
    "        source_tokens = source_tokens2\n",
    "        target_errors= target_errors2        \n",
    "        target_LB= target_LB2        \n",
    "\n",
    "        print(\"XXXX2: \" , len(source_tokens))\n",
    "                    \n",
    " \n",
    "        # Generate dictionaries\n",
    "        source_token_dict = self._build_token_dict(source_tokens)\n",
    "        \n",
    " \n",
    "        # Add special tokens\n",
    "        encode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
    "        \n",
    "        #output_tokens = [tokens + ['<END>', '<PAD>'] for tokens in target_tokens]\n",
    " \n",
    "        # Padding\n",
    "        self.sl = max(map(len, encode_tokens))\n",
    "        \n",
    "        source_max_len = self.sl\n",
    "        \n",
    " \n",
    "        encode_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encode_tokens]\n",
    "        \n",
    "        \n",
    " \n",
    "        encode_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encode_tokens]\n",
    "       \n",
    "        \n",
    "        #print(\"encode_input:\", encode_input)\n",
    "        \n",
    "        #print(\"len(source_token_dict):\", len(source_token_dict))\n",
    "        \n",
    "        \n",
    "        #decode_output_one_hot_encoded = to_categorical(decode_output)\n",
    "        #print(\"one-hot-decode_output:\", decode_output_one_hot_encoded)\n",
    "        #decode_output =  list(decode_output_one_hot_encoded)\n",
    "        token_num =len(source_token_dict)\n",
    "        print(type(token_num))\n",
    "        #Build & fit model\n",
    "        #Set model para    \n",
    "        model = tfr.get_model(\n",
    "            max_input_len= (source_max_len),\n",
    "            max_javaline_length=max_javaline_length,\n",
    "            errNum=36,\n",
    "            lbNum=len(target_LB[0]),\n",
    "            token_num=len(source_token_dict),\n",
    "            embed_dim=32, #32,\n",
    "            encoder_num=4, #2 max = 6\n",
    "            head_num=4,#4\n",
    "            hidden_dim=64, #128\n",
    "            dropout_rate=0.05 #0.05\n",
    "        )\n",
    "        #'LNout0'\n",
    "        \n",
    "        losses = {    \n",
    "            \"error_feed_forward_output1\": \"binary_crossentropy\"}\n",
    "            #\"error_feed_forward_output2\": \"categorical_crossentropy\",            \n",
    "        \n",
    "        \n",
    "        lossWeights = {\"error_feed_forward_output1\": 1.0  }#\"error_feed_forward_output2\": 1.0}\n",
    "        for i in range(len(target_LB[0])):  #列出 len(target_LB[0]) 組網路層\n",
    "          name = \"LNout\"+str(i)\n",
    "          losses[name] = \"categorical_crossentropy\"\n",
    "          lossWeights[name] = 1 #error_feed_forward_output2[] weight\n",
    "\n",
    "        \n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss=losses, loss_weights=lossWeights)\n",
    "        \n",
    "    \n",
    "        \n",
    "        print(\"x.shape\", np.asarray(encode_input).shape)  #x.shape (2,  9)\n",
    "        \n",
    " \n",
    "        #x=[np.array(encode_input * 1)]\n",
    "        #y=[np.array(target_errors * 1),np.array(target_LB * 1)]\n",
    "       \n",
    "        #print(\"x.shape\", np.asarray(x).shape)  #x.shape (2, 2048, 9)\n",
    "        \n",
    "        ####  Split the data set into train and test_model\n",
    "        x=np.array(encode_input)\n",
    "        y=list(zip(np.array(target_errors), np.array(target_LB)))\n",
    "\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "        y_train = list(zip(*y_train))  \n",
    "        y_train[0] = np.array(y_train[0])\n",
    "        y_train[1] = np.array(y_train[1])\n",
    "\n",
    "        y_train[1] = to_categorical(y_train[1], num_classes=max_javaline_length) #將類別向量轉換為二進制矩陣\n",
    "        #y_train = list(zip(y_train[0], y_train[1]))\n",
    "\n",
    "        print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX:\" , y_train[0].shape)\n",
    "        print(\"y_train[1].shape\", y_train[1].shape)\n",
    "        print(\"???????????: y_train.length \", len(y_train))\n",
    "        print(\"???????????: y_train.[1] type \", type(y_train[1]))\n",
    "        y_train[1] = np.split(y_train[1], indices_or_sections=len(target_LB[0]), axis=1)\n",
    "        y_train[1] = [  np.squeeze(elm, axis=1) for elm in y_train[1] ]\n",
    "        print(\"after change->len(y_train[1].shape)\", len(y_train[1]) )\n",
    "        \n",
    "        y_test = list(zip(*y_test))\n",
    "        y_test[0] = np.array(y_test[0])\n",
    "        y_test[1] = np.array(y_test[1])\n",
    "        y_test[1] = to_categorical(y_test[1], num_classes=max_javaline_length) \n",
    "        #y_test = list(zip(y_test[0], y_test[1])) \n",
    "        y_test[1] = np.split(y_test[1], indices_or_sections=len(target_LB[0]), axis=1) \n",
    "        y_test[1] = [  np.squeeze(elm, axis=1) for elm in y_test[1] ]           \n",
    "        '''\n",
    "        saveTestTrainData(\"/content/x_train_500.npy\", x_train)\n",
    "        saveTestTrainData(\"/content/x_test_500.npy\", x_test)\n",
    "        saveTestTrainData(\"/content/y_train0_500.npy\", y_train[0])#target\n",
    "        saveTestTrainData(\"/content/y_train1_500.npy\", y_train[1])#lb\n",
    "        saveTestTrainData(\"/content/y_test0_500.npy\", y_test[0])\n",
    "        saveTestTrainData(\"/content/y_test1_500.npy\", y_test[1])\n",
    "        '''\n",
    "        saveTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/train_models/x_train_500.npy\", x_train)\n",
    "        saveTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/x_test_500.npy\", x_test)\n",
    "        saveTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/train_models/y_train0_500.npy\", y_train[0])#target\n",
    "        saveTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/train_models/y_train1_500.npy\", y_train[1])#lb\n",
    "        saveTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/y_test0_500.npy\", y_test[0])\n",
    "        saveTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/y_test1_500.npy\", y_test[1])\n",
    "    \n",
    "        ####\n",
    "        #if you only need to train model don't use this\n",
    "        print(\"y_train[0].shape\",y_train[0].shape)\n",
    "        print(\"len(y_train[1])\",len(y_train[1]))\n",
    "        print(\"y_train[1][0].shape\",y_train[1][0].shape)\n",
    "        \n",
    "        history=model.fit(\n",
    "            x=x_train,\n",
    "            y= [y_train[0]] + y_train[1],\n",
    "            epochs=1, #100 200 500\n",
    "            batch_size=32,\n",
    "        )\n",
    "        plotTrainingLoss(history)\n",
    "        model.save(\"/content/drive/MyDrive/Final_Edition_include_model/models/test_model1.h5\")\n",
    "        saveDictionary(source_token_dict, '/content/drive/MyDrive/Final_Edition_include_model/models/source_token_dict.pickle')\n",
    "        \n",
    "        model, source_token_dict = load(\"/content/drive/MyDrive/Final_Edition_include_model/models/test_model1.h5\")\n",
    "\n",
    "        # Predict\n",
    "        '''\n",
    "        x_train_loaded = loadTestTrainData(\"/content/x_train_500.npy\") \n",
    "        y_train_loaded = [  loadTestTrainData(\"/content/y_train0_500.npy\"),\n",
    "                          loadTestTrainData(\"/content/y_train1_500.npy\") ]\n",
    "\n",
    "        x_test_loaded =  loadTestTrainData(\"/content/x_test_500.npy\") \n",
    "        y_test_loaded = [ loadTestTrainData(\"/content/y_test0_500.npy\"),\n",
    "                         loadTestTrainData(\"/content/y_test1_500.npy\")]\n",
    "        '''\n",
    "        x_train_loaded = loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/train_models/x_train_500.npy\") \n",
    "        y_train_loaded_0 =   loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/train_models/y_train0_500.npy\")\n",
    "        y_train_loaded_1 =   loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/train_models/y_train1_500.npy\") \n",
    "\n",
    "        x_test_loaded =  loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/x_test_500.npy\") \n",
    "        y_test_loaded_0 =   loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/y_test0_500.npy\")\n",
    "        y_test_loaded_1 =   loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/y_test1_500.npy\") \n",
    "        '''\n",
    "        y_test_loaded = [ loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/y_test0_500.npy\"),\n",
    "                         loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/y_test1_500.npy\")]\n",
    "        '''\n",
    "        \n",
    "        out1, out2 = tfr.decode(\n",
    "            model,\n",
    "            #encode_input,\n",
    "            x_test_loaded,max_len=source_max_len\n",
    "        )\n",
    "        print(\"out1: \", out1)\n",
    "        #print(\"target_errors: \",target_errors) \n",
    "        print(\"target_errors: \", y_test_loaded_0)        \n",
    "        print(\"out2: \", out2)\n",
    "        #print(\"target_LB: \", target_LB)\n",
    "        print(\"target_LB: \", y_test_loaded_1)\n",
    "        \n",
    "        #model.summary()\n",
    "        '''\n",
    "        print(\"x_train_loaded.shape:\",x_train_loaded.shape)\n",
    "        print(\"y_train_loaded[0].shape:\",y_train_loaded[0].shape)\n",
    "        print(\"y_train_loaded[1].shape:\",y_train_loaded[1].shape)\n",
    "        y_train_loaded[1] = np.split(y_train_loaded[1], indices_or_sections=323, axis=1)\n",
    "        y_train_loaded[1] = [  np.squeeze(elm, axis=1) for elm in y_train_loaded[1] ]\n",
    "        #print(\"after change->y_train_loaded[1].shape:\",y_train_loaded[1].shape)\n",
    "        #print(\"after change->len(y_train_loaded)\", len(y_train_loaded) )\n",
    "        #print(\"after change->y_train_loaded[1].shape\", y_train_loaded[1].shape )\n",
    "        print(\"after change->len(y_train_loaded[1])\", len(y_train_loaded[1]) )\n",
    "        print(\"after change->len(y_train_loaded[1][0])\", len(y_train_loaded[1][0]) )\n",
    "        print(\"after change->len(y_train_loaded[1][0][0])\", len(y_train_loaded[1][0][0]) )\n",
    "        #x_train_loaded.reshape(len(y_train_loaded[0]),len(y_train_loaded[1]))\n",
    "        '''\n",
    "        print(\"type(y_train_loaded_0)\",type(y_train_loaded_0))\n",
    "        print(\"type(y_train_loaded_1)\",type(y_train_loaded_1))\n",
    "        print(\"y_train_loaded[0].shape\",y_train_loaded_0.shape)\n",
    "\n",
    "        print(\"len(y_train_loaded[1])\",len(y_train_loaded_1))\n",
    "        print(\"y_train_loaded[1][0].shape\",y_train_loaded_1[0].shape)\n",
    "        train_loss = model.evaluate(x_train_loaded, [y_train_loaded_0] + list(y_train_loaded_1) )\n",
    "        print(\"train_loss\",train_loss)\n",
    "        '''\n",
    "        x=x_train,\n",
    "        y= [y_train[0]] + y_train[1]\n",
    "        '''\n",
    "        '''\n",
    "        y_test_loaded[1] = np.split(y_test_loaded[1], indices_or_sections=323, axis=1)\n",
    "        y_test_loaded[1] = [  np.squeeze(elm, axis=1) for elm in y_test_loaded[1] ]\n",
    "        '''\n",
    "        test_loss = model.evaluate(x_test_loaded, [y_test_loaded_0] + list(y_test_loaded_1) )\n",
    "        print(\"test_loss\",test_loss)\n",
    "        \n",
    "    def getsource_max_lan(self):\n",
    "        return self.sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aa3c824"
   },
   "outputs": [],
   "source": [
    "def saveDictionary(dt, file):\n",
    "        import pickle\n",
    "        a_file = open(file, \"wb\")\n",
    "        pickle.dump(dt, a_file)\n",
    "        a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6ddfb54"
   },
   "outputs": [],
   "source": [
    "def loadDictionary(file):\n",
    "        import pickle\n",
    "        a_file = open(file, \"rb\")\n",
    "        dt = pickle.load(a_file)\n",
    "        return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20063beb"
   },
   "outputs": [],
   "source": [
    "def saveTestTrainData(filename, data): # e.g., 'test.npy'\n",
    "    with open(filename, 'wb') as f:\n",
    "        np.save(f, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34dcfe7d"
   },
   "outputs": [],
   "source": [
    "def loadTestTrainData(filename): # e.g., 'test.npy'    \n",
    "    with open(filename, 'rb') as f:\n",
    "        a = np.load(f)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba969ac3"
   },
   "outputs": [],
   "source": [
    "def load(model_name):\n",
    "        import sys\n",
    "        sys.path.append('/content/drive/MyDrive/Final_Edition_include_model')\n",
    "        #sys.path.append('/content/drive/MyDrive/Final_Edition_include_model/keras_position_wise_feed_forward')\n",
    "        #sys.path.append('/content/drive/MyDrive/Final_Edition_include_model/tensorflow_fast_attention')\n",
    "        #sys.path.append('/content/drive/MyDrive/Final_Edition_include_model/keras_performer')\n",
    "        #sys.path.append('/content/drive/MyDrive/Final_Edition_include_model/keras_pos_embed')\n",
    "\n",
    "        from keras_performer import performer\n",
    "        from tensorflow import keras\n",
    "        from keras_embed_sim import EmbeddingRet, EmbeddingSim\n",
    "        from keras_pos_embd import TrigPosEmbedding\n",
    "        from tensorflow_fast_attention.fast_attention import  Attention, SelfAttention\n",
    "        from keras_position_wise_feed_forward.feed_forward import FeedForward  \n",
    "\n",
    "        co = performer.get_custom_objects()\n",
    "\n",
    "        model = keras.models.load_model(model_name, custom_objects= co)\n",
    "        source_token_dict = loadDictionary('/content/drive/MyDrive/Final_Edition_include_model/models/source_token_dict.pickle')\n",
    "       # t = loadDictionary(target_token_dict, 'target_token_dict.pickle')\n",
    "       # t_inv = loadDictionary(target_token_dict_inv, 'target_token_dict_inv.pickle')\n",
    "        return model, source_token_dict,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "083be668",
    "outputId": "bddf7fcb-a6cb-4669-fdff-181d62f1afba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am here: \n",
      "AAAA:  (1, 359, 36)\n",
      "aaaa:  <class 'list'>\n",
      "XXXX:  359\n",
      "YYYY:  <class 'int'>\n",
      "ZZZZ:  359\n",
      "ZZZZ len(target_LB[0]):  84\n",
      "XXXX2:  359\n",
      "<class 'int'>\n",
      "In get_model: encoder_input:  (None, 2919)\n",
      "In get_model: encoder_embed:  (None, 2919, 32)\n",
      "Start Warpping................................\n",
      "OOOO: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-Embedding/add_1:0', description=\"created by layer 'Encoder-Embedding'\")\n",
      "embed_dim: 32\n",
      "head_num: 4\n",
      "dropout_rate: 0.05\n",
      "masked: False\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"self_attention_161/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "Start Warpping................................\n",
      "Start Warpping................................\n",
      "OOOO: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-1-FeedForward-Norm/add_1:0', description=\"created by layer 'Encoder-1-FeedForward-Norm'\")\n",
      "embed_dim: 32\n",
      "head_num: 4\n",
      "dropout_rate: 0.05\n",
      "masked: False\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"self_attention_163/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "Start Warpping................................\n",
      "Start Warpping................................\n",
      "OOOO: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-2-FeedForward-Norm/add_1:0', description=\"created by layer 'Encoder-2-FeedForward-Norm'\")\n",
      "embed_dim: 32\n",
      "head_num: 4\n",
      "dropout_rate: 0.05\n",
      "masked: False\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"self_attention_165/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "Start Warpping................................\n",
      "Start Warpping................................\n",
      "OOOO: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-3-FeedForward-Norm/add_1:0', description=\"created by layer 'Encoder-3-FeedForward-Norm'\")\n",
      "embed_dim: 32\n",
      "head_num: 4\n",
      "dropout_rate: 0.05\n",
      "masked: False\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"self_attention_167/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "Start Warpping................................\n",
      "encoded_layer: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-4-FeedForward-Norm/add_1:0', description=\"created by layer 'Encoder-4-FeedForward-Norm'\")\n",
      "encoded_layer shape: (None, 2919, 32)\n",
      "max_input_len, embed_dim: 2919 32\n",
      "flatten_state: (None, 93408)\n",
      "flatten_state: (None, 93408)\n",
      "error_feed_forward_output1: (None, 36)\n",
      "error_feed_forward_output2: (None, 84)\n",
      "LNoutputs: [<KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout0')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout1')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout2')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout3')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout4')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout5')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout6')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout7')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout8')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout9')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout10')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout11')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout12')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout13')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout14')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout15')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout16')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout17')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout18')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout19')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout20')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout21')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout22')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout23')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout24')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout25')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout26')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout27')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout28')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout29')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout30')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout31')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout32')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout33')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout34')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout35')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout36')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout37')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout38')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout39')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout40')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout41')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout42')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout43')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout44')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout45')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout46')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout47')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout48')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout49')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout50')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout51')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout52')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout53')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout54')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout55')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout56')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout57')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout58')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout59')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout60')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout61')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout62')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout63')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout64')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout65')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout66')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout67')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout68')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout69')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout70')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout71')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout72')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout73')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout74')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout75')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout76')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout77')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout78')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout79')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout80')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout81')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout82')>, <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'LNout83')>]\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder-Input (InputLayer)      [(None, 2919)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Token-Embedding (EmbeddingRet)  [(None, 2919, 32), ( 46816       Encoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Embedding (TrigPosEmbed (None, 2919, 32)     0           Token-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_161 (SelfAttenti (None, 2919, 32)     4096        Encoder-Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 2919, 32)     0           self_attention_161[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 2919, 32)     0           Encoder-Embedding[0][0]          \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 2919, 32)     64          Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 2919, 32)     4192        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 2919, 32)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 2919, 32)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 2919, 32)     64          Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_163 (SelfAttenti (None, 2919, 32)     4096        Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 2919, 32)     0           self_attention_163[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 2919, 32)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 2919, 32)     64          Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 2919, 32)     4192        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 2919, 32)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 2919, 32)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 2919, 32)     64          Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_165 (SelfAttenti (None, 2919, 32)     4096        Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 2919, 32)     0           self_attention_165[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 2919, 32)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 2919, 32)     64          Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 2919, 32)     4192        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 2919, 32)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 2919, 32)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 2919, 32)     64          Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_167 (SelfAttenti (None, 2919, 32)     4096        Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 2919, 32)     0           self_attention_167[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 2919, 32)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 2919, 32)     64          Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 2919, 32)     4192        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 2919, 32)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 2919, 32)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 2919, 32)     64          Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 93408)        0           Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 64)           5978176     reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "error_feed_forward_output1 (Den (None, 36)           2340        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 93444)        0           error_feed_forward_output1[0][0] \n",
      "                                                                 reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 64)           5980480     concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "error_feed_forward_output2 (Den (None, 84)           5460        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "LNout0 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout1 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout2 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout3 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout4 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout5 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout6 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout7 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout8 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout9 (Dense)                  (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout10 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout11 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout12 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout13 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout14 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout15 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout16 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout17 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout18 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout19 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout20 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout21 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout22 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout23 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout24 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout25 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout26 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout27 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout28 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout29 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout30 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout31 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout32 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout33 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout34 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout35 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout36 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout37 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout38 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout39 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout40 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout41 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout42 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout43 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout44 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout45 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout46 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout47 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout48 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout49 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout50 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout51 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout52 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout53 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout54 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout55 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout56 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout57 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout58 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout59 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout60 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout61 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout62 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout63 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout64 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout65 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout66 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout67 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout68 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout69 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout70 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout71 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout72 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout73 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout74 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout75 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout76 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout77 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout78 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout79 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout80 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout81 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout82 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "LNout83 (Dense)                 (None, 150)          12750       error_feed_forward_output2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 13,117,936\n",
      "Trainable params: 13,117,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "x.shape (359, 2919)\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX: (323, 36)\n",
      "y_train[1].shape (323, 84, 150)\n",
      "???????????: y_train.length  2\n",
      "???????????: y_train.[1] type  <class 'numpy.ndarray'>\n",
      "after change->len(y_train[1].shape) 84\n",
      "y_train[0].shape (323, 36)\n",
      "len(y_train[1]) 84\n",
      "y_train[1][0].shape (323, 150)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"model_11/self_attention_161/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"model_11/self_attention_163/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"model_11/self_attention_165/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"model_11/self_attention_167/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"model_11/self_attention_161/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"model_11/self_attention_163/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"model_11/self_attention_165/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "dim:  8\n",
      "query:  Tensor(\"model_11/self_attention_167/query/einsum/Einsum:0\", shape=(None, 2919, 4, 8), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 16)\n",
      "11/11 [==============================] - 67s 4s/step - loss: 1149.2027 - error_feed_forward_output1_loss: 3.4364 - LNout0_loss: 13.9916 - LNout1_loss: 13.1847 - LNout2_loss: 10.8715 - LNout3_loss: 17.7097 - LNout4_loss: 22.6793 - LNout5_loss: 19.0112 - LNout6_loss: 14.2326 - LNout7_loss: 11.0160 - LNout8_loss: 17.0177 - LNout9_loss: 18.6006 - LNout10_loss: 12.0681 - LNout11_loss: 17.8678 - LNout12_loss: 13.0995 - LNout13_loss: 10.3381 - LNout14_loss: 16.3209 - LNout15_loss: 17.2122 - LNout16_loss: 14.2901 - LNout17_loss: 16.2597 - LNout18_loss: 15.7311 - LNout19_loss: 22.5941 - LNout20_loss: 14.2211 - LNout21_loss: 13.6145 - LNout22_loss: 13.0694 - LNout23_loss: 15.9441 - LNout24_loss: 11.2362 - LNout25_loss: 22.4329 - LNout26_loss: 15.2026 - LNout27_loss: 9.1780 - LNout28_loss: 10.9313 - LNout29_loss: 7.9513 - LNout30_loss: 16.1401 - LNout31_loss: 12.9453 - LNout32_loss: 11.8027 - LNout33_loss: 15.9943 - LNout34_loss: 14.6080 - LNout35_loss: 13.9076 - LNout36_loss: 13.8292 - LNout37_loss: 16.5511 - LNout38_loss: 12.1379 - LNout39_loss: 7.8962 - LNout40_loss: 5.3404 - LNout41_loss: 8.8000 - LNout42_loss: 12.4956 - LNout43_loss: 17.3852 - LNout44_loss: 12.8364 - LNout45_loss: 13.8075 - LNout46_loss: 14.5105 - LNout47_loss: 12.0513 - LNout48_loss: 13.2631 - LNout49_loss: 6.8942 - LNout50_loss: 14.7528 - LNout51_loss: 15.5630 - LNout52_loss: 11.7858 - LNout53_loss: 10.3981 - LNout54_loss: 8.4497 - LNout55_loss: 17.8408 - LNout56_loss: 8.5599 - LNout57_loss: 12.2965 - LNout58_loss: 18.8846 - LNout59_loss: 10.9242 - LNout60_loss: 6.3425 - LNout61_loss: 3.9170 - LNout62_loss: 17.7264 - LNout63_loss: 16.7806 - LNout64_loss: 7.0581 - LNout65_loss: 8.2808 - LNout66_loss: 18.4131 - LNout67_loss: 8.0580 - LNout68_loss: 15.7294 - LNout69_loss: 11.8937 - LNout70_loss: 20.7398 - LNout71_loss: 14.1210 - LNout72_loss: 16.0053 - LNout73_loss: 13.2032 - LNout74_loss: 12.6133 - LNout75_loss: 12.7747 - LNout76_loss: 16.9400 - LNout77_loss: 17.0052 - LNout78_loss: 14.4980 - LNout79_loss: 11.4154 - LNout80_loss: 11.5878 - LNout81_loss: 10.1377 - LNout82_loss: 14.0737 - LNout83_loss: 15.9218\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "out1.shape (36, 36)\n",
      "out2.shape (36, 150)\n",
      "out1:  [[3.6933196e-01 4.6388242e-02 2.9064061e-02 ... 6.1619973e-11\n",
      "  2.4084165e-06 5.6779550e-07]\n",
      " [3.1207886e-01 4.6458013e-02 3.3929836e-02 ... 6.3493530e-11\n",
      "  3.4673690e-06 5.5565317e-07]\n",
      " [4.6016291e-01 4.3379929e-02 2.0658748e-02 ... 5.7786467e-11\n",
      "  1.4503084e-06 5.7054990e-07]\n",
      " ...\n",
      " [3.8385719e-01 4.5454483e-02 2.7096914e-02 ... 6.1202730e-11\n",
      "  2.1589885e-06 5.6091488e-07]\n",
      " [3.3349645e-01 4.6749327e-02 3.2305077e-02 ... 6.3042224e-11\n",
      "  3.0469316e-06 5.6208080e-07]\n",
      " [4.1316244e-01 4.4504162e-02 2.4892528e-02 ... 5.9713942e-11\n",
      "  1.7915849e-06 5.5666044e-07]]\n",
      "target_errors:  [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "out2:  [[0.00350622 0.00959133 0.01100901 ... 0.00340101 0.00536826 0.01477389]\n",
      " [0.00323741 0.00957146 0.0113716  ... 0.00312209 0.00514135 0.01469315]\n",
      " [0.00382144 0.00997636 0.01080308 ... 0.00372572 0.00568684 0.01469237]\n",
      " ...\n",
      " [0.00355525 0.00973272 0.01100126 ... 0.00346342 0.0054764  0.01502116]\n",
      " [0.00333682 0.00958905 0.01121713 ... 0.00321295 0.00521438 0.01472365]\n",
      " [0.00364155 0.00980641 0.01090111 ... 0.003563   0.00558916 0.01486642]]\n",
      "target_LB:  [[[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n",
      "type(y_train_loaded_0) <class 'numpy.ndarray'>\n",
      "type(y_train_loaded_1) <class 'numpy.ndarray'>\n",
      "y_train_loaded[0].shape (323, 36)\n",
      "len(y_train_loaded[1]) 84\n",
      "y_train_loaded[1][0].shape (323, 150)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 4, 8)\n",
      "Key: XXXXXXX  (None, 2919, 4, 8)\n",
      "Value: XXXXXXX  (None, 2919, 4, 8)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 4, 8)\n",
      "11/11 [==============================] - 15s 703ms/step - loss: 408.9731 - error_feed_forward_output1_loss: 1.1611 - LNout0_loss: 4.9290 - LNout1_loss: 5.0919 - LNout2_loss: 4.6343 - LNout3_loss: 5.1428 - LNout4_loss: 4.7825 - LNout5_loss: 5.3591 - LNout6_loss: 4.6562 - LNout7_loss: 4.9091 - LNout8_loss: 5.5899 - LNout9_loss: 4.9870 - LNout10_loss: 3.8514 - LNout11_loss: 5.7308 - LNout12_loss: 4.3426 - LNout13_loss: 4.3681 - LNout14_loss: 4.9821 - LNout15_loss: 5.2653 - LNout16_loss: 4.5310 - LNout17_loss: 4.3566 - LNout18_loss: 4.4859 - LNout19_loss: 5.3148 - LNout20_loss: 5.3021 - LNout21_loss: 3.8042 - LNout22_loss: 5.4906 - LNout23_loss: 5.1174 - LNout24_loss: 5.1625 - LNout25_loss: 5.5100 - LNout26_loss: 5.1551 - LNout27_loss: 4.5696 - LNout28_loss: 5.3908 - LNout29_loss: 3.8933 - LNout30_loss: 4.2532 - LNout31_loss: 4.5947 - LNout32_loss: 4.3961 - LNout33_loss: 5.4775 - LNout34_loss: 5.5194 - LNout35_loss: 4.5388 - LNout36_loss: 4.9793 - LNout37_loss: 5.2862 - LNout38_loss: 4.7465 - LNout39_loss: 4.7466 - LNout40_loss: 3.7759 - LNout41_loss: 4.5322 - LNout42_loss: 4.6435 - LNout43_loss: 4.8715 - LNout44_loss: 4.5158 - LNout45_loss: 5.8295 - LNout46_loss: 5.1728 - LNout47_loss: 5.2171 - LNout48_loss: 4.4362 - LNout49_loss: 5.0091 - LNout50_loss: 5.4920 - LNout51_loss: 4.1961 - LNout52_loss: 4.4994 - LNout53_loss: 4.0897 - LNout54_loss: 5.1454 - LNout55_loss: 5.3326 - LNout56_loss: 5.7213 - LNout57_loss: 4.8769 - LNout58_loss: 5.4499 - LNout59_loss: 3.3784 - LNout60_loss: 5.1714 - LNout61_loss: 3.9707 - LNout62_loss: 5.0088 - LNout63_loss: 5.2526 - LNout64_loss: 4.9520 - LNout65_loss: 5.1205 - LNout66_loss: 5.0017 - LNout67_loss: 4.8788 - LNout68_loss: 5.0959 - LNout69_loss: 4.3685 - LNout70_loss: 5.6349 - LNout71_loss: 4.3746 - LNout72_loss: 4.2581 - LNout73_loss: 4.8366 - LNout74_loss: 4.7776 - LNout75_loss: 3.7509 - LNout76_loss: 5.6326 - LNout77_loss: 4.8800 - LNout78_loss: 5.3061 - LNout79_loss: 4.2169 - LNout80_loss: 4.9774 - LNout81_loss: 4.8715 - LNout82_loss: 4.5451 - LNout83_loss: 5.4993\n",
      "train_loss [408.97314453125, 1.1611417531967163, 4.928971290588379, 5.091871738433838, 4.634332180023193, 5.14279317855835, 4.7825093269348145, 5.359140872955322, 4.656188488006592, 4.909093379974365, 5.589897632598877, 4.987030029296875, 3.8513712882995605, 5.730752944946289, 4.342566013336182, 4.368072032928467, 4.9820709228515625, 5.265281677246094, 4.53098726272583, 4.3565754890441895, 4.485947608947754, 5.314834117889404, 5.30206298828125, 3.8042242527008057, 5.490564823150635, 5.117425441741943, 5.162465572357178, 5.509985446929932, 5.155129909515381, 4.569591999053955, 5.39084529876709, 3.8933093547821045, 4.253230094909668, 4.5947136878967285, 4.396129131317139, 5.47747802734375, 5.5193891525268555, 4.5387864112854, 4.979310989379883, 5.286201000213623, 4.746484279632568, 4.746564865112305, 3.775878429412842, 4.532240390777588, 4.6434550285339355, 4.87145471572876, 4.515758991241455, 5.829504489898682, 5.1727705001831055, 5.217074394226074, 4.436216831207275, 5.009057998657227, 5.492032051086426, 4.196147918701172, 4.4993815422058105, 4.089704513549805, 5.145381927490234, 5.332611560821533, 5.721257209777832, 4.876899719238281, 5.449903964996338, 3.378371477127075, 5.1713738441467285, 3.9707062244415283, 5.00883150100708, 5.252572059631348, 4.952049255371094, 5.120543479919434, 5.001675128936768, 4.878818035125732, 5.095939636230469, 4.368521213531494, 5.634860515594482, 4.374609470367432, 4.2580976486206055, 4.836645126342773, 4.777593612670898, 3.7509114742279053, 5.632566452026367, 4.88001823425293, 5.306140899658203, 4.216864585876465, 4.977447509765625, 4.871507167816162, 4.545101165771484, 5.499340534210205]\n",
      "2/2 [==============================] - 1s 105ms/step - loss: 409.1270 - error_feed_forward_output1_loss: 1.1950 - LNout0_loss: 4.9406 - LNout1_loss: 5.1741 - LNout2_loss: 4.6136 - LNout3_loss: 5.1568 - LNout4_loss: 4.7696 - LNout5_loss: 5.3903 - LNout6_loss: 4.6319 - LNout7_loss: 4.8729 - LNout8_loss: 5.5923 - LNout9_loss: 5.0229 - LNout10_loss: 3.8399 - LNout11_loss: 5.7222 - LNout12_loss: 4.3309 - LNout13_loss: 4.3597 - LNout14_loss: 4.9864 - LNout15_loss: 5.2944 - LNout16_loss: 4.4787 - LNout17_loss: 4.3409 - LNout18_loss: 4.5153 - LNout19_loss: 5.3346 - LNout20_loss: 5.2700 - LNout21_loss: 3.8232 - LNout22_loss: 5.4750 - LNout23_loss: 5.1158 - LNout24_loss: 5.1518 - LNout25_loss: 5.5152 - LNout26_loss: 5.1414 - LNout27_loss: 4.5682 - LNout28_loss: 5.3231 - LNout29_loss: 3.9698 - LNout30_loss: 4.3395 - LNout31_loss: 4.6262 - LNout32_loss: 4.4285 - LNout33_loss: 5.4554 - LNout34_loss: 5.4884 - LNout35_loss: 4.5673 - LNout36_loss: 4.9794 - LNout37_loss: 5.2457 - LNout38_loss: 4.7890 - LNout39_loss: 4.7679 - LNout40_loss: 3.7909 - LNout41_loss: 4.5421 - LNout42_loss: 4.6464 - LNout43_loss: 4.9176 - LNout44_loss: 4.5665 - LNout45_loss: 5.7389 - LNout46_loss: 5.1664 - LNout47_loss: 5.1972 - LNout48_loss: 4.4352 - LNout49_loss: 4.9931 - LNout50_loss: 5.4921 - LNout51_loss: 4.1989 - LNout52_loss: 4.5123 - LNout53_loss: 4.0950 - LNout54_loss: 5.1335 - LNout55_loss: 5.3159 - LNout56_loss: 5.6955 - LNout57_loss: 4.9103 - LNout58_loss: 5.4271 - LNout59_loss: 3.4122 - LNout60_loss: 5.1492 - LNout61_loss: 3.9744 - LNout62_loss: 5.0088 - LNout63_loss: 5.2362 - LNout64_loss: 4.9426 - LNout65_loss: 5.1072 - LNout66_loss: 4.9958 - LNout67_loss: 4.8800 - LNout68_loss: 5.0783 - LNout69_loss: 4.3646 - LNout70_loss: 5.6338 - LNout71_loss: 4.3990 - LNout72_loss: 4.2674 - LNout73_loss: 4.8370 - LNout74_loss: 4.7966 - LNout75_loss: 3.7725 - LNout76_loss: 5.6171 - LNout77_loss: 4.8734 - LNout78_loss: 5.3058 - LNout79_loss: 4.2208 - LNout80_loss: 4.9767 - LNout81_loss: 4.8617 - LNout82_loss: 4.5646 - LNout83_loss: 5.4724\n",
      "test_loss [409.1269836425781, 1.1950480937957764, 4.9406256675720215, 5.174127101898193, 4.6136064529418945, 5.1568474769592285, 4.769623279571533, 5.390326499938965, 4.63185453414917, 4.8728814125061035, 5.592250347137451, 5.022927761077881, 3.839869976043701, 5.722234725952148, 4.330931663513184, 4.359748840332031, 4.986368179321289, 5.294383525848389, 4.478743076324463, 4.340895652770996, 4.515314102172852, 5.334635257720947, 5.269958972930908, 3.823171854019165, 5.475006580352783, 5.115828514099121, 5.151848793029785, 5.51522159576416, 5.141391277313232, 4.568230628967285, 5.323075294494629, 3.969759225845337, 4.33947229385376, 4.62615966796875, 4.428520679473877, 5.455358505249023, 5.488430023193359, 4.567311763763428, 4.979390621185303, 5.245682716369629, 4.789007186889648, 4.767920017242432, 3.790904998779297, 4.542144298553467, 4.646406173706055, 4.917623519897461, 4.566466331481934, 5.738912582397461, 5.166414260864258, 5.197230339050293, 4.435189247131348, 4.993076324462891, 5.492074012756348, 4.1988725662231445, 4.512267112731934, 4.0949788093566895, 5.133460998535156, 5.315925121307373, 5.695534706115723, 4.910293102264404, 5.427126884460449, 3.412242889404297, 5.149200916290283, 3.974405527114868, 5.008785724639893, 5.236186504364014, 4.942600250244141, 5.107171058654785, 4.995840549468994, 4.879988193511963, 5.078258514404297, 4.36463737487793, 5.633772373199463, 4.3990373611450195, 4.267396926879883, 4.836967945098877, 4.796629905700684, 3.77245831489563, 5.6171345710754395, 4.873395919799805, 5.305750370025635, 4.220791339874268, 4.976690769195557, 4.861684799194336, 4.564638137817383, 5.47243070602417]\n"
     ]
    }
   ],
   "source": [
    "x=TestTranslate()\n",
    "x.test_translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psq7nyP0ca_Z"
   },
   "source": [
    "## 績效測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2ad29f4"
   },
   "outputs": [],
   "source": [
    "# the following funcs is make socre to model \n",
    "testmodel = \"/content/drive/MyDrive/Final_Edition_include_model/models/test_model1.h5\"\n",
    "score_dict = \"/content/drive/MyDrive/Final_Edition_include_model/models/source_token_dict.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGUreZSPmLVi"
   },
   "outputs": [],
   "source": [
    "def load_score(model_name):\n",
    "        import sys\n",
    "        sys.path.append('/content/drive/MyDrive/Final_Edition_include_model')\n",
    "        #sys.path.append('/content/drive/MyDrive/Final_Edition_include_model/keras_position_wise_feed_forward')\n",
    "        #sys.path.append('/content/drive/MyDrive/Final_Edition_include_model/tensorflow_fast_attention')\n",
    "        #sys.path.append('/content/drive/MyDrive/Final_Edition_include_model/keras_performer')\n",
    "        #sys.path.append('/content/drive/MyDrive/Final_Edition_include_model/keras_pos_embed')\n",
    "\n",
    "        from keras_performer import performer\n",
    "        from tensorflow import keras\n",
    "        from keras_embed_sim import EmbeddingRet, EmbeddingSim\n",
    "        from keras_pos_embd import TrigPosEmbedding\n",
    "        from tensorflow_fast_attention.fast_attention import  Attention, SelfAttention\n",
    "        from keras_position_wise_feed_forward.feed_forward import FeedForward  \n",
    "\n",
    "        co = performer.get_custom_objects()\n",
    "\n",
    "        model = keras.models.load_model(model_name, custom_objects= co)\n",
    "        \n",
    "        source_token_dict = loadDictionary(score_dict)\n",
    "       # t = loadDictionary(target_token_dict, 'target_token_dict.pickle')\n",
    "       # t_inv = loadDictionary(target_token_dict_inv, 'target_token_dict_inv.pickle')\n",
    "        return model, source_token_dict,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e009c2ae"
   },
   "outputs": [],
   "source": [
    "def loadTestdata():\n",
    "    import numpy as np\n",
    "    #load model and dic ps. dic is not use\n",
    "    model, source_token_dict = load_score(testmodel)\n",
    "    #load\n",
    "    x_test_loaded = loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/256 100 0.0001/x_test_100.npy\") \n",
    "    y_test_loaded = [ loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/256 100 0.0001/y_test0_100.npy\"), \n",
    "                     loadTestTrainData(\"/content/drive/MyDrive/Final_Edition_include_model/test_models/256 100 0.0001/y_test1_100.npy\")] \n",
    "    out1, out2 = tfr.decode(model,x_test_loaded,max_len=x.getsource_max_lan()) \n",
    "    #print((y_test_loaded[0][1])) #Error_type #vs out1\n",
    "    #print((y_test_loaded[1][1])) #Line_Block #vs out2\n",
    "    #print((out1[1]))#prob upper then 0.5\n",
    "    #print((out2[1]))#prob upper then 0.5\n",
    "    #print(int(out2))#prob lb\n",
    "    '''np.around為四捨五入\n",
    "    test_ep = np.around(out1)\n",
    "    test_lb = np.around(out2)\n",
    "    ans_ep = np.around(y_test_loaded[0])\n",
    "    ans_lb = np.around(y_test_loaded[1])\n",
    "    '''\n",
    "    test_ep = np.array(out1)\n",
    "    test_lb = np.array(out2)\n",
    "    ans_ep = np.array(y_test_loaded[0])\n",
    "    ans_lb = np.array(y_test_loaded[1])\n",
    "    print(\"test_ep.shape\")\n",
    "    print(test_ep.shape)\n",
    "    print(\"test_ep[0]\")\n",
    "    print(test_ep[0])\n",
    "    print(\"test_lb.shape\")\n",
    "    print(test_lb.shape)\n",
    "    print(\"test_lb[0]\")\n",
    "    print(test_lb[0])\n",
    "    print(\"ans_ep.shape\")\n",
    "    print(ans_ep.shape)\n",
    "    print(\"ans_ep[0]\")\n",
    "    print(ans_ep[0])\n",
    "    print(\"ans_lb[0]\")\n",
    "    print(ans_lb[0])\n",
    "    scoreTest(test_ep,test_lb,ans_ep,ans_lb) #go to test the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25b602c4"
   },
   "outputs": [],
   "source": [
    "def scoreTest(test_ep,test_lb,ans_ep,ans_lb):\n",
    "    #錯誤類型\n",
    "    ep_average=[]        #預測錯誤以及真實錯誤的交集除以樣本數\n",
    "    ep_accuracy=[]        #準確率\n",
    "    ep_recall=[]         #召回率\n",
    "    for i in range( len(test_ep) ):\n",
    "      ep_predic_and_real_Error_sum = []  #預測錯誤以及真實錯誤的交集\n",
    "      ep_predic_error=[]      #預測錯誤的總數\n",
    "      ep_real_error=[]       #真實錯誤的總數\n",
    "      for j in range(len( test_ep[i]) ):\n",
    "        if test_ep[i][j]==1:\n",
    "          ep_predic_error.append(1)\n",
    "        else: \n",
    "          ep_predic_error.append(0)\n",
    "        if ans_ep[i][j]==1:\n",
    "          ep_real_error.append(1)\n",
    "        else: \n",
    "          ep_real_error.append(0)\n",
    "        if (test_ep[i][j]==1 and ans_ep[i][j]==1):\n",
    "          ep_predic_and_real_Error_sum.append(1)\n",
    "        else:\n",
    "          ep_predic_and_real_Error_sum.append(0)       \n",
    "      ep_average.append( np.mean(ep_predic_and_real_Error_sum))\n",
    "      #準確率\n",
    "      if ( sum(ep_predic_and_real_Error_sum)==0 and sum(ep_predic_error)==0 ): #預測錯誤以及真實錯誤的交集=0和預測錯誤=0 代表預測正確\n",
    "        ep_accuracy.append(1)\n",
    "      elif ( sum(ep_predic_and_real_Error_sum)!=0 and sum(ep_predic_error)==0 ):\n",
    "        ep_accuracy.append(0)\n",
    "      else:\n",
    "        ep_accuracy.append( sum(ep_predic_and_real_Error_sum) /  sum(ep_predic_error) )\n",
    "        #print(\"第\",i,\"圈的準確率\",sum(ep_predic_and_real_Error_sum) /  sum(ep_predic_error))\n",
    "      #召回率\n",
    "      if ( sum(ep_predic_and_real_Error_sum)==0 and sum(ep_real_error)==0 ): #預測錯誤以及真實錯誤的交集=0和真實錯誤=0 代表預測正確\n",
    "        ep_recall.append(1)\n",
    "      elif ( sum(ep_predic_and_real_Error_sum)!=0 and sum(ep_real_error)==0 ):\n",
    "        ep_recall.append(0)\n",
    "      else:\n",
    "        ep_recall.append( sum(ep_predic_and_real_Error_sum) /  sum(ep_real_error))\n",
    "        print(\"第\",i,\"圈的召回率\",sum(ep_predic_and_real_Error_sum) /  sum(ep_real_error))\n",
    "    ep_average_averagy = sum(ep_average) / len(test_ep)\n",
    "    ep_accuracy_averagy= sum(ep_accuracy) / len(test_ep)\n",
    "    ep_recall_averagy= sum(ep_recall) / len(test_ep)\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"錯誤類型平均值(預測錯誤以及真實錯誤的交集除以樣本數): \",ep_average_averagy)\n",
    "    print(\"錯誤類型準確率: \",ep_accuracy_averagy)\n",
    "    print(\"錯誤類型召回率: \",ep_recall_averagy)\n",
    "\n",
    "    \n",
    "    #位置標註\n",
    "    lb_average=[] #預測錯誤以及真實錯誤的交集除以樣本數\n",
    "    lb_accuracy=[] #準確率\n",
    "    lb_recall=[] #召回率\n",
    "    for i in range( len(test_lb) ):   \n",
    "      lb_predic_and_real_Error_sum=[]  #預測錯誤以及真實錯誤的交集\n",
    "      lb_predic_error=[]       #預測錯誤的總數\n",
    "      lb_real_error=[]         #真實錯誤的總數\n",
    "      for j in range(0, (int(len(test_lb[i])/2)) ,2):\n",
    "        if (test_lb[i][j]!=0 and test_lb[i][j+1]!=0):\n",
    "          lb_predic_error.append(1)\n",
    "        else:\n",
    "          lb_predic_error.append(0)\n",
    "        if (ans_lb[i][j]!=0 and ans_lb[i][j+1]!=0):\n",
    "          lb_real_error.append(1)\n",
    "        else:\n",
    "          lb_real_error.append(0)\n",
    "        if (test_lb[i][j]==ans_lb[i][j] and test_lb[i][j+1]==ans_lb[i][j+1] and (test_lb[0][j]!=0 and ans_lb[0][j]!=0)):\n",
    "          lb_predic_and_real_Error_sum.append(1)\n",
    "        else:\n",
    "          lb_predic_and_real_Error_sum.append(0)       \n",
    "      lb_average.append( np.mean(lb_predic_and_real_Error_sum) )\n",
    "      #準確率\n",
    "      if ( sum(lb_predic_and_real_Error_sum)==0 and sum(lb_predic_error)==0 ): #預測錯誤以及真實錯誤的交集=0和預測錯誤=0 代表預測正確\n",
    "        lb_accuracy.append(1)\n",
    "      elif ( sum(lb_predic_and_real_Error_sum)!=0 and sum(lb_predic_error)==0 ):\n",
    "        lb_accuracy.append(0)\n",
    "      else:\n",
    "        lb_accuracy.append( sum(lb_predic_and_real_Error_sum) /  sum(lb_predic_error))\n",
    "        #print(\"第\",i,\"圈的準確率\",sum(lb_predic_and_real_Error_sum) /  sum(lb_predic_error))\n",
    "      #召回率\n",
    "      if ( sum(lb_predic_and_real_Error_sum)==0 and sum(lb_real_error)==0 ): #預測錯誤以及真實錯誤的交集=0和真實錯誤=0 代表預測正確\n",
    "        lb_recall.append(1)\n",
    "      elif ( sum(lb_predic_and_real_Error_sum)!=0 and sum(lb_real_error)==0 ):\n",
    "        lb_recall.append(0)\n",
    "      else:\n",
    "        lb_recall.append( sum(lb_predic_and_real_Error_sum) /  sum(lb_real_error) )\n",
    "        \n",
    "      print(\"第\",i,\"圈的召回率\",sum(lb_predic_and_real_Error_sum) /  sum(lb_real_error))\n",
    "    \n",
    "    lb_average_averagy = sum(lb_average) / (len(test_lb)/2)\n",
    "    lb_accuracy_averagy= sum(lb_accuracy) / (len(test_lb)/2)\n",
    "    lb_recall_averagy= sum(lb_recall) / (len(test_lb)/2)\n",
    "\n",
    "    print(\"標註位置平均值(預測錯誤以及真實錯誤的交集除以樣本數): \",lb_average_averagy)\n",
    "    print(\"標註位置準確率: \",lb_accuracy_averagy)\n",
    "    print(\"標註位置召回率: \",lb_recall_averagy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba7d0ca1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loadTestdata()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Y-JMBpEFcJWh",
    "psq7nyP0ca_Z"
   ],
   "name": "Main_Colab_績效測試版_7_26.84ver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
