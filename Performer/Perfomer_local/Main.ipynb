{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Perfomer_local/keras_layer_normalization')\n",
    "sys.path.append('Perfomer_local/keras_performer')\n",
    "sys.path.append('Perfomer_local/keras_position_wise_feed_forward')\n",
    "sys.path.append('Perfomer_local/tensorflow_fast_attention')\n",
    "\n",
    "'''\n",
    "sys.path.append('D:\\Code\\Project-AI-JAVA-ANNOTATION-2021\\Performer\\Perfomer_local\\keras_layer_normalization')\n",
    "sys.path.append('D:\\Code\\Project-AI-JAVA-ANNOTATION-2021\\Performer\\Perfomer_local\\keras_performer')\n",
    "sys.path.append('D:\\Code\\Project-AI-JAVA-ANNOTATION-2021\\Performer\\Perfomer_local\\keras_position_wise_feed_forward')\n",
    "sys.path.append('D:\\Code\\Project-AI-JAVA-ANNOTATION-2021\\Performer\\Perfomer_local\\tensorflow_fast_attention')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\W.R_Chen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import unittest\n",
    "import numpy as np\n",
    "from keras_performer import performer as tfr\n",
    "import nltk\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef solve_cudnn_error():\\n    import tensorflow as tf\\n    gpus = tf.config.experimental.list_physical_devices(\\'GPU\\')\\n    if gpus:\\n        try:\\n            # Currently, memory growth needs to be the same across GPUs\\n            for gpu in gpus:\\n                tf.config.experimental.set_memory_growth(gpu, True)\\n            logical_gpus = tf.config.experimental.list_logical_devices(\\'GPU\\')\\n            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\\n        except RuntimeError as e:\\n            # Memory growth must be set before GPUs have been initialized\\n            print(e)\\n            \\nsolve_cudnn_error()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def solve_cudnn_error():\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "            \n",
    "solve_cudnn_error()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def readCSV(file_name):\n",
    "  errlist=[]\n",
    "  LBlist=[]\n",
    "  with open(file_name, newline='') as csvfile:\n",
    "\n",
    "  # 讀取 CSV 檔內容，將每一列轉成一個 dictionary\n",
    "\n",
    "    rows = csv.DictReader(csvfile)\n",
    "    for row in rows: \n",
    "      RL=list(row.values())\n",
    "\n",
    "      RL = list(map(int, RL))\n",
    "      errs=RL[1:37]\n",
    "      LB=RL[37:]\n",
    "      errlist.append(errs)\n",
    "      LBlist.append(LB)\n",
    "  return errlist,LBlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_sublist(seq, sublist, start=0):\n",
    "    length = len(sublist)\n",
    "    for index in range(start, len(seq)):\n",
    "        if seq[index:index+length] == sublist:\n",
    "            return index, index+length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sublist(seq, sublist, replacement):\n",
    "    length = len(replacement)\n",
    "    index = 0\n",
    "    for start, end in iter(lambda: find_first_sublist(seq, sublist, index), None):\n",
    "        seq[start:end] = replacement\n",
    "        index = start + length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceTAGS(x):\n",
    "    replace_sublist(x, ['<', 'BOC', '>'], [\"<BOC>\"])\n",
    "    replace_sublist(x, ['<', 'EOC', '>'], [\"<EOC>\"])\n",
    "    replace_sublist(x, ['<', 'BOTM', '>'], [\"<BOTM>\"])\n",
    "    replace_sublist(x, ['<', 'BOT', '>'], [\"<BOT>\"])\n",
    "    replace_sublist(x, ['<', 'EOT', '>'], [\"<EOT>\"])\n",
    "    replace_sublist(x, ['<', 'BOM', '>'], [\"<BOM>\"])\n",
    "    replace_sublist(x, ['<', 'EOM', '>'], [\"<EOM>\"])\n",
    "    replace_sublist(x, ['<', 'EOTM', '>'], [\"<EOTM>\"])\n",
    "    replace_sublist(x, ['<', 'CR', '>'], [\"<CR>\"])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSentence(x):\t\n",
    "\ttokenizer = RegexpTokenizer(r\"[\\w']+|[].,:!?;=+-\\\\*/@#$%^&_(){}~|\\\"[]\")\n",
    "\ttokens=[]\n",
    "\tstate=\"START\"\n",
    "\tchrs=\"\"\n",
    "\tfor i in range(len(x)):\n",
    "\t\t#print(ord(x[i]))\n",
    "\t\tif (ord(x[i])>255):\n",
    "\t\t\tinp=\"U\"\n",
    "\t\telse:\n",
    "\t\t\tinp=\"E\"\n",
    "\t\n",
    "\t\tif state==\"START\":\n",
    "\t\t\tif inp==\"E\":\n",
    "\t\t\t\tstate=\"ASCII\"\n",
    "\t\t\t\tchrs=x[i]\n",
    "\t\t\telse:\n",
    "\t\t\t\tstate=\"UNICODE\"\n",
    "\t\t\t\ttokens.append(x[i])\n",
    "\t\t\t\n",
    "\t\telif state==\"ASCII\":\n",
    "\t\t\tif inp==\"E\":\n",
    "\t\t\t\tchrs += x[i]\n",
    "\t\t\telse:#U\n",
    "\t\t\t\tstate=\"UNICODE\"\n",
    "\t\t\t\ttokens += tokenizer.tokenize(chrs) #wordpunct_tokenize(chrs)  #nltk.word_tokenize(chrs)\n",
    "\t\t\t\tchrs=\"\"\n",
    "\t\t\t\ttokens.append(x[i])\n",
    "\t\n",
    "\t\telif state==\"UNICODE\":\n",
    "\t\t\tif inp==\"E\":\n",
    "\t\t\t\tstate=\"ASCII\"\n",
    "\t\t\t\tchrs=x[i]\n",
    "\t\t\telse:\n",
    "\t\t\t\tstate=\"UNICODE\"\n",
    "\t\t\t\ttokens.append(x[i])\n",
    "\tif len(chrs)>0:\n",
    "\t\ttokens += tokenizer.tokenize(chrs) #wordpunct_tokenize(chrs)  # nltk.word_tokenize(chrs) \n",
    "\treturn tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readcode(fname):\n",
    "    with open(fname,encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTranslate(unittest.TestCase):\n",
    "    @staticmethod\n",
    "    def _build_token_dict(token_list):\n",
    "        token_dict = {\n",
    "            '<PAD>': 0,\n",
    "            '<START>': 1,\n",
    "            '<END>': 2,\n",
    "            '<BOC>': 3,\n",
    "            '<EOC>': 4,\n",
    "            '<BOTM>': 5,\n",
    "            '<BOT>': 6,\n",
    "            '<EOT>': 7,\n",
    "            '<BOM>': 8,\n",
    "            '<EOM>': 9,\n",
    "            '<EOTM>': 10,\n",
    "            '<CR>': 11,\n",
    "        }\n",
    "        for tokens in token_list:\n",
    "            for token in tokens:\n",
    "                if token not in token_dict:\n",
    "                    token_dict[token] = len(token_dict)\n",
    "        return token_dict\n",
    " \n",
    "    def test_translate(self):\n",
    "        print(\"i am here: \" )\n",
    "        source_tokens = []\n",
    "        target_errors=[]\n",
    "        target_LB=[]\n",
    "        #source_file=[]\n",
    "        \n",
    "        Input_Path = \"D:\\Code\\Project-AI-JAVA-ANNOTATION-2021\\Performer\\Perfomer_local\\Trianing\\InputTxt\"\n",
    "        Location_Output_Path = \"D:\\Code\\Project-AI-JAVA-ANNOTATION-2021\\Performer\\Perfomer_local\\Trianing\\InputCSV\"\n",
    "        '''\n",
    "        Input_Path = \"Performer/Perfomer_local/Trianing/InputTxt\"\n",
    "        Location_Output_Path = \"Performer/Perfomer_local/Trianing/InputCSV\"\n",
    "        '''\n",
    " \n",
    "        InputFiles = sorted(listdir(Input_Path))\n",
    "        OutputFiles = sorted(listdir(Location_Output_Path))\n",
    "        #max_files =10\n",
    "        for f in InputFiles:\n",
    "          fullpath = join(Input_Path,f)\n",
    "          #source_file=fullpath\n",
    "          if isfile(fullpath):\n",
    "            source_tokens.append(parseSentence(readcode(fullpath)))\n",
    "            #if len(source_tokens)>max_files: break\n",
    "        for f in OutputFiles:\n",
    "          fullpath = join(Location_Output_Path,f)\n",
    "          #source_file=fullpath\n",
    "          if isfile(fullpath):\n",
    "            err,lb = readCSV(fullpath)\n",
    "            target_errors.append(err)\n",
    "            target_LB.append(lb)\n",
    "            #if len(source_tokens)>max_files: break\n",
    "        dd=np.asarray(target_errors)\n",
    "        print(\"AAAA: \", dd.shape)\n",
    "        print(\"aaaa: \" , type(target_errors[0][0]))\n",
    "        target_errors=target_errors[0]  \n",
    "        target_LB=target_LB[0]     \n",
    "        print(\"XXXX: \" , len(source_tokens))\n",
    "        print(\"YYYY: \" , type(target_errors[0][0]))\n",
    "        print(\"ZZZZ: \" , len(target_LB))\n",
    "\n",
    " \n",
    "        source_tokens2 = []\n",
    "        target_errors2= []\n",
    "        target_LB2=[]\n",
    "\n",
    "        THRESHOLD_FILE_LEN = 64000000\n",
    " \n",
    "        for i in range(len(source_tokens)): \n",
    "          #print (i)\n",
    "          src = source_tokens[i]\n",
    "          err = target_errors[i]   \n",
    "          lb = target_LB[i]                   \n",
    "          if (len(src)<=THRESHOLD_FILE_LEN):\n",
    "            source_tokens2.append(src)\n",
    "            target_errors2.append(err)\n",
    "            target_LB2.append(lb) \n",
    "        source_tokens = source_tokens2\n",
    "        target_errors= target_errors2        \n",
    "        target_LB= target_LB2        \n",
    "\n",
    "        print(\"XXXX2: \" , len(source_tokens))\n",
    "                    \n",
    " \n",
    "        # Generate dictionaries\n",
    "        source_token_dict = self._build_token_dict(source_tokens)\n",
    "        \n",
    " \n",
    "        # Add special tokens\n",
    "        encode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
    "        \n",
    "        #output_tokens = [tokens + ['<END>', '<PAD>'] for tokens in target_tokens]\n",
    " \n",
    "        # Padding\n",
    "        self.sl = max(map(len, encode_tokens))\n",
    "        \n",
    "        source_max_len = self.sl\n",
    "        \n",
    " \n",
    "        encode_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encode_tokens]\n",
    "        \n",
    "        \n",
    " \n",
    "        encode_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encode_tokens]\n",
    "       \n",
    "        \n",
    "        #print(\"encode_input:\", encode_input)\n",
    "        \n",
    "        #print(\"len(source_token_dict):\", len(source_token_dict))\n",
    "        \n",
    "        \n",
    "        #decode_output_one_hot_encoded = to_categorical(decode_output)\n",
    "        #print(\"one-hot-decode_output:\", decode_output_one_hot_encoded)\n",
    "        #decode_output =  list(decode_output_one_hot_encoded)\n",
    "        token_num =len(source_token_dict)\n",
    "        print(type(token_num))\n",
    "        #Build & fit model\n",
    "        #Set model para    \n",
    "        model = tfr.get_model(\n",
    "            max_input_len= (source_max_len),\n",
    "            errNum=36,\n",
    "            lbNum=192,\n",
    "            token_num=len(source_token_dict),\n",
    "            embed_dim=32, #32,\n",
    "            encoder_num=4, #2 max = 6\n",
    "            head_num=2,#4\n",
    "            hidden_dim=64, #128\n",
    "            dropout_rate=0.05 #0.05\n",
    "        )\n",
    "        \n",
    "        losses = {    \n",
    "            \"error_feed_forward_output1\": \"binary_crossentropy\",\n",
    "            \"error_feed_forward_output2\": \"mean_squared_error\",            \n",
    "        }\n",
    "        \n",
    "        lossWeights = {\"error_feed_forward_output1\": 1.0,\"error_feed_forward_output2\": 1.0}\n",
    "        \n",
    "        #==================learning rate ed==================\n",
    "        import tensorflow as tf\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.00001) #can change learning rate more lower default rate = 0.001\n",
    "        model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights)\n",
    "        #==================learning rate ed==================\n",
    "        \n",
    "        #==================default ed==================\n",
    "        #model.compile('adam', loss=losses, loss_weights=lossWeights)\n",
    "        #==================default ed==================\n",
    "        print(\"x.shape\", np.asarray(encode_input).shape)  #x.shape (2,  9)\n",
    "        \n",
    " \n",
    "        #x=[np.array(encode_input * 1)]\n",
    "        #y=[np.array(target_errors * 1),np.array(target_LB * 1)]\n",
    "       \n",
    "        #print(\"x.shape\", np.asarray(x).shape)  #x.shape (2, 2048, 9)\n",
    "        \n",
    "        ####  Split the data set into train and test_model\n",
    "        x=np.array(encode_input)\n",
    "        y=list(zip(np.array(target_errors), np.array(target_LB)))\n",
    "\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "        y_train = list(zip(*y_train))\n",
    "        y_train[0] = np.array(y_train[0])\n",
    "        y_train[1] = np.array(y_train[1])\n",
    "\n",
    "        \n",
    "        y_test = list(zip(*y_test))\n",
    "        y_test[0] = np.array(y_test[0])\n",
    "        y_test[1] = np.array(y_test[1])\n",
    "               \n",
    "        \n",
    "        saveTestTrainData(\"train_models/x_train_500.npy\", x_train)\n",
    "        saveTestTrainData(\"test_models/x_test_500.npy\", x_test)\n",
    "        saveTestTrainData(\"train_models/y_train0_500.npy\", y_train[0])#target\n",
    "        saveTestTrainData(\"train_models/y_train1_500.npy\", y_train[1])#lb\n",
    "        saveTestTrainData(\"test_models/y_test0_500.npy\", y_test[0])\n",
    "        saveTestTrainData(\"test_models/y_test1_500.npy\", y_test[1])\n",
    "    \n",
    "        ####\n",
    "        #if you only need to train model don't use this\n",
    "        \n",
    "        model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            epochs=200, #100 200 500\n",
    "            batch_size=32,\n",
    "        )\n",
    "        \n",
    "        #save model\n",
    "        #===============tf version===============\n",
    "        #filepath = \"/models\"\n",
    "        #import tensorflow as tf\n",
    "        #tf.keras.models.save_model(model,filepath,save_format='h5')\n",
    "        #===============tf version===============\n",
    "        \n",
    "        #==============kerasversion==============\n",
    "        #origin ed\n",
    "        model.save(\"test_model1.h5\")  #set model name and path\n",
    "        saveDictionary(source_token_dict, 'source_token_dict.pickle') #save dic\n",
    "        #==============kerasversion==============\n",
    "        \n",
    "        model, source_token_dict = load(\"test_model1.h5\")\n",
    "\n",
    "        # Predict\n",
    "        x_train_loaded = loadTestTrainData(\"train_models/x_train_500.npy\") \n",
    "        y_train_loaded = [  loadTestTrainData(\"train_models/y_train0_500.npy\"),\n",
    "                          loadTestTrainData(\"train_models/y_train1_500.npy\") ]\n",
    "\n",
    "        x_test_loaded =  loadTestTrainData(\"test_models/x_test_500.npy\") \n",
    "        y_test_loaded = [ loadTestTrainData(\"test_models/y_test0_500.npy\"),\n",
    "                         loadTestTrainData(\"test_models/y_test1_500.npy\")]\n",
    "        \n",
    "        out1, out2 = tfr.decode(\n",
    "            model,\n",
    "            #encode_input,\n",
    "            x_test_loaded,max_len=source_max_len\n",
    "        )\n",
    "        '''\n",
    "        print(\"out1: \", out1)\n",
    "        #print(\"target_errors: \",target_errors) \n",
    "        print(\"target_errors: \", y_test_loaded[0])        \n",
    "        print(\"out2: \", out2)\n",
    "        #print(\"target_LB: \", target_LB)\n",
    "        print(\"target_LB: \", y_test_loaded[1])\n",
    "        '''\n",
    "        \n",
    "    def getsource_max_lan(self):\n",
    "        return self.sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDictionary(dt, file):\n",
    "        import pickle\n",
    "        a_file = open(file, \"wb\")\n",
    "        pickle.dump(dt, a_file)\n",
    "        a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDictionary(file):\n",
    "        import pickle\n",
    "        a_file = open(file, \"rb\")\n",
    "        dt = pickle.load(a_file)\n",
    "        return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTestTrainData(filename, data): # e.g., 'test.npy'\n",
    "    with open(filename, 'wb') as f:\n",
    "        np.save(f, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestTrainData(filename): # e.g., 'test.npy'    \n",
    "    with open(filename, 'rb') as f:\n",
    "        a = np.load(f)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(model_name):\n",
    "        import sys\n",
    "        sys.path.append('Perfomer_local/keras_position_wise_feed_forward')\n",
    "        sys.path.append('Perfomer_local/tensorflow_fast_attention')\n",
    "        sys.path.append('Perfomer_local/keras_performer')\n",
    "        #sys.path.append('/Perfomer_local/keras_pos_embed')\n",
    "\n",
    "        from keras_performer import performer\n",
    "        from tensorflow import keras\n",
    "        from keras_embed_sim import EmbeddingRet, EmbeddingSim\n",
    "        from keras_pos_embd import TrigPosEmbedding\n",
    "        from tensorflow_fast_attention.fast_attention import  Attention, SelfAttention\n",
    "        from keras_position_wise_feed_forward.feed_forward import FeedForward  \n",
    "\n",
    "        co = performer.get_custom_objects()\n",
    "\n",
    "        model = keras.models.load_model(model_name, custom_objects= co)\n",
    "        source_token_dict = loadDictionary('source_token_dict.pickle')\n",
    "       # t = loadDictionary(target_token_dict, 'target_token_dict.pickle')\n",
    "       # t_inv = loadDictionary(target_token_dict_inv, 'target_token_dict_inv.pickle')\n",
    "        return model, source_token_dict,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am here: \n",
      "AAAA:  (1, 359, 36)\n",
      "aaaa:  <class 'list'>\n",
      "XXXX:  359\n",
      "YYYY:  <class 'int'>\n",
      "ZZZZ:  359\n",
      "XXXX2:  359\n",
      "<class 'int'>\n",
      "In get_model: encoder_input:  (None, 2919)\n",
      "In get_model: encoder_embed:  (None, 2919, 32)\n",
      "Start Warpping................................\n",
      "OOOO: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-Embedding/add_1:0', description=\"created by layer 'Encoder-Embedding'\")\n",
      "embed_dim: 32\n",
      "head_num: 2\n",
      "dropout_rate: 0.05\n",
      "masked: False\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"self_attention_17/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "Start Warpping................................\n",
      "Start Warpping................................\n",
      "OOOO: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-1-FeedForward-Norm/add_1:0', description=\"created by layer 'Encoder-1-FeedForward-Norm'\")\n",
      "embed_dim: 32\n",
      "head_num: 2\n",
      "dropout_rate: 0.05\n",
      "masked: False\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"self_attention_19/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "Start Warpping................................\n",
      "Start Warpping................................\n",
      "OOOO: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-2-FeedForward-Norm/add_1:0', description=\"created by layer 'Encoder-2-FeedForward-Norm'\")\n",
      "embed_dim: 32\n",
      "head_num: 2\n",
      "dropout_rate: 0.05\n",
      "masked: False\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"self_attention_21/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "Start Warpping................................\n",
      "Start Warpping................................\n",
      "OOOO: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-3-FeedForward-Norm/add_1:0', description=\"created by layer 'Encoder-3-FeedForward-Norm'\")\n",
      "embed_dim: 32\n",
      "head_num: 2\n",
      "dropout_rate: 0.05\n",
      "masked: False\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"self_attention_23/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "Start Warpping................................\n",
      "encoded_layer: KerasTensor(type_spec=TensorSpec(shape=(None, 2919, 32), dtype=tf.float32, name=None), name='Encoder-4-FeedForward-Norm/add_1:0', description=\"created by layer 'Encoder-4-FeedForward-Norm'\")\n",
      "encoded_layer shape: (None, 2919, 32)\n",
      "max_input_len, embed_dim: 2919 32\n",
      "flatten_state: (None, 93408)\n",
      "flatten_state: (None, 93408)\n",
      "error_feed_forward_output1: (None, 36)\n",
      "error_feed_forward_output2: (None, 192)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder-Input (InputLayer)      [(None, 2919)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Token-Embedding (EmbeddingRet)  [(None, 2919, 32), ( 46816       Encoder-Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-Embedding (TrigPosEmbed (None, 2919, 32)     0           Token-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_17 (SelfAttentio (None, 2919, 32)     4096        Encoder-Embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 2919, 32)     0           self_attention_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 2919, 32)     0           Encoder-Embedding[0][0]          \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 2919, 32)     64          Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 2919, 32)     4192        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 2919, 32)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 2919, 32)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 2919, 32)     64          Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_19 (SelfAttentio (None, 2919, 32)     4096        Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 2919, 32)     0           self_attention_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 2919, 32)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 2919, 32)     64          Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 2919, 32)     4192        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 2919, 32)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 2919, 32)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 2919, 32)     64          Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_21 (SelfAttentio (None, 2919, 32)     4096        Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 2919, 32)     0           self_attention_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 2919, 32)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 2919, 32)     64          Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 2919, 32)     4192        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 2919, 32)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 2919, 32)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 2919, 32)     64          Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_23 (SelfAttentio (None, 2919, 32)     4096        Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 2919, 32)     0           self_attention_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 2919, 32)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 2919, 32)     64          Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 2919, 32)     4192        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 2919, 32)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 2919, 32)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 2919, 32)     64          Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 93408)        0           Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           5978176     reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "error_feed_forward_output1 (Den (None, 36)           2340        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 93444)        0           error_feed_forward_output1[0][0] \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           5980480     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "error_feed_forward_output2 (Den (None, 192)          12480       dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,053,956\n",
      "Trainable params: 12,053,956\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (359, 2919)\n",
      "Epoch 1/200\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"model_2/self_attention_17/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"model_2/self_attention_19/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"model_2/self_attention_21/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"model_2/self_attention_23/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"model_2/self_attention_17/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"model_2/self_attention_19/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"model_2/self_attention_21/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "dim:  16\n",
      "query:  Tensor(\"model_2/self_attention_23/query/einsum/Einsum:0\", shape=(None, 2919, 2, 16), dtype=float32)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "11/11 [==============================] - 7s 70ms/step - loss: 50.7368 - error_feed_forward_output1_loss: 0.7100 - error_feed_forward_output2_loss: 50.0268\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 46.7312 - error_feed_forward_output1_loss: 0.5441 - error_feed_forward_output2_loss: 46.1870\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.3649 - error_feed_forward_output1_loss: 0.5280 - error_feed_forward_output2_loss: 41.8369\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 39.2255 - error_feed_forward_output1_loss: 0.5105 - error_feed_forward_output2_loss: 38.7151\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 41.7692 - error_feed_forward_output1_loss: 0.4906 - error_feed_forward_output2_loss: 41.2786\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 41.0352 - error_feed_forward_output1_loss: 0.4843 - error_feed_forward_output2_loss: 40.5509\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 46.4787 - error_feed_forward_output1_loss: 0.4824 - error_feed_forward_output2_loss: 45.9963\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 48.0435 - error_feed_forward_output1_loss: 0.4893 - error_feed_forward_output2_loss: 47.5543\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 47.0522 - error_feed_forward_output1_loss: 0.4784 - error_feed_forward_output2_loss: 46.5738\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.4289 - error_feed_forward_output1_loss: 0.4743 - error_feed_forward_output2_loss: 41.9545\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 44.1113 - error_feed_forward_output1_loss: 0.4689 - error_feed_forward_output2_loss: 43.6425\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 44.8505 - error_feed_forward_output1_loss: 0.4737 - error_feed_forward_output2_loss: 44.3768\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 36.1932 - error_feed_forward_output1_loss: 0.4588 - error_feed_forward_output2_loss: 35.7344\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 43.9601 - error_feed_forward_output1_loss: 0.4579 - error_feed_forward_output2_loss: 43.5022\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 44.7076 - error_feed_forward_output1_loss: 0.4641 - error_feed_forward_output2_loss: 44.2435\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 45.2621 - error_feed_forward_output1_loss: 0.4626 - error_feed_forward_output2_loss: 44.7995\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.7698 - error_feed_forward_output1_loss: 0.4564 - error_feed_forward_output2_loss: 39.3134\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 47.9661 - error_feed_forward_output1_loss: 0.4550 - error_feed_forward_output2_loss: 47.5112\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.9863 - error_feed_forward_output1_loss: 0.4560 - error_feed_forward_output2_loss: 38.5303\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 48.9332 - error_feed_forward_output1_loss: 0.4535 - error_feed_forward_output2_loss: 48.4797\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 39.9073 - error_feed_forward_output1_loss: 0.4529 - error_feed_forward_output2_loss: 39.4545\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.9691 - error_feed_forward_output1_loss: 0.4458 - error_feed_forward_output2_loss: 38.5234\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 41.2316 - error_feed_forward_output1_loss: 0.4379 - error_feed_forward_output2_loss: 40.7937\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 36.9357 - error_feed_forward_output1_loss: 0.4346 - error_feed_forward_output2_loss: 36.5011\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 41.0633 - error_feed_forward_output1_loss: 0.4404 - error_feed_forward_output2_loss: 40.6229\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 41.2984 - error_feed_forward_output1_loss: 0.4466 - error_feed_forward_output2_loss: 40.8518\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 71ms/step - loss: 45.7425 - error_feed_forward_output1_loss: 0.4326 - error_feed_forward_output2_loss: 45.3099\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 44.7220 - error_feed_forward_output1_loss: 0.4295 - error_feed_forward_output2_loss: 44.2925\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 41.4232 - error_feed_forward_output1_loss: 0.4286 - error_feed_forward_output2_loss: 40.9946\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 46.1722 - error_feed_forward_output1_loss: 0.4287 - error_feed_forward_output2_loss: 45.7435\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 43.0318 - error_feed_forward_output1_loss: 0.4160 - error_feed_forward_output2_loss: 42.6158\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 42.2199 - error_feed_forward_output1_loss: 0.4203 - error_feed_forward_output2_loss: 41.7996\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.5600 - error_feed_forward_output1_loss: 0.4165 - error_feed_forward_output2_loss: 40.1435\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 49.4364 - error_feed_forward_output1_loss: 0.4106 - error_feed_forward_output2_loss: 49.0257\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.9885 - error_feed_forward_output1_loss: 0.4049 - error_feed_forward_output2_loss: 39.5836\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.1995 - error_feed_forward_output1_loss: 0.4097 - error_feed_forward_output2_loss: 41.7897\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 43.5797 - error_feed_forward_output1_loss: 0.4033 - error_feed_forward_output2_loss: 43.1764\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 36.9359 - error_feed_forward_output1_loss: 0.4058 - error_feed_forward_output2_loss: 36.5302\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.5880 - error_feed_forward_output1_loss: 0.3975 - error_feed_forward_output2_loss: 39.1906\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.8332 - error_feed_forward_output1_loss: 0.4051 - error_feed_forward_output2_loss: 42.4281\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.3861 - error_feed_forward_output1_loss: 0.3976 - error_feed_forward_output2_loss: 38.9885\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.6164 - error_feed_forward_output1_loss: 0.3871 - error_feed_forward_output2_loss: 40.2292\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.1431 - error_feed_forward_output1_loss: 0.3834 - error_feed_forward_output2_loss: 41.7597\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.6851 - error_feed_forward_output1_loss: 0.3763 - error_feed_forward_output2_loss: 38.3089\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.3162 - error_feed_forward_output1_loss: 0.3875 - error_feed_forward_output2_loss: 39.9287\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.5086 - error_feed_forward_output1_loss: 0.3745 - error_feed_forward_output2_loss: 40.1341\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 36.4234 - error_feed_forward_output1_loss: 0.3777 - error_feed_forward_output2_loss: 36.0456\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 51.1798 - error_feed_forward_output1_loss: 0.3783 - error_feed_forward_output2_loss: 50.8015\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.5266 - error_feed_forward_output1_loss: 0.3716 - error_feed_forward_output2_loss: 42.1549\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 39.6337 - error_feed_forward_output1_loss: 0.3702 - error_feed_forward_output2_loss: 39.2636\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 41.4543 - error_feed_forward_output1_loss: 0.3613 - error_feed_forward_output2_loss: 41.0929\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 48.3286 - error_feed_forward_output1_loss: 0.3761 - error_feed_forward_output2_loss: 47.9525\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.4599 - error_feed_forward_output1_loss: 0.3654 - error_feed_forward_output2_loss: 40.0945\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.0243 - error_feed_forward_output1_loss: 0.3652 - error_feed_forward_output2_loss: 37.6591\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 43.7289 - error_feed_forward_output1_loss: 0.3558 - error_feed_forward_output2_loss: 43.3731\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 40.9451 - error_feed_forward_output1_loss: 0.3555 - error_feed_forward_output2_loss: 40.5896\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.5687 - error_feed_forward_output1_loss: 0.3464 - error_feed_forward_output2_loss: 38.2222\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 44.1135 - error_feed_forward_output1_loss: 0.3490 - error_feed_forward_output2_loss: 43.7645\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 40.3434 - error_feed_forward_output1_loss: 0.3323 - error_feed_forward_output2_loss: 40.0110\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 43.8508 - error_feed_forward_output1_loss: 0.3318 - error_feed_forward_output2_loss: 43.5190\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 42.1491 - error_feed_forward_output1_loss: 0.3422 - error_feed_forward_output2_loss: 41.8069\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 47.6924 - error_feed_forward_output1_loss: 0.3382 - error_feed_forward_output2_loss: 47.3542\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 40.3538 - error_feed_forward_output1_loss: 0.3357 - error_feed_forward_output2_loss: 40.0182\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 43.2353 - error_feed_forward_output1_loss: 0.3295 - error_feed_forward_output2_loss: 42.9058\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 45.6038 - error_feed_forward_output1_loss: 0.3239 - error_feed_forward_output2_loss: 45.2799\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 38.2665 - error_feed_forward_output1_loss: 0.3236 - error_feed_forward_output2_loss: 37.9429\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 44.3183 - error_feed_forward_output1_loss: 0.3289 - error_feed_forward_output2_loss: 43.9894\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 48.3924 - error_feed_forward_output1_loss: 0.3257 - error_feed_forward_output2_loss: 48.0667\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 40.4802 - error_feed_forward_output1_loss: 0.3154 - error_feed_forward_output2_loss: 40.1648\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 46.8684 - error_feed_forward_output1_loss: 0.3167 - error_feed_forward_output2_loss: 46.5517\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 40.1269 - error_feed_forward_output1_loss: 0.3105 - error_feed_forward_output2_loss: 39.8165\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 41.6574 - error_feed_forward_output1_loss: 0.3034 - error_feed_forward_output2_loss: 41.3541\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 34.6336 - error_feed_forward_output1_loss: 0.3031 - error_feed_forward_output2_loss: 34.3305\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 37.7571 - error_feed_forward_output1_loss: 0.3019 - error_feed_forward_output2_loss: 37.4552\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 71ms/step - loss: 37.9125 - error_feed_forward_output1_loss: 0.2954 - error_feed_forward_output2_loss: 37.6171\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 42.5518 - error_feed_forward_output1_loss: 0.3086 - error_feed_forward_output2_loss: 42.2432\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 40.8340 - error_feed_forward_output1_loss: 0.2910 - error_feed_forward_output2_loss: 40.5430\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 46.9670 - error_feed_forward_output1_loss: 0.2924 - error_feed_forward_output2_loss: 46.6746\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 42.0341 - error_feed_forward_output1_loss: 0.2896 - error_feed_forward_output2_loss: 41.7445\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 38.7352 - error_feed_forward_output1_loss: 0.2869 - error_feed_forward_output2_loss: 38.4483\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 45.1990 - error_feed_forward_output1_loss: 0.2828 - error_feed_forward_output2_loss: 44.9162\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 45.9030 - error_feed_forward_output1_loss: 0.2985 - error_feed_forward_output2_loss: 45.6045\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 45.5974 - error_feed_forward_output1_loss: 0.2918 - error_feed_forward_output2_loss: 45.3056\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 45.9164 - error_feed_forward_output1_loss: 0.2847 - error_feed_forward_output2_loss: 45.6316\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 43.5453 - error_feed_forward_output1_loss: 0.2727 - error_feed_forward_output2_loss: 43.2726\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 36.3663 - error_feed_forward_output1_loss: 0.2759 - error_feed_forward_output2_loss: 36.0904\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.9143 - error_feed_forward_output1_loss: 0.2774 - error_feed_forward_output2_loss: 39.6369\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 44.4494 - error_feed_forward_output1_loss: 0.2770 - error_feed_forward_output2_loss: 44.1724\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 37.1426 - error_feed_forward_output1_loss: 0.2591 - error_feed_forward_output2_loss: 36.8835\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.0103 - error_feed_forward_output1_loss: 0.2806 - error_feed_forward_output2_loss: 37.7296\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.0028 - error_feed_forward_output1_loss: 0.2721 - error_feed_forward_output2_loss: 38.7307\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 41.1169 - error_feed_forward_output1_loss: 0.2671 - error_feed_forward_output2_loss: 40.8498\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 37.9555 - error_feed_forward_output1_loss: 0.2667 - error_feed_forward_output2_loss: 37.6888\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 37.6921 - error_feed_forward_output1_loss: 0.2638 - error_feed_forward_output2_loss: 37.4283\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 42.2633 - error_feed_forward_output1_loss: 0.2701 - error_feed_forward_output2_loss: 41.9932\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 41.7110 - error_feed_forward_output1_loss: 0.2661 - error_feed_forward_output2_loss: 41.4449\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 43.2713 - error_feed_forward_output1_loss: 0.2645 - error_feed_forward_output2_loss: 43.0068\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 44.1101 - error_feed_forward_output1_loss: 0.2717 - error_feed_forward_output2_loss: 43.8383\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 49.7541 - error_feed_forward_output1_loss: 0.2743 - error_feed_forward_output2_loss: 49.4798\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.2514 - error_feed_forward_output1_loss: 0.2641 - error_feed_forward_output2_loss: 39.9873\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 36.2088 - error_feed_forward_output1_loss: 0.2469 - error_feed_forward_output2_loss: 35.9618\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 46.5684 - error_feed_forward_output1_loss: 0.2545 - error_feed_forward_output2_loss: 46.3138\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.5466 - error_feed_forward_output1_loss: 0.2616 - error_feed_forward_output2_loss: 42.2850\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 37.2098 - error_feed_forward_output1_loss: 0.2519 - error_feed_forward_output2_loss: 36.9579\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 34.7213 - error_feed_forward_output1_loss: 0.2476 - error_feed_forward_output2_loss: 34.4737\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 46.0577 - error_feed_forward_output1_loss: 0.2578 - error_feed_forward_output2_loss: 45.7998\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 37.8646 - error_feed_forward_output1_loss: 0.2450 - error_feed_forward_output2_loss: 37.6197\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 47.4805 - error_feed_forward_output1_loss: 0.2534 - error_feed_forward_output2_loss: 47.2271\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 39.1060 - error_feed_forward_output1_loss: 0.2480 - error_feed_forward_output2_loss: 38.8580\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 39.9068 - error_feed_forward_output1_loss: 0.2407 - error_feed_forward_output2_loss: 39.6661\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 39.9349 - error_feed_forward_output1_loss: 0.2392 - error_feed_forward_output2_loss: 39.6956\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 37.7440 - error_feed_forward_output1_loss: 0.2326 - error_feed_forward_output2_loss: 37.5114\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.9865 - error_feed_forward_output1_loss: 0.2396 - error_feed_forward_output2_loss: 42.7469\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.4184 - error_feed_forward_output1_loss: 0.2467 - error_feed_forward_output2_loss: 40.1718\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 38.0771 - error_feed_forward_output1_loss: 0.2335 - error_feed_forward_output2_loss: 37.8436\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.5308 - error_feed_forward_output1_loss: 0.2382 - error_feed_forward_output2_loss: 40.2926\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 37.5581 - error_feed_forward_output1_loss: 0.2294 - error_feed_forward_output2_loss: 37.3287\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 46.5073 - error_feed_forward_output1_loss: 0.2398 - error_feed_forward_output2_loss: 46.2675\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.0071 - error_feed_forward_output1_loss: 0.2390 - error_feed_forward_output2_loss: 41.7682\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.7059 - error_feed_forward_output1_loss: 0.2285 - error_feed_forward_output2_loss: 39.4774\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 38.6613 - error_feed_forward_output1_loss: 0.2258 - error_feed_forward_output2_loss: 38.4356\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 45.8253 - error_feed_forward_output1_loss: 0.2280 - error_feed_forward_output2_loss: 45.5974\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 70ms/step - loss: 40.3461 - error_feed_forward_output1_loss: 0.2294 - error_feed_forward_output2_loss: 40.1167\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 38.0092 - error_feed_forward_output1_loss: 0.2271 - error_feed_forward_output2_loss: 37.7821\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 38.4437 - error_feed_forward_output1_loss: 0.2296 - error_feed_forward_output2_loss: 38.2141\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 35.8617 - error_feed_forward_output1_loss: 0.2230 - error_feed_forward_output2_loss: 35.6387\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 38.5653 - error_feed_forward_output1_loss: 0.2292 - error_feed_forward_output2_loss: 38.3361\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 43.1780 - error_feed_forward_output1_loss: 0.2253 - error_feed_forward_output2_loss: 42.9526\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 34.9222 - error_feed_forward_output1_loss: 0.2255 - error_feed_forward_output2_loss: 34.6966\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 43.6424 - error_feed_forward_output1_loss: 0.2363 - error_feed_forward_output2_loss: 43.4061\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 40.1534 - error_feed_forward_output1_loss: 0.2171 - error_feed_forward_output2_loss: 39.9364\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 43.1710 - error_feed_forward_output1_loss: 0.2266 - error_feed_forward_output2_loss: 42.9444\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.1630 - error_feed_forward_output1_loss: 0.2246 - error_feed_forward_output2_loss: 37.9383\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 46.1074 - error_feed_forward_output1_loss: 0.2146 - error_feed_forward_output2_loss: 45.8929\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 37.9593 - error_feed_forward_output1_loss: 0.2327 - error_feed_forward_output2_loss: 37.7266\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.7565 - error_feed_forward_output1_loss: 0.2194 - error_feed_forward_output2_loss: 38.5371\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 34.6809 - error_feed_forward_output1_loss: 0.2219 - error_feed_forward_output2_loss: 34.4589\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 44.3925 - error_feed_forward_output1_loss: 0.2288 - error_feed_forward_output2_loss: 44.1638\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 35.8300 - error_feed_forward_output1_loss: 0.2147 - error_feed_forward_output2_loss: 35.6153\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 44.5932 - error_feed_forward_output1_loss: 0.2284 - error_feed_forward_output2_loss: 44.3648\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 36.6859 - error_feed_forward_output1_loss: 0.2174 - error_feed_forward_output2_loss: 36.4684\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 45.2957 - error_feed_forward_output1_loss: 0.2169 - error_feed_forward_output2_loss: 45.0788\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 40.7230 - error_feed_forward_output1_loss: 0.2132 - error_feed_forward_output2_loss: 40.5098\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 37.4343 - error_feed_forward_output1_loss: 0.2132 - error_feed_forward_output2_loss: 37.2211\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.0103 - error_feed_forward_output1_loss: 0.2148 - error_feed_forward_output2_loss: 38.7955\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 39.5068 - error_feed_forward_output1_loss: 0.2129 - error_feed_forward_output2_loss: 39.2939\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 42.0221 - error_feed_forward_output1_loss: 0.2187 - error_feed_forward_output2_loss: 41.8034\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 44.4054 - error_feed_forward_output1_loss: 0.2228 - error_feed_forward_output2_loss: 44.1826\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 40.7635 - error_feed_forward_output1_loss: 0.2089 - error_feed_forward_output2_loss: 40.5547\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.2959 - error_feed_forward_output1_loss: 0.2183 - error_feed_forward_output2_loss: 38.0776\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.1664 - error_feed_forward_output1_loss: 0.2140 - error_feed_forward_output2_loss: 37.9524\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 39.9603 - error_feed_forward_output1_loss: 0.2032 - error_feed_forward_output2_loss: 39.7571\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 39.1619 - error_feed_forward_output1_loss: 0.2139 - error_feed_forward_output2_loss: 38.9481\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 38.3362 - error_feed_forward_output1_loss: 0.2086 - error_feed_forward_output2_loss: 38.1276\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 44.6221 - error_feed_forward_output1_loss: 0.2110 - error_feed_forward_output2_loss: 44.4111\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 37.1669 - error_feed_forward_output1_loss: 0.2019 - error_feed_forward_output2_loss: 36.9650\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 45.6004 - error_feed_forward_output1_loss: 0.2109 - error_feed_forward_output2_loss: 45.3894\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 34.4298 - error_feed_forward_output1_loss: 0.1911 - error_feed_forward_output2_loss: 34.2387\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 32.2848 - error_feed_forward_output1_loss: 0.1986 - error_feed_forward_output2_loss: 32.0862\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 39.4252 - error_feed_forward_output1_loss: 0.2106 - error_feed_forward_output2_loss: 39.2146\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 44.8603 - error_feed_forward_output1_loss: 0.2195 - error_feed_forward_output2_loss: 44.6407\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 35.7975 - error_feed_forward_output1_loss: 0.2107 - error_feed_forward_output2_loss: 35.5869\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 42.7879 - error_feed_forward_output1_loss: 0.2054 - error_feed_forward_output2_loss: 42.5825\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 40.4382 - error_feed_forward_output1_loss: 0.2059 - error_feed_forward_output2_loss: 40.2323\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 42.5381 - error_feed_forward_output1_loss: 0.2113 - error_feed_forward_output2_loss: 42.3268\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 41.3054 - error_feed_forward_output1_loss: 0.2070 - error_feed_forward_output2_loss: 41.0985\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 36.4151 - error_feed_forward_output1_loss: 0.2002 - error_feed_forward_output2_loss: 36.2149\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 38.2416 - error_feed_forward_output1_loss: 0.2083 - error_feed_forward_output2_loss: 38.0334\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 40.3005 - error_feed_forward_output1_loss: 0.1976 - error_feed_forward_output2_loss: 40.1029\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 36.8669 - error_feed_forward_output1_loss: 0.2045 - error_feed_forward_output2_loss: 36.6624\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 69ms/step - loss: 39.9351 - error_feed_forward_output1_loss: 0.2016 - error_feed_forward_output2_loss: 39.7336\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 44.7534 - error_feed_forward_output1_loss: 0.2142 - error_feed_forward_output2_loss: 44.5392\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 41.0101 - error_feed_forward_output1_loss: 0.2068 - error_feed_forward_output2_loss: 40.8033\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 42.1159 - error_feed_forward_output1_loss: 0.1951 - error_feed_forward_output2_loss: 41.9208\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 37.9997 - error_feed_forward_output1_loss: 0.1992 - error_feed_forward_output2_loss: 37.8005\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 36.3509 - error_feed_forward_output1_loss: 0.2073 - error_feed_forward_output2_loss: 36.1436\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 30.7871 - error_feed_forward_output1_loss: 0.2041 - error_feed_forward_output2_loss: 30.5830\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 42.2990 - error_feed_forward_output1_loss: 0.2059 - error_feed_forward_output2_loss: 42.0931\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 36.5539 - error_feed_forward_output1_loss: 0.1979 - error_feed_forward_output2_loss: 36.3560\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 43.7357 - error_feed_forward_output1_loss: 0.2058 - error_feed_forward_output2_loss: 43.5299\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 37.4505 - error_feed_forward_output1_loss: 0.2052 - error_feed_forward_output2_loss: 37.2453\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 38.3234 - error_feed_forward_output1_loss: 0.2010 - error_feed_forward_output2_loss: 38.1224\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 35.3196 - error_feed_forward_output1_loss: 0.2030 - error_feed_forward_output2_loss: 35.1166\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 41.4378 - error_feed_forward_output1_loss: 0.1973 - error_feed_forward_output2_loss: 41.2406\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 38.7110 - error_feed_forward_output1_loss: 0.2067 - error_feed_forward_output2_loss: 38.5043\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 32.8724 - error_feed_forward_output1_loss: 0.1974 - error_feed_forward_output2_loss: 32.6750\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 35.1628 - error_feed_forward_output1_loss: 0.2003 - error_feed_forward_output2_loss: 34.9625\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 36.7807 - error_feed_forward_output1_loss: 0.2014 - error_feed_forward_output2_loss: 36.5793\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 40.2714 - error_feed_forward_output1_loss: 0.1918 - error_feed_forward_output2_loss: 40.0795\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 40.9140 - error_feed_forward_output1_loss: 0.2021 - error_feed_forward_output2_loss: 40.7119\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 40.2017 - error_feed_forward_output1_loss: 0.2073 - error_feed_forward_output2_loss: 39.9944\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 41.5666 - error_feed_forward_output1_loss: 0.2073 - error_feed_forward_output2_loss: 41.3592\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 43.8988 - error_feed_forward_output1_loss: 0.2006 - error_feed_forward_output2_loss: 43.6982\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 34.3636 - error_feed_forward_output1_loss: 0.1876 - error_feed_forward_output2_loss: 34.1760\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 37.6750 - error_feed_forward_output1_loss: 0.1974 - error_feed_forward_output2_loss: 37.4776\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 34.2238 - error_feed_forward_output1_loss: 0.1981 - error_feed_forward_output2_loss: 34.0257\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 35.0074 - error_feed_forward_output1_loss: 0.1906 - error_feed_forward_output2_loss: 34.8168\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 35.4738 - error_feed_forward_output1_loss: 0.2013 - error_feed_forward_output2_loss: 35.2725\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 35.4933 - error_feed_forward_output1_loss: 0.1939 - error_feed_forward_output2_loss: 35.2994\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 37.1169 - error_feed_forward_output1_loss: 0.2015 - error_feed_forward_output2_loss: 36.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\W.R_Chen\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "out1.shape (36, 36)\n",
      "out2.shape (36, 192)\n"
     ]
    }
   ],
   "source": [
    "x=TestTranslate()\n",
    "x.test_translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "11/11 [==============================] - 1s 20ms/step - loss: 38.8978 - error_feed_forward_output1_loss: 0.1945 - error_feed_forward_output2_loss: 38.7033\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 47.2521 - error_feed_forward_output1_loss: 0.2340 - error_feed_forward_output2_loss: 47.0182\n",
      "train_loss:  [38.89784622192383, 0.194545716047287, 38.70330047607422]\n",
      "test_loss:  [47.25214767456055, 0.23397916555404663, 47.018165588378906]\n"
     ]
    }
   ],
   "source": [
    "#check loss\n",
    "testmodel = \"test_model1.h5\" #set model name\n",
    "model, source_token_dict = load(testmodel) #load model \n",
    "\n",
    "#load train models\n",
    "x_train_loaded = loadTestTrainData(\"train_models/x_train_500.npy\")\n",
    "y_train_loaded = [loadTestTrainData(\"train_models/y_train0_500.npy\"), loadTestTrainData(\"train_models/y_train1_500.npy\")] \n",
    "\n",
    "#load test models\n",
    "x_test_loaded = loadTestTrainData(\"test_models/x_test_500.npy\") \n",
    "y_test_loaded = [loadTestTrainData(\"test_models/y_test0_500.npy\"), loadTestTrainData(\"test_models/y_test1_500.npy\")] \n",
    "\n",
    "train_loss = model.evaluate(x_train_loaded, y_train_loaded)\n",
    "test_loss = model.evaluate(x_test_loaded, y_test_loaded)\n",
    "print(\"train_loss: \", train_loss)\n",
    "print(\"test_loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following funcs is make socre to model \n",
    "testmodel = \"test_model1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTestdata():\n",
    "    import numpy as np\n",
    "    #load model and dic ps. dic is not use\n",
    "    model, source_token_dict = load(testmodel)\n",
    "    #load\n",
    "    x_test_loaded = loadTestTrainData(\"test_models/x_test_500.npy\") \n",
    "    y_test_loaded = [ loadTestTrainData(\"test_models/y_test0_500.npy\"), loadTestTrainData(\"test_models/y_test1_500.npy\")] \n",
    "    out1, out2 = tfr.decode(model,x_test_loaded,max_len=x.getsource_max_lan()) \n",
    "    #==============show org result================\n",
    "    ''' <-------dust switch\n",
    "    print((y_test_loaded[0][1])) #Error_type #vs out1\n",
    "    print((y_test_loaded[1][1])) #Line_Block #vs out2\n",
    "    print((out1[1]))#prob upper then 0.5\n",
    "    print((out2[1]))#prob upper then 0.5\n",
    "    print(int(out2))#prob lb\n",
    "    #'''#\n",
    "    #=============================================\n",
    "    \n",
    "    #==============show toint result==============\n",
    "    #'''\n",
    "    test_ep = np.around(out1)\n",
    "    test_lb = np.around(out2)\n",
    "    ans_ep = np.around(y_test_loaded[0])\n",
    "    ans_lb = np.around(y_test_loaded[1])\n",
    "    print(test_ep[1])\n",
    "    print(test_lb[1])\n",
    "    print(ans_ep[1])\n",
    "    print(ans_lb[1])\n",
    "    #'''#\n",
    "    #=============================================\n",
    "    #scoreTest(test_ep,test_lb,ans_ep,ans_lb) #go to test the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "query_input: XXXXXXX  (None, 2919, 32)\n",
      "source_input: XXXXXXX  (None, 2919, 32)\n",
      "Query: XXXXXXX  (None, 2919, 2, 16)\n",
      "Key: XXXXXXX  (None, 2919, 2, 16)\n",
      "Value: XXXXXXX  (None, 2919, 2, 16)\n",
      "QS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "KS OOOOOOOOOOOOO <class 'tensorflow.python.framework.ops.Tensor'> (2919, None, 2, 16)\n",
      "out1.shape (36, 36)\n",
      "out2.shape (36, 192)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[20. 18.  0.  8.  5.  7.  0.  0.  0.  3.  0.  0.  0.  2.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 14. 12.  7.  7.\n",
      "  3.  6.  2.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  5.  7.  0.  0.  0.  3.  0.  1.\n",
      "  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  3.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  2.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[10 10 11 11 12 12 13 13 25 25 26 26 27 27 28 28 29 29 41 41 42 42 43 43\n",
      " 46 46 49 49  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "loadTestdata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
