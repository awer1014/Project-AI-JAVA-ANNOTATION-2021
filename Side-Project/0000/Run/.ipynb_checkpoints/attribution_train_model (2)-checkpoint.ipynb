{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "achZsSjjc6hw"
   },
   "source": [
    "# 安裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62WsE2_OblO2",
    "outputId": "b6780e6d-dbd0-4536-c6ed-1608cd94d5c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-pos-embd in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from keras-pos-embd) (1.21.5)\n",
      "Requirement already satisfied: keras-multi-head in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (0.29.0)\n",
      "Requirement already satisfied: keras-self-attention==0.51.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from keras-multi-head) (0.51.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from keras-self-attention==0.51.0->keras-multi-head) (1.21.5)\n",
      "Requirement already satisfied: keras-layer-normalization in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from keras-layer-normalization) (1.21.5)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from keras-position-wise-feed-forward) (1.21.5)\n",
      "Requirement already satisfied: keras-embed-sim in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from keras-embed-sim) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (3.10.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: alibi in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (0.6.5)\n",
      "Requirement already satisfied: attrs<22.0.0,>=19.2.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (21.4.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.1.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=0.20.2 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from alibi) (1.0.2)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from alibi) (3.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (4.64.0)\n",
      "Requirement already satisfied: scikit-image!=0.17.1,<0.20,>=0.14.2 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (0.19.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.7.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (4.18.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (1.21.5)\n",
      "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (1.3.5)\n",
      "Requirement already satisfied: Pillow<10.0,>=5.4.1 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from alibi) (9.1.1)\n",
      "Requirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (3.2.4)\n",
      "Requirement already satisfied: tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (2.8.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (3.10.0.2)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from alibi) (0.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from pandas<2.0.0,>=0.23.3->alibi) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2.0.4)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2021.11.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2.17.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2.6.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yolohsu\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn<1.1.0,>=0.20.2->alibi) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from scikit-learn<1.1.0,>=0.20.2->alibi) (1.1.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.7.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.6.1)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.4.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.9.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.0.15)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (58.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.6)\n",
      "Requirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from catalogue<2.1.0,>=2.0.6->spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.7.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from click<8.1.0->spacy[lookups]<4.0.0,>=2.0.0->alibi) (4.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from click<8.1.0->spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.4.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from pathy>=0.3.5->spacy[lookups]<4.0.0,>=2.0.0->alibi) (5.2.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.8.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.34.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.24.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.14.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.12)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.13.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (13.0.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.4.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from astunparse>=1.6.0->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.35.1)\n",
      "Requirement already satisfied: cached-property in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from h5py>=2.9.0->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.35.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow!=2.6.0,!=2.6.1,<2.9.0,>=2.0.0->alibi) (3.2.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.0.49)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.11.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yolohsu\\.conda\\envs\\tf11\\lib\\site-packages (from jinja2->spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-pos-embd\n",
    "!pip install keras-multi-head\n",
    "!pip install keras-layer-normalization\n",
    "!pip install keras-position-wise-feed-forward\n",
    "!pip install keras-embed-sim\n",
    "!pip install matplotlib\n",
    "!pip install alibi\n",
    "!pip install nvidia-ml-py3\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T3lB0BWKKEf"
   },
   "source": [
    "# #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKJ7DZipcBw4",
    "outputId": "c585973a-69b6-41a7-c295-41669d4631cd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#drive_path = 'C:/模型 ver. 2/encoder_num=4, decoder_num=4/embed_dim=' + Embed_Dim + '/head_num=' + Head_Num + '/learning_rate=' + Learning_Rate + '/lossWeights_1-' + LossWeights + '/'\n",
    "drive_path = 'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LHUD7liWc434"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_KERAS']= \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "twUnzwRtdBXN"
   },
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "import sys\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/Men-len-1000')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/甲班模型')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/performer')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/performer/keras_position_wise_feed_forward')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/performer/tensorflow_fast_attention')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/performer/keras_performer')\n",
    "from alibi.explainers import IntegratedGradients\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import pynvml\n",
    "from keras_performer import performer_ver_3 as tfr\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ftrZJUOjlJQC"
   },
   "outputs": [],
   "source": [
    "def saveTestTrainData(filename, data): # e.g., 'test.npy'\n",
    "  with open(filename, 'wb') as f:\n",
    "    np.save(f, data)\n",
    "\n",
    "def saveDictionary(dt, file):\n",
    "    import pickle\n",
    "    a_file = open(file, \"wb\")\n",
    "    pickle.dump(dt, a_file)\n",
    "    a_file.close()\n",
    "\n",
    "def loadDictionary(file):\n",
    "    import pickle\n",
    "    a_file = open(file, \"rb\")\n",
    "    dt = pickle.load(a_file)\n",
    "    return dt\n",
    "\n",
    "        \n",
    "def loadMaxLen(filename):     \n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        return lines\n",
    "    \n",
    "def plotTrainingLoss(history):\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right') \n",
    "    plt.show()\n",
    "\n",
    "def plotAttributionAcc(attr_mse_train):\n",
    "    plt.plot(attr_mse_train)\n",
    "    plt.title('model Attribution accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('loop')\n",
    "    plt.legend(['accuracy'], loc='upper left') \n",
    "    plt.show()\n",
    "def plotTrainingAcc(history):\n",
    "    plt.plot(history['sparse_categorical_accuracy'])\n",
    "    plt.plot(history['val_sparse_categorical_accuracy'])\n",
    "    plt.title('model Decoder-Output accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['accuracy', 'val_accuracy'], loc='upper left') \n",
    "    plt.show()\n",
    "    \n",
    "def loadTestTrainData(filename): # e.g., 'test.npy'    \n",
    "    with open(filename, 'rb') as f:\n",
    "        a = np.load(f, allow_pickle=True)\n",
    "        return a    \n",
    "def plotTrainingEFFOLoss(history):\n",
    "    plt.plot(history.history['error_feed_forward_output1_loss'])\n",
    "    plt.plot(history.history['val_error_feed_forward_output1_loss'])\n",
    "    plt.title('model error_feed_forward_output1 loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right') \n",
    "    plt.show()\n",
    "    \n",
    "def plotTrainingDOLoss(history):\n",
    "    plt.plot(history.history['Decoder-Output_loss'])\n",
    "    plt.plot(history.history['val_Decoder-Output_loss'])\n",
    "    plt.title('model Decoder-Output loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right') \n",
    "    plt.show()\n",
    "    \n",
    "def plotTrainingEFFOBinAcc(history):\n",
    "    plt.plot(history.history['error_feed_forward_output1_binary_accuracy'])\n",
    "    plt.plot(history.history['val_error_feed_forward_output1_binary_accuracy'])\n",
    "    plt.title('model error_feed_forward_output1 binary_accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['accuracy', 'val_accuracy'], loc='upper left') \n",
    "    plt.show()\n",
    "    \n",
    "def plotTrainingDOAcc(history):\n",
    "    plt.plot(history.history['Decoder-Output_sparse_categorical_accuracy'])\n",
    "    plt.plot(history.history['val_Decoder-Output_sparse_categorical_accuracy'])\n",
    "    plt.title('model Decoder-Output accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['accuracy', 'val_accuracy'], loc='upper left') \n",
    "    plt.show()\n",
    "    \n",
    "def myAcc(y_true, y_pred):#not necessarily used\n",
    "    global p_msg\n",
    "    tf.config.run_functions_eagerly(True) \n",
    "    #tf.print(\"y_true:\", y_true, output_stream=sys.stderr)\n",
    "    #tf.print(\"y_pred:\", y_pred, output_stream=sys.stderr)\n",
    "    #t_msg = y_true.numpy().tolist()\n",
    "    p_msg = y_pred #.numpy().tolist()\n",
    "    \n",
    "    acc = K.cast(K.equal(K.max(y_true, axis=-1),\n",
    "        K.cast(K.argmax(y_pred, axis=-1), K.floatx())),\n",
    "        K.floatx())\n",
    "    #print(\"metric acc:\" , acc)\n",
    "    return acc\n",
    "\n",
    "def newmodel(model):\n",
    "    inp = model.layers[2].input\n",
    "    opt = model.output\n",
    "    new_model = keras.models.Model(inputs = [inp], outputs = [opt])\n",
    "    return new_model\n",
    "\n",
    "def grad(sample, model):\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(sample)\n",
    "        loss = model(sample)\n",
    "        target = tf.reduce_max(loss, axis=1, keepdims = True)\n",
    "    gt = g.gradient(target, sample)  \n",
    "    return gt\n",
    "\n",
    "def grad2(sample, model):\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(sample)\n",
    "        with tf.GradientTape() as gg:\n",
    "            gg.watch(sample)\n",
    "            loss = model(sample)\n",
    "        ggt = gg.gradient(loss, sample)\n",
    "    gt = g.gradient(ggt, sample)\n",
    "    return gt\n",
    "\n",
    "def attrx_grad(sample, ig, mk, new_model, n_steps):\n",
    "    zk_grad_x = ig / sample\n",
    "    #print('zk_grad_x shape:', zk_grad_x.shape)\n",
    "    \n",
    "    zk_grad2_zk = 0\n",
    "    for i in range(n_steps):\n",
    "        #zk = x * mk\n",
    "        zk = sample * mk[i]\n",
    "        ans = grad2(zk, new_model) * (mk[i] * mk[i])\n",
    "        zk_grad2_zk += ans\n",
    "    #print('zk_grad2_zk shape: ', zk_grad2_zk.shape)\n",
    "    attrx_grad = zk_grad_x + (sample/n_steps) + zk_grad2_zk\n",
    "    return attrx_grad\n",
    "def displayMemory():\n",
    "    import nvidia_smi\n",
    "\n",
    "    nvidia_smi.nvmlInit()\n",
    "\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    # card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "    print(\"Total memory:\", info.total)\n",
    "    print(\"Free memory:\", info.free)\n",
    "    print(\"Used memory:\", info.used)\n",
    "\n",
    "    nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4NG1PGqXQkm"
   },
   "source": [
    "# 讀取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l-X0MKCDRoGz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs:  {'name': 'self_attention_1', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_3', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_5', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_7', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_9', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_11', 'trainable': True, 'dtype': 'float32'}\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmax_seq_len=999\\nmodel1 = tfr.get_model(\\n  max_input_len=(max_seq_len, max_seq_len), \\n  token_num=max(len(source_token_dict),len(target_token_dict)),\\n  embed_dim=32,\\n  encoder_num=6,\\n  #decoder_num=6,\\n  head_num=4,\\n  hidden_dim=128,\\n  use_same_embed=False\\n)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load(model_name):\n",
    "\n",
    "  from keras_performer import performer_ver_3\n",
    "  from tensorflow import keras\n",
    "  from keras_embed_sim import EmbeddingRet, EmbeddingSim\n",
    "  from keras_pos_embd import TrigPosEmbedding\n",
    "  from tensorflow_fast_attention.fast_attention_2 import softmax_kernel_transformation,  Attention, SelfAttention\n",
    "  from keras_position_wise_feed_forward.feed_forward import FeedForward  \n",
    "\n",
    "  co = performer_ver_3.get_custom_objects()\n",
    "  co['softmax_kernel_transformation']= softmax_kernel_transformation\n",
    "  path = 'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000//甲班模型/'\n",
    "  model = keras.models.load_model(path + model_name, custom_objects= co)\n",
    "  s = loadDictionary(path + 'source_token_dict.pickle')\n",
    "  t = loadDictionary(path + 'target_token_dict.pickle')\n",
    "  t_inv = loadDictionary(path + 'target_token_dict_inv.pickle')\n",
    "  return model, s, t, t_inv\n",
    "\n",
    "def loadTestTrainData(filename): # e.g., 'test.npy'    \n",
    "  with open(filename, 'rb') as f:\n",
    "    a = np.load(f, allow_pickle=True)\n",
    "    return a\n",
    "model, source_token_dict, target_token_dict, target_token_dict_inv = load(\"model.h5\")\n",
    "#model.summary()\n",
    "'''\n",
    "max_seq_len=999\n",
    "model1 = tfr.get_model(\n",
    "  max_input_len=(max_seq_len, max_seq_len), \n",
    "  token_num=max(len(source_token_dict),len(target_token_dict)),\n",
    "  embed_dim=32,\n",
    "  encoder_num=6,\n",
    "  #decoder_num=6,\n",
    "  head_num=4,\n",
    "  hidden_dim=128,\n",
    "  use_same_embed=False\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from alibi.api.defaults import DEFAULT_DATA_INTGRAD, DEFAULT_META_INTGRAD\n",
    "from alibi.utils.approximation_methods import approximation_parameters\n",
    "from alibi.api.interfaces import Explainer, Explanation\n",
    "from typing import Callable, Union, List, Tuple, Optional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "_valid_output_shape_type: List = [tuple, list]\n",
    "\n",
    "\n",
    "def _compute_convergence_delta(model: Union[tf.keras.models.Model],\n",
    "                               input_dtypes: List[tf.DType],\n",
    "                               attributions: List[np.ndarray],\n",
    "                               start_point: Union[List[np.ndarray], np.ndarray],\n",
    "                               end_point: Union[List[np.ndarray], np.ndarray],\n",
    "                               forward_kwargs: Optional[dict],\n",
    "                               target: Optional[List[int]],\n",
    "                               _is_list: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes convergence deltas for each data point. Convergence delta measures how close the sum of all attributions\n",
    "    is to the difference between the model output at the baseline and the model output at the data point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    input_dtypes\n",
    "        List with data types of the inputs.\n",
    "    attributions\n",
    "        Attributions assigned by the integrated gradients method to each feature.\n",
    "    start_point\n",
    "        Baselines.\n",
    "    end_point\n",
    "        Data points.\n",
    "    forward_kwargs\n",
    "        Input keywords args.\n",
    "    target\n",
    "        Target for which the gradients are calculated for classification models.\n",
    "    _is_list\n",
    "        Whether the model's input is a list (multiple inputs) or a np array (single input).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Convergence deltas for each data point.\n",
    "    \"\"\"\n",
    "    if _is_list:\n",
    "        start_point = [tf.convert_to_tensor(start_point[k], dtype=input_dtypes[k]) for k in range(len(input_dtypes))]\n",
    "        end_point = [tf.convert_to_tensor(end_point[k], dtype=input_dtypes[k]) for k in range(len(input_dtypes))]\n",
    "\n",
    "    else:\n",
    "        start_point = tf.convert_to_tensor(start_point)\n",
    "        end_point = tf.convert_to_tensor(end_point)\n",
    "\n",
    "    def _sum_rows(inp):\n",
    "\n",
    "        input_str = string.ascii_lowercase[1: len(inp.shape)]\n",
    "        if isinstance(inp, tf.Tensor):\n",
    "            sums = tf.einsum('a{}->a'.format(input_str), inp).numpy()\n",
    "        elif isinstance(inp, np.ndarray):\n",
    "            sums = np.einsum('a{}->a'.format(input_str), inp)\n",
    "        else:\n",
    "            raise NotImplementedError('input must be a tensorflow tensor or a numpy array')\n",
    "        return sums\n",
    "\n",
    "    start_out = _run_forward(model, start_point, target, forward_kwargs=forward_kwargs)\n",
    "    end_out = _run_forward(model, end_point, target, forward_kwargs=forward_kwargs)\n",
    "\n",
    "    if (len(model.output_shape) == 1 or model.output_shape[-1] == 1) and target is not None:\n",
    "        target_tensor = tf.cast(target, dtype=start_out.dtype)\n",
    "        target_tensor = tf.reshape(1 - target_tensor, [len(target), 1])\n",
    "        sign = 2 * target_tensor - 1\n",
    "\n",
    "        start_out = target_tensor + sign * start_out\n",
    "        end_out = target_tensor + sign * end_out\n",
    "\n",
    "    start_out_sum = _sum_rows(start_out)\n",
    "    end_out_sum = _sum_rows(end_out)\n",
    "\n",
    "    attr_sum = np.zeros(start_out_sum.shape)\n",
    "    for j in range(len(attributions)):\n",
    "        attrs_sum_j = _sum_rows(attributions[j])\n",
    "        attr_sum += attrs_sum_j\n",
    "\n",
    "    _deltas = attr_sum - (end_out_sum - start_out_sum)\n",
    "\n",
    "    return _deltas\n",
    "\n",
    "\n",
    "def _select_target(preds: tf.Tensor,\n",
    "                   targets: Union[None, tf.Tensor, np.ndarray, list]) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Select the predictions corresponding to the targets if targets is not None.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    preds\n",
    "        Predictions before selection.\n",
    "    targets\n",
    "        Targets to select.\n",
    "    Returns\n",
    "    -------\n",
    "        Selected predictions\n",
    "\n",
    "    \"\"\"\n",
    "    if targets is not None:\n",
    "        if isinstance(preds, tf.Tensor):\n",
    "            preds = tf.linalg.diag_part(tf.gather(preds, targets, axis=1))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    else:\n",
    "        raise ValueError(\"target cannot be `None` if `model` output dimensions > 1\")\n",
    "    return preds\n",
    "\n",
    "\n",
    "def _run_forward(model: Union[tf.keras.models.Model],\n",
    "                 x: Union[List[tf.Tensor], List[np.ndarray]],\n",
    "                 target: Union[None, tf.Tensor, np.ndarray, list],\n",
    "                 forward_kwargs: Optional[dict] = None) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Returns the output of the model. If the target is not `None`, only the output for the selected target is returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    x\n",
    "        Input data point.\n",
    "    target\n",
    "        Target for which the gradients are calculated for classification models.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    Returns\n",
    "    -------\n",
    "        Model output or model output after target selection for classification models.\n",
    "\n",
    "    \"\"\"\n",
    "    if forward_kwargs is None:\n",
    "        preds = model(x)\n",
    "    else:\n",
    "        preds = model(x, **forward_kwargs)\n",
    "\n",
    "    if len(model.output_shape) > 1 and model.output_shape[-1] > 1:\n",
    "        preds = _select_target(preds, target)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def _run_forward_from_layer(model: tf.keras.models.Model,\n",
    "                            layer: tf.keras.layers.Layer,\n",
    "                            orig_call: Callable,\n",
    "                            orig_dummy_input: Union[list, np.ndarray],\n",
    "                            x: tf.Tensor,\n",
    "                            target: Union[None, tf.Tensor, np.ndarray, list],\n",
    "                            forward_kwargs: Optional[dict] = None,\n",
    "                            run_from_layer_inputs: bool = False,\n",
    "                            select_target: bool = True) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Function currently unused.\n",
    "    Executes a forward call from an internal layer of the model to the model output.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    layer\n",
    "        Starting layer for the forward call.\n",
    "    orig_call\n",
    "        Original `call` method of the layer.\n",
    "    orig_dummy_input\n",
    "        Dummy input needed to initiate the model forward call. The number of instances in the dummy input must\n",
    "        be the same as the number of instances in x. The dummy input values play no role in the evaluation\n",
    "        as the  layer's status is overwritten during the forward call.\n",
    "    x\n",
    "        Layer's inputs. The layer's status is overwritten with `x` during the forward call.\n",
    "    target\n",
    "        Target for the output position to be returned.\n",
    "    forward_kwargs\n",
    "        Input keyword args. It must be a dict with numpy arrays as values. If it's not None,\n",
    "        the first dimension of the arrays must correspond to the number of instances in x and orig_dummy_input.\n",
    "    run_from_layer_inputs\n",
    "        If True, the forward pass starts from the layer's inputs, if False it starts from the layer's outputs.\n",
    "    select_target\n",
    "        Whether to return predictions for selected targets or return predictions for all targets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Model's predictions for the given target.\n",
    "\n",
    "    \"\"\"\n",
    "    def feed_layer(layer):\n",
    "        \"\"\"\n",
    "        Overwrites the intermediate layer status with the precomputed values `x`.\n",
    "\n",
    "        \"\"\"\n",
    "        def decorator(func):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                # Store the result and inputs of `layer.call` internally.\n",
    "                if run_from_layer_inputs:\n",
    "                    layer.inp = x\n",
    "                    layer.result = func(*x, **kwargs)\n",
    "                else:\n",
    "                    layer.inp = args\n",
    "                    layer.result = x\n",
    "                # Return the result to continue with the forward pass.\n",
    "                return layer.result\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        layer.call = decorator(layer.call)\n",
    "\n",
    "    feed_layer(layer)\n",
    "    if forward_kwargs is None:\n",
    "        preds = model(orig_dummy_input)\n",
    "    else:\n",
    "        preds = model(orig_dummy_input, **forward_kwargs)\n",
    "\n",
    "    delattr(layer, 'inp')\n",
    "    delattr(layer, 'result')\n",
    "    layer.call = orig_call\n",
    "\n",
    "    if select_target and len(model.output_shape) > 1 and model.output_shape[-1] > 1:\n",
    "        preds = _select_target(preds, target)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def _run_forward_to_layer(model: tf.keras.models.Model,\n",
    "                          layer: tf.keras.layers.Layer,\n",
    "                          orig_call: Callable,\n",
    "                          x: Union[List[np.ndarray], np.ndarray],\n",
    "                          forward_kwargs: Optional[dict] = None,\n",
    "                          run_to_layer_inputs: bool = False) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Executes a forward call from the model input to an internal layer output.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    layer\n",
    "        Starting layer for the forward call.\n",
    "    orig_call\n",
    "        Original `call` method of the layer.\n",
    "    x\n",
    "        Model's inputs.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    run_to_layer_inputs\n",
    "        If True, the layer's inputs are returned. If False, the layer's output's are returned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Output of the given layer.\n",
    "\n",
    "    \"\"\"\n",
    "    def take_layer(layer):\n",
    "        \"\"\"\n",
    "        Stores the layer's outputs internally to the layer's object.\n",
    "\n",
    "        \"\"\"\n",
    "        def decorator(func):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                # Store the result of `layer.call` internally.\n",
    "                layer.inp = args\n",
    "                layer.result = func(*args, **kwargs)\n",
    "                # Return the result to continue with the forward pass.\n",
    "                return layer.result\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        layer.call = decorator(layer.call)\n",
    "\n",
    "    # inp = tf.zeros((x.shape[0], ) + model.input_shape[1:])\n",
    "    take_layer(layer)\n",
    "    if forward_kwargs is None:\n",
    "        _ = model(x)\n",
    "    else:\n",
    "        _ = model(x, **forward_kwargs)\n",
    "    layer_inp = layer.inp\n",
    "    layer_out = layer.result\n",
    "\n",
    "    delattr(layer, 'inp')\n",
    "    delattr(layer, 'result')\n",
    "    layer.call = orig_call\n",
    "\n",
    "    if run_to_layer_inputs:\n",
    "        return layer_inp\n",
    "    else:\n",
    "        return layer_out\n",
    "\n",
    "from tensorflow.python.training.tracking.data_structures import ListWrapper\n",
    "def _forward_input_baseline(X: Union[List[np.ndarray], np.ndarray],\n",
    "                            bls: Union[List[np.ndarray], np.ndarray],\n",
    "                            model: tf.keras.Model,\n",
    "                            layer: tf.keras.layers.Layer,\n",
    "                            orig_call: Callable,\n",
    "                            forward_kwargs: Optional[dict] = None,\n",
    "                            forward_to_inputs: bool = False) -> Tuple[Union[list, tf.Tensor], Union[list, tf.Tensor]]:\n",
    "    \"\"\"\n",
    "    Forwards inputs and baselines to the layer's inputs or outputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Input data points.\n",
    "    bls\n",
    "        Baselines.\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    layer\n",
    "        Desired layer output.\n",
    "    orig_call\n",
    "        Original `call` method of layer.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    forward_to_inputs\n",
    "        If True, X and bls are forwarded to the layer's input. If False, they are forwarded to the layer's outputs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Forwarded inputs and  baselines as a numpy arrays.\n",
    "\n",
    "    \"\"\"\n",
    "    #print(\"layer: \", layer)\n",
    "    if layer is not None:\n",
    "        X_layer = _run_forward_to_layer(model,\n",
    "                                        layer,\n",
    "                                        orig_call,\n",
    "                                        X,\n",
    "                                        forward_kwargs=forward_kwargs,\n",
    "                                        run_to_layer_inputs=forward_to_inputs)\n",
    "        bls_layer = _run_forward_to_layer(model,\n",
    "                                          layer,\n",
    "                                          orig_call,\n",
    "                                          bls,\n",
    "                                          forward_kwargs=forward_kwargs,\n",
    "                                          run_to_layer_inputs=forward_to_inputs)\n",
    "\n",
    "        #print(\"bls_layer type: \", type(bls_layer))\n",
    "        #print(\"X_layer type: \", type(X_layer))\n",
    "        if isinstance(X_layer, tuple):\n",
    "            X_layer = list(X_layer)\n",
    "\n",
    "        if isinstance(bls_layer, tuple):\n",
    "            bls_layer = list(bls_layer)\n",
    "\n",
    "        return X_layer, bls_layer\n",
    "\n",
    "    else:\n",
    "        return X, bls\n",
    "\n",
    "\n",
    "def _gradients_input(model: Union[tf.keras.models.Model],\n",
    "                     x: List[tf.Tensor],\n",
    "                     target: Union[None, tf.Tensor],\n",
    "                     forward_kwargs: Optional[dict] = None) -> List[tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculates the gradients of the target class output (or the output if the output dimension is equal to 1)\n",
    "    with respect to each input feature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    x\n",
    "        Input data point.\n",
    "    target\n",
    "        Target for which the gradients are calculated if the output dimension is higher than 1.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    Returns\n",
    "    -------\n",
    "        Gradients for each input feature.\n",
    "\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        preds = _run_forward(model, x, target, forward_kwargs=forward_kwargs)\n",
    "\n",
    "    grads = tape.gradient(preds, x)\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def _gradients_layer(model: Union[tf.keras.models.Model],\n",
    "                     layer: Union[tf.keras.layers.Layer],\n",
    "                     orig_call: Callable,\n",
    "                     orig_dummy_input: Union[list, np.ndarray],\n",
    "                     x: Union[List[tf.Tensor], tf.Tensor],\n",
    "                     target: Union[None, tf.Tensor],\n",
    "                     forward_kwargs: Optional[dict] = None,\n",
    "                     compute_layer_inputs_gradients: bool = False) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the gradients of the target class output (or the output if the output dimension is equal to 1)\n",
    "    with respect to each element of `layer`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    layer\n",
    "        Layer of the model with respect to which the gradients are calculated.\n",
    "    orig_call\n",
    "        Original `call` method of the layer. This is necessary since the call method is modified by the function\n",
    "        in order to make the layer output visible to the GradientTape.\n",
    "    x\n",
    "        Input data point.\n",
    "    target\n",
    "        Target for which the gradients are calculated if the output dimension is higher than 1.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    compute_layer_inputs_gradients\n",
    "        If True, gradients are computed with respect to the layer's inputs.\n",
    "        If False, they are computed with respect to the layer's outputs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Gradients for each element of layer.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def watch_layer(layer, tape):\n",
    "        \"\"\"\n",
    "        Make an intermediate hidden `layer` watchable by the `tape`.\n",
    "        After calling this function, you can obtain the gradient with\n",
    "        respect to the output of the `layer` by calling:\n",
    "\n",
    "            grads = tape.gradient(..., layer.result)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def decorator(func):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                # Store the result and the input of `layer.call` internally.\n",
    "                if compute_layer_inputs_gradients:\n",
    "                    layer.inp = x\n",
    "                    layer.result = func(*x, **kwargs)\n",
    "                    # From this point onwards, watch this tensor.\n",
    "                    tape.watch(layer.inp)\n",
    "                else:\n",
    "                    layer.inp = args\n",
    "                    layer.result = x\n",
    "                    # From this point onwards, watch this tensor.\n",
    "                    tape.watch(layer.result)\n",
    "                # Return the result to continue with the forward pass.\n",
    "                return layer.result\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        layer.call = decorator(layer.call)\n",
    "\n",
    "    #  Repeating the dummy input needed to initiate the model's forward call in order to ensure that\n",
    "    #  the number of dummy instances is the same as the number of real instances.\n",
    "    #  This is necessary in case `forward_kwargs` is not None. In that case, the model forward call  would crash\n",
    "    #  if the number of instances in `orig_dummy_input` is different from the number of instances in `forward_kwargs`.\n",
    "    #  The number of instances in `forward_kwargs` is the same as the number of instances in `x` by construction.\n",
    "    if isinstance(orig_dummy_input, list):\n",
    "        if isinstance(x, list):\n",
    "            orig_dummy_input = [np.repeat(inp, x[0].shape[0], axis=0) for inp in orig_dummy_input]\n",
    "        else:\n",
    "            orig_dummy_input = [np.repeat(inp, x.shape[0], axis=0) for inp in orig_dummy_input]\n",
    "    else:\n",
    "        if isinstance(x, list):\n",
    "            orig_dummy_input = np.repeat(orig_dummy_input, x[0].shape[0], axis=0)\n",
    "        else:\n",
    "            orig_dummy_input = np.repeat(orig_dummy_input, x.shape[0], axis=0)\n",
    "\n",
    "    #  Calculating the gradients with respect to the layer.\n",
    "    with tf.GradientTape() as tape:\n",
    "        watch_layer(layer, tape)\n",
    "        preds = _run_forward(model, orig_dummy_input, target, forward_kwargs=forward_kwargs)\n",
    "\n",
    "    if compute_layer_inputs_gradients:\n",
    "        grads = tape.gradient(preds, layer.inp)\n",
    "    else:\n",
    "        grads = tape.gradient(preds, layer.result)\n",
    "\n",
    "    delattr(layer, 'inp')\n",
    "    delattr(layer, 'result')\n",
    "    layer.call = orig_call\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def _format_baseline(X: np.ndarray,\n",
    "                     baselines: Union[None, int, float, np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Formats baselines to return a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Input data points.\n",
    "    baselines\n",
    "        Baselines.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Formatted inputs and  baselines as a numpy arrays.\n",
    "\n",
    "    \"\"\"\n",
    "    #print(\"X.shape: \", X.shape)\n",
    "    if baselines is None:\n",
    "        bls = np.zeros(X.shape).astype(X.dtype)\n",
    "    elif isinstance(baselines, int) or isinstance(baselines, float):\n",
    "        bls = np.full(X.shape, baselines).astype(X.dtype)\n",
    "    elif isinstance(baselines, np.ndarray):\n",
    "        bls = baselines.astype(X.dtype)\n",
    "    else:\n",
    "        raise ValueError(f\"baselines must be `int`, `float`, `np.ndarray` or `None`. Found {type(baselines)}\")\n",
    "    #print(\"bls.shape: \", bls.shape)\n",
    "    return bls\n",
    "\n",
    "\n",
    "def _format_target(target: Union[None, int, list, np.ndarray],\n",
    "                   nb_samples: int) -> Union[None, List[int]]:\n",
    "    \"\"\"\n",
    "    Formats target to return a list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target\n",
    "        Original target.\n",
    "    nb_samples\n",
    "        Number of samples in the batch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Formatted target as a list.\n",
    "\n",
    "    \"\"\"\n",
    "    if target is not None:\n",
    "        if isinstance(target, int):\n",
    "            target = [target for _ in range(nb_samples)]\n",
    "        elif isinstance(target, list) or isinstance(target, np.ndarray):\n",
    "            target = [t.astype(int) for t in target]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "def _sum_integral_terms(step_sizes: list,\n",
    "                        grads: Union[tf.Tensor, np.ndarray]) -> Union[tf.Tensor, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Sums the terms in the path integral with weights `step_sizes`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    step_sizes\n",
    "        Weights in the path integral sum.\n",
    "    grads\n",
    "        Gradients to sum for each feature.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Sums of the gradients along the chosen path.\n",
    "\n",
    "    \"\"\"\n",
    "    input_str = string.ascii_lowercase[1: len(grads.shape)]\n",
    "    if isinstance(grads, tf.Tensor):\n",
    "        step_sizes = tf.convert_to_tensor(step_sizes)\n",
    "        einstr = 'a,a{}->{}'.format(input_str, input_str)\n",
    "        sums = tf.einsum(einstr, step_sizes, grads).numpy()\n",
    "    elif isinstance(grads, np.ndarray):\n",
    "        einstr = 'a,a{}->{}'.format(input_str, input_str)\n",
    "        sums = np.einsum(einstr, step_sizes, grads)\n",
    "    else:\n",
    "        raise NotImplementedError('input must be a tensorflow tensor or a numpy array')\n",
    "    return sums\n",
    "\n",
    "\n",
    "def _calculate_sum_int(batches: List[List[tf.Tensor]],\n",
    "                       model: Union[tf.keras.Model],\n",
    "                       target: Union[None, List[int]],\n",
    "                       target_paths: np.ndarray,\n",
    "                       n_steps: int,\n",
    "                       nb_samples: int,\n",
    "                       step_sizes: List[float],\n",
    "                       j: int) -> Union[tf.Tensor, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculates the sum of all the terms in the integral from a list of batch gradients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batches\n",
    "        List of batch gradients.\n",
    "    model\n",
    "        tf.keras or keras model.\n",
    "    target\n",
    "        List of targets.\n",
    "    target_paths\n",
    "        Targets for each path in the integral.\n",
    "    n_steps\n",
    "        Number of steps in the integral.\n",
    "    nb_samples\n",
    "        Total number of samples.\n",
    "    step_sizes\n",
    "        Step sizes used to calculate the integral.\n",
    "    j\n",
    "        Iterates through list of inputs or list of layers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    grads = tf.concat(batches[j], 0)\n",
    "    shape = grads.shape[1:]\n",
    "    if isinstance(shape, tf.TensorShape):\n",
    "        shape = tuple(shape.as_list())\n",
    "\n",
    "    # invert sign of gradients for target 0 examples if classifier returns only positive class probability\n",
    "    if (len(model.output_shape) == 1 or model.output_shape[-1] == 1) and target is not None:\n",
    "        sign = 2 * target_paths - 1\n",
    "        grads = np.asarray([s * g for s, g in zip(sign, grads)])\n",
    "\n",
    "    grads = tf.reshape(grads, (n_steps, nb_samples) + shape)\n",
    "    # sum integral terms and scale attributions\n",
    "    sum_int = _sum_integral_terms(step_sizes, grads.numpy())\n",
    "\n",
    "    return sum_int\n",
    "\n",
    "\n",
    "def _validate_output(model: tf.keras.Model,\n",
    "                     target: Optional[List[int]]) -> None:\n",
    "    \"\"\"\n",
    "    Validates the model's output type and raises an error if the output type is not supported.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Keras model for which the output is validated.\n",
    "    target\n",
    "        Targets for which gradients are calculated\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    if not model.output_shape or not any(isinstance(model.output_shape, t) for t in _valid_output_shape_type):\n",
    "        raise NotImplementedError(f\"The model output_shape attribute must be in {_valid_output_shape_type}. \"\n",
    "                                  f\"Found model.output_shape: {model.output_shape}\")\n",
    "\n",
    "    if (len(model.output_shape) == 1\n",
    "        or model.output_shape[-1] == 1) \\\n",
    "            and target is None:\n",
    "        logger.warning(\"It looks like you are passing a model with a scalar output and target is set to `None`.\"\n",
    "                       \"If your model is a regression model this will produce correct attributions. If your model \"\n",
    "                       \"is a classification model, targets for each datapoint must be defined. \"\n",
    "                       \"Not defining the target may lead to incorrect values for the attributions.\"\n",
    "                       \"Targets can be either the true classes or the classes predicted by the model.\")\n",
    "\n",
    "\n",
    "class IntegratedGradients1(Explainer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: tf.keras.Model,\n",
    "                 layer: Optional[tf.keras.layers.Layer] = None,\n",
    "                 method: str = \"gausslegendre\",\n",
    "                 n_steps: int = 10,\n",
    "                 internal_batch_size: int = 100\n",
    "                 ) -> None:\n",
    "        \"\"\"\n",
    "        An implementation of the integrated gradients method for Tensorflow and Keras models.\n",
    "\n",
    "        For details of the method see the original paper:\n",
    "        https://arxiv.org/abs/1703.01365 .\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model\n",
    "            Tensorflow or Keras model.\n",
    "        layer\n",
    "            Layer with respect to which the gradients are calculated.\n",
    "            If not provided, the gradients are calculated with respect to the input.\n",
    "        method\n",
    "            Method for the integral approximation. Methods available:\n",
    "            \"riemann_left\", \"riemann_right\", \"riemann_middle\", \"riemann_trapezoid\", \"gausslegendre\".\n",
    "        n_steps\n",
    "            Number of step in the path integral approximation from the baseline to the input instance.\n",
    "        internal_batch_size\n",
    "            Batch size for the internal batching.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(meta=copy.deepcopy(DEFAULT_META_INTGRAD))\n",
    "        params = locals()\n",
    "        remove = ['self', 'model', '__class__', 'layer']\n",
    "        params = {k: v for k, v in params.items() if k not in remove}\n",
    "        self.model = model\n",
    "\n",
    "        if self.model.inputs is None:\n",
    "            self._has_inputs = False\n",
    "        else:\n",
    "            self._has_inputs = True\n",
    "\n",
    "        if layer is None:\n",
    "            self.orig_call = None\n",
    "            layer_num = 0\n",
    "        else:\n",
    "            self.orig_call = layer.call\n",
    "            try:\n",
    "                layer_num = model.layers.index(layer)\n",
    "            except ValueError:\n",
    "                logger.info(\"Layer not in the list of model.layers\")\n",
    "                layer_num = None\n",
    "\n",
    "        params['layer'] = layer_num\n",
    "        self.meta['params'].update(params)\n",
    "        self.layer = layer\n",
    "        self.n_steps = n_steps\n",
    "        self.method = method\n",
    "        self.internal_batch_size = internal_batch_size\n",
    "\n",
    "        self._is_list: Optional[bool] = None\n",
    "        self._is_np: Optional[bool] = None\n",
    "        self.orig_dummy_input: Optional[Union[list, np.ndarray]] = None\n",
    "\n",
    "\n",
    "    def explain(self,\n",
    "                X: Union[np.ndarray, List[np.ndarray]],\n",
    "                forward_kwargs: Optional[dict] = None,\n",
    "                baselines: Union[int, float, np.ndarray, List[int], List[float], List[np.ndarray]] = None,\n",
    "                target: Union[int, list, np.ndarray] = None,\n",
    "                attribute_to_layer_inputs: bool = False) -> Explanation:\n",
    "        \"\"\"Calculates the attributions for each input feature or element of layer and\n",
    "        returns an Explanation object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X\n",
    "            Instance for which integrated gradients attribution are computed.\n",
    "        forward_kwargs\n",
    "            Input keyword args. If it's not None, it must be a dict with numpy arrays as values.\n",
    "            The first dimension of the arrays must correspond to the number of examples.\n",
    "            It will be repeated for each of n_steps along the integrated path.\n",
    "            The attributions are not computed with respect to these arguments.\n",
    "        baselines\n",
    "            Baselines (starting point of the path integral) for each instance.\n",
    "            If the passed value is an `np.ndarray` must have the same shape as X.\n",
    "            If not provided, all features values for the baselines are set to 0.\n",
    "        target\n",
    "            Defines which element of the model output is considered to compute the gradients.\n",
    "            It can be a list of integers or a numeric value. If a numeric value is passed, the gradients are calculated\n",
    "            for the same element of the output for all data points.\n",
    "            It must be provided if the model output dimension is higher than 1.\n",
    "            For regression models whose output is a scalar, target should not be provided.\n",
    "            For classification models `target` can be either the true classes or the classes predicted by the model.\n",
    "        attribute_to_layer_inputs\n",
    "            In case of layers gradients, controls whether the gradients are computed for the layer's inputs or\n",
    "            outputs. If True, gradients are computed for the layer's inputs, if False for the layer's outputs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            `Explanation` object including `meta` and `data` attributes with integrated gradients attributions\n",
    "            for each feature.\n",
    "\n",
    "        \"\"\"\n",
    "        self._is_list = isinstance(X, list)\n",
    "        self._is_np = isinstance(X, np.ndarray)\n",
    "        #print('self._is_list: ', self._is_list)\n",
    "        #print('self._is_np: ', self._is_np)\n",
    "        if self._is_list:\n",
    "            self.orig_dummy_input = [np.zeros((1,) + xx.shape[1:], dtype=xx.dtype) for xx in X]  # type: ignore\n",
    "            nb_samples = len(X[0])\n",
    "            input_dtypes = [xx.dtype for xx in X]\n",
    "            # Formatting baselines in case of models with multiple inputs\n",
    "            if baselines is None:\n",
    "                baselines = [None for _ in range(len(X))]\n",
    "            else:\n",
    "                if not isinstance(baselines, list):\n",
    "                    raise ValueError(f\"If the input X is a list, baseline can only be `None` or \"\n",
    "                                     f\"a list of the same length of X. Found baselines type {type(baselines)}\")\n",
    "                else:\n",
    "                    if len(X) != len(baselines):\n",
    "                        raise ValueError(f\"Length of 'X' must match length of 'baselines'. \"\n",
    "                                         f\"Found len(X): {len(X)}, len(baselines): {len(baselines)}\")\n",
    "\n",
    "            if max([len(x) for x in X]) != min([len(x) for x in X]):\n",
    "                raise ValueError(\"First dimension must be egual for all inputs\")\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                x, baseline = X[i], baselines[i]  # type: ignore\n",
    "                # format and check baselines\n",
    "                baseline = _format_baseline(x, baseline)\n",
    "                baselines[i] = baseline  # type: ignore\n",
    "\n",
    "        elif self._is_np:\n",
    "            #X = cast(np.ndarray, X)  # help mypy out\n",
    "            #print('in is np : X shape:', X.shape)\n",
    "            self.orig_dummy_input = np.zeros((1,) + X.shape[1:], dtype=X.dtype)  # type: ignore\n",
    "            nb_samples = len(X)\n",
    "            input_dtypes = [X.dtype]  # type: ignore\n",
    "            # Formatting baselines for models with a single input\n",
    "            baselines = _format_baseline(X, baselines)\n",
    "            #print(\"baselines.shape1: \", baselines.shape)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Input must be a np.ndarray or a list of np.ndarray\")\n",
    "\n",
    "        # defining integral method\n",
    "        step_sizes_func, alphas_func = approximation_parameters(self.method)\n",
    "        step_sizes, alphas = step_sizes_func(self.n_steps), alphas_func(self.n_steps)\n",
    "        #print('alphas: ', alphas)\n",
    "        target = _format_target(target, nb_samples)\n",
    "        #print('target:', target)\n",
    "        #print('target type:', type(target))\n",
    "        if self._is_list:\n",
    "            # Attributions calculation in case of multiple inputs\n",
    "            if not self._has_inputs:\n",
    "                # Inferring model's inputs from data points for models with no explicit inputs\n",
    "                # (typically subclassed models)\n",
    "                inputs = [tf.keras.Input(shape=xx.shape[1:], dtype=xx.dtype) for xx in X]\n",
    "                self.model(inputs)\n",
    "\n",
    "            _validate_output(self.model, target)\n",
    "\n",
    "            if self.layer is None:\n",
    "                # No layer passed, attributions computed with respect to the inputs\n",
    "                attributions = self._compute_attributions_list_input(X,\n",
    "                                                                     baselines,\n",
    "                                                                     target,\n",
    "                                                                     step_sizes,\n",
    "                                                                     alphas,\n",
    "                                                                     nb_samples,\n",
    "                                                                     forward_kwargs,\n",
    "                                                                     attribute_to_layer_inputs)\n",
    "\n",
    "            else:\n",
    "                # forwad inputs and  baselines\n",
    "                X_layer, baselines_layer = _forward_input_baseline(X,\n",
    "                                                                   baselines,\n",
    "                                                                   self.model,\n",
    "                                                                   self.layer,\n",
    "                                                                   self.orig_call,\n",
    "                                                                   forward_kwargs=forward_kwargs,\n",
    "                                                                   forward_to_inputs=attribute_to_layer_inputs)\n",
    "\n",
    "                if isinstance(X_layer, list) and isinstance(baselines_layer, list):\n",
    "                    attributions = self._compute_attributions_list_input(X_layer,\n",
    "                                                                         baselines_layer,\n",
    "                                                                         target,\n",
    "                                                                         step_sizes,\n",
    "                                                                         alphas,\n",
    "                                                                         nb_samples,\n",
    "                                                                         forward_kwargs,\n",
    "                                                                         attribute_to_layer_inputs)\n",
    "                else:\n",
    "                    attributions = self._compute_attributions_tensor_input(X_layer,\n",
    "                                                                           baselines_layer,\n",
    "                                                                           target,\n",
    "                                                                           step_sizes,\n",
    "                                                                           alphas,\n",
    "                                                                           nb_samples,\n",
    "                                                                           forward_kwargs,\n",
    "                                                                           attribute_to_layer_inputs)\n",
    "\n",
    "        else:\n",
    "            # Attributions calculation in case of single input\n",
    "            if not self._has_inputs:\n",
    "                inputs = tf.keras.Input(shape=X.shape[1:], dtype=X.dtype)  # type: ignore\n",
    "                self.model(inputs)\n",
    "\n",
    "            _validate_output(self.model, target)\n",
    "\n",
    "            if self.layer is None:\n",
    "                attributions = self._compute_attributions_tensor_input(X,\n",
    "                                                                       baselines,\n",
    "                                                                       target,\n",
    "                                                                       step_sizes,\n",
    "                                                                       alphas,\n",
    "                                                                       nb_samples,\n",
    "                                                                       forward_kwargs,\n",
    "                                                                       attribute_to_layer_inputs)\n",
    "\n",
    "            else:\n",
    "                #print(\"--------else self.layer is None:\")\n",
    "                # forwad inputs and  baselines\n",
    "                X_layer, baselines_layer = _forward_input_baseline(X,\n",
    "                                            baselines,\n",
    "                                            self.model,\n",
    "                                            self.layer,\n",
    "                                            self.orig_call,\n",
    "                                            forward_kwargs=forward_kwargs,\n",
    "                                            forward_to_inputs=attribute_to_layer_inputs)\n",
    "\n",
    "                #print(\"-----baselines_layer[0].shape: \", baselines_layer[0].shape)\n",
    "                if isinstance(X_layer, list) and isinstance(baselines_layer, list):\n",
    "                    attributions = self._compute_attributions_list_input(X_layer,\n",
    "                                                baselines_layer,\n",
    "                                                target,\n",
    "                                                step_sizes,\n",
    "                                                alphas,\n",
    "                                                nb_samples,\n",
    "                                                forward_kwargs,\n",
    "                                                attribute_to_layer_inputs)\n",
    "                    #print(\"------baselines.shape\", baselines.shape)\n",
    "                else:\n",
    "                    attributions = self._compute_attributions_tensor_input(X_layer,\n",
    "                                                                           baselines_layer,\n",
    "                                                                           target,\n",
    "                                                                           step_sizes,\n",
    "                                                                           alphas,\n",
    "                                                                           nb_samples,\n",
    "                                                                           forward_kwargs,\n",
    "                                                                           attribute_to_layer_inputs)\n",
    "        # calculate convergence deltas\n",
    "        deltas = _compute_convergence_delta(self.model,\n",
    "                                            input_dtypes,\n",
    "                                            attributions,\n",
    "                                            baselines,\n",
    "                                            X,\n",
    "                                            forward_kwargs,\n",
    "                                            target,\n",
    "                                            self._is_list)\n",
    "\n",
    "        return self.build_explanation(\n",
    "            X=X,\n",
    "            forward_kwargs=forward_kwargs,\n",
    "            baselines=baselines,\n",
    "            target=target,\n",
    "            attributions=attributions,\n",
    "            deltas=deltas\n",
    "        )\n",
    "\n",
    "\n",
    "    def build_explanation(self,\n",
    "                          X: List[np.ndarray],\n",
    "                          forward_kwargs: Optional[dict],\n",
    "                          baselines: List[np.ndarray],\n",
    "                          target: Optional[List[int]],\n",
    "                          attributions: Union[List[np.ndarray], List[tf.Tensor]],\n",
    "                          deltas: np.ndarray) -> Explanation:\n",
    "\n",
    "        data = copy.deepcopy(DEFAULT_DATA_INTGRAD)\n",
    "        predictions = self.model(X).numpy()\n",
    "        if isinstance(attributions[0], tf.Tensor):\n",
    "            attributions = [attr.numpy() for attr in attributions]\n",
    "        data.update(X=X,\n",
    "                    forward_kwargs=forward_kwargs,\n",
    "                    baselines=baselines,\n",
    "                    target=target,\n",
    "                    attributions=attributions,\n",
    "                    deltas=deltas,\n",
    "                    predictions=predictions)\n",
    "\n",
    "        return Explanation(meta=copy.deepcopy(self.meta), data=data)\n",
    "\n",
    "\n",
    "    def reset_predictor(self, predictor: Union[tf.keras.Model]) -> None:\n",
    "        # TODO: check what else should be done (e.g. validate dtypes again?)\n",
    "        self.model = predictor\n",
    "\n",
    "\n",
    "    def _compute_attributions_list_input(self,\n",
    "                       X: List[np.ndarray],\n",
    "                       baselines: Union[List[int], List[float], List[np.ndarray]],\n",
    "                       target: Optional[List[int]],\n",
    "                       step_sizes: List[float],\n",
    "                       alphas: List[float],\n",
    "                       nb_samples: int,\n",
    "                       forward_kwargs: Optional[dict],\n",
    "                       compute_layer_inputs_gradients: bool) -> List:\n",
    "        \"\"\"For each tensor in a list of input tensors,\n",
    "        calculates the attributions for each feature or element of layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X\n",
    "        Instance for which integrated gradients attribution are computed.\n",
    "        baselines\n",
    "            Baselines (starting point of the path integral) for each instance.\n",
    "        target\n",
    "            Defines which element of the model output is considered to compute the gradients.\n",
    "        step_sizes\n",
    "            Weights in the path integral sum.\n",
    "        alphas\n",
    "            Interpolation parameter defining the points of the interal path.\n",
    "        nb_samples\n",
    "            Total number of samples.\n",
    "        forward_kwargs\n",
    "            Input keywords args.\n",
    "        compute_layer_inputs_gradients\n",
    "            In case of layers gradients, controls whether the gradients are computed for the layer's inputs or\n",
    "            outputs. If True, gradients are computed for the layer's inputs, if False for the layer's outputs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tuple with integrated gradients attributions, deltas and predictions\n",
    "\n",
    "        \"\"\"\n",
    "        #print(\"X type: \", type(X))\n",
    "        #print(\"X len: \", len(X))\n",
    "        #print('X[0] shape: ', X[0].shape)\n",
    "        #print('X[1] shape: ', X[1].shape)\n",
    "        attrs_dtypes = [ [xx.dtype for xx in X][0] ] # [# of outputs]\n",
    "        #print(\"attrs_dtypes type: \", type(attrs_dtypes))\n",
    "        #print(\"attrs_dtypes len: \", len(attrs_dtypes))\n",
    "        #print(\"attrs_dtypes[0] type: \", type(attrs_dtypes[0]))\n",
    "\n",
    "        # define paths in features' space\n",
    "        paths = []\n",
    "        #print(\"type(baselines): \", type(baselines))\n",
    "        #print(\"baselines[0].shape: \", baselines[0].shape)\n",
    "        for i in range(len(X)): #ListWrapper of length 2\n",
    "            x, baseline = X[i], baselines[i]  # type: ignore\n",
    "            # construct paths (279 X 802 X 32)\n",
    "            blist =[]\n",
    "            for j in range(self.n_steps): \n",
    "              tmp = baseline + alphas[j] * (x-baseline) \n",
    "              #print('alphas[j] shape: ', alphas[j].shape)\n",
    "              #print('alphas[j]: ', alphas[j])\n",
    "              #print(\"tmp shape:\", tmp.shape)            \n",
    "              blist.append(tmp)\n",
    "            path = np.concatenate(blist, axis=0)\n",
    "            #print(\"path shape\", path.shape)\n",
    "            paths.append(path)\n",
    "\n",
    "        if forward_kwargs is not None:\n",
    "            paths_kwargs = {k: np.concatenate([forward_kwargs[k] for _ in range(self.n_steps)], axis=0)\n",
    "                            for k in forward_kwargs.keys()}\n",
    "        else:\n",
    "            paths_kwargs = None\n",
    "\n",
    "        # define target paths\n",
    "        if target is not None:\n",
    "            target_paths = np.concatenate([target \n",
    "                    for _ in range(self.n_steps)],\n",
    "                    axis=0)\n",
    "        else:\n",
    "            target_paths = None\n",
    "        if forward_kwargs is not None:\n",
    "            if target_paths is not None:\n",
    "                #print(\"PATH1....\")\n",
    "                ds_args = tuple(p for p in paths) + (paths_kwargs, target_paths)\n",
    "            else:\n",
    "                #print(\"PATH2....\")\n",
    "                ds_args = tuple(p for p in paths) + (paths_kwargs,)\n",
    "\n",
    "        else:\n",
    "            if target_paths is not None:\n",
    "                #print(\"PATH3....\")\n",
    "                #print(\"len(target_paths): \", len(target_paths))\n",
    "                #print(\"target_paths[0].shape: \", target_paths[0].shape)\n",
    "                #print(\"target_paths[0]: \", target_paths[0])\n",
    "                #print(\"len(paths): \", len(paths))\n",
    "                #print(\"type(paths): \", type(paths))\n",
    "                #print(\"paths[0].shape: \", paths[0].shape)\n",
    "                #print(\"paths[1].shape: \", paths[1].shape)\n",
    "                #print(\"paths: \", paths)\n",
    "                #ds_args = tuple(p for p in paths) + (target_paths,)\n",
    "                ds_args = tuple([paths[0]]) + (target_paths,)\n",
    "            else:\n",
    "                #print(\"PATH4....\")\n",
    "                ds_args = tuple(p for p in paths)\n",
    "        #print('len(ds_args): ', len(ds_args))\n",
    "        #print('ds_args[0].shape: ', ds_args[0].shape)\n",
    "        #print('ds_args[1].shape: ', ds_args[1].shape)\n",
    "        paths_ds = tf.data.Dataset.from_tensor_slices(ds_args).batch(self.internal_batch_size)\n",
    "        paths_ds.as_numpy_iterator()\n",
    "        paths_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        #print(\"paths_ds len: \", len(paths_ds))\n",
    "\n",
    "        # calculate gradients for batches\n",
    "        batches = []\n",
    "        for path in paths_ds:\n",
    "            #print(\"path type: \", type(path))\n",
    "            #print(\"path len: \", len(path))\n",
    "            if forward_kwargs is not None:\n",
    "                if target is not None:\n",
    "                    paths_b, kwargs_b, target_b = path[:-2], path[-2], path[-1]\n",
    "                else:\n",
    "                    paths_b, kwargs_b = path\n",
    "                    target_b = None\n",
    "            else:\n",
    "                if target is not None:\n",
    "                    paths_b, target_b = path[:-1], path[-1]\n",
    "                    kwargs_b = None\n",
    "                else:\n",
    "                    paths_b, kwargs_b, target_b = path, None, None\n",
    "\n",
    "            paths_b = [tf.dtypes.cast(paths_b[i], attrs_dtypes[i]) for i in range(len(paths_b))]\n",
    "\n",
    "            #print(\"self.layer: \", self.layer)\n",
    "            if self.layer is None:\n",
    "                grads_b = _gradients_input(self.model, paths_b, target_b, forward_kwargs=kwargs_b)\n",
    "            else:\n",
    "                grads_b = _gradients_layer(self.model,\n",
    "                                           self.layer,\n",
    "                                           self.orig_call,\n",
    "                                           self.orig_dummy_input,\n",
    "                                           paths_b,\n",
    "                                           target_b,\n",
    "                                           forward_kwargs=kwargs_b,\n",
    "                                           compute_layer_inputs_gradients=compute_layer_inputs_gradients)\n",
    "            #print(\"grads_b type: \", type(grads_b))\n",
    "            #print(\"grads_b shape: \", grads_b.shape)\n",
    "\n",
    "            batches.append(grads_b)\n",
    "\n",
    "        # multi-input\n",
    "        #print(\"batches type: \", type(batches))\n",
    "        #print(\"len(batches): \", len(batches))\n",
    "        #print(\"batches[0] len\",len(batches[0]) )\n",
    "        #print(\"attrs_dtypes type: \", type(attrs_dtypes))\n",
    "        #print(\"len(attrs_dtypes): \", len(attrs_dtypes))\n",
    "        #print(\"batches[0]: \", batches[0])\n",
    "\n",
    "        batches = [[batches[i][j] for i in range(len(batches))] for j in range(len(attrs_dtypes))]\n",
    "\n",
    "        # calculate attributions from gradients batches\n",
    "        attributions = []\n",
    "        for j in range(len(attrs_dtypes)):\n",
    "            sum_int = _calculate_sum_int(batches, self.model,\n",
    "                                         target, target_paths,\n",
    "                                         self.n_steps, nb_samples,\n",
    "                                         step_sizes, j)\n",
    "            norm = X[j] - baselines[j]  # type: ignore\n",
    "            attribution = norm * sum_int\n",
    "            attributions.append(attribution)\n",
    "        return attributions\n",
    "\n",
    "    def _compute_attributions_tensor_input(self,\n",
    "                                           X: Union[np.ndarray, tf.Tensor],\n",
    "                                           baselines: Union[np.ndarray, tf.Tensor],\n",
    "                                           target: Optional[List[int]],\n",
    "                                           step_sizes: List[float],\n",
    "                                           alphas: List[float],\n",
    "                                           nb_samples: int,\n",
    "                                           forward_kwargs: Optional[dict],\n",
    "                                           compute_layer_inputs_gradients: bool) -> List:\n",
    "        \"\"\"For a single input tensor, calculates the attributions for each input feature or element of layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X\n",
    "            Instance for which integrated gradients attribution are computed.\n",
    "        baselines\n",
    "            Baselines (starting point of the path integral) for each instance.\n",
    "        target\n",
    "            Defines which element of the model output is considered to compute the gradients.\n",
    "        step_sizes\n",
    "            Weights in the path integral sum.\n",
    "        alphas\n",
    "            Interpolation parameter defining the points of the interal path.\n",
    "        nb_samples\n",
    "            Total number of samples.\n",
    "        forward_kwargs\n",
    "            Inputs keywords args.\n",
    "        compute_layer_inputs_gradients\n",
    "            In case of layers gradients, controls whether the gradients are computed for the layer's inputs or\n",
    "            outputs. If True, gradients are computed for the layer's inputs, if False for the layer's outputs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tuple with integrated gradients attributions, deltas and predictions\n",
    "        \"\"\"\n",
    "        # define paths in features's or layers' space\n",
    "        paths = np.concatenate([baselines + alphas[i] * (X - baselines) for i in range(self.n_steps)], axis=0)\n",
    "\n",
    "        if forward_kwargs is not None:\n",
    "            paths_kwargs = {k: np.concatenate([forward_kwargs[k] for _ in range(self.n_steps)], axis=0)\n",
    "                            for k in forward_kwargs.keys()}\n",
    "        else:\n",
    "            paths_kwargs = None\n",
    "\n",
    "        # define target paths\n",
    "        if target is not None:\n",
    "            target_paths = np.concatenate([target for _ in range(self.n_steps)], axis=0)\n",
    "        else:\n",
    "            target_paths = None\n",
    "\n",
    "        if forward_kwargs is not None:\n",
    "            if target_paths is not None:\n",
    "                ds_args = (paths, paths_kwargs, target_paths)\n",
    "            else:\n",
    "                ds_args = (paths, paths_kwargs)  # type: ignore\n",
    "        else:\n",
    "            if target_paths is not None:\n",
    "                ds_args = (paths, target_paths)  # type: ignore\n",
    "            else:\n",
    "                ds_args = paths\n",
    "\n",
    "        paths_ds = tf.data.Dataset.from_tensor_slices(ds_args).batch(self.internal_batch_size)\n",
    "        paths_ds.as_numpy_iterator()\n",
    "        paths_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        # calculate gradients for batches\n",
    "        batches = []\n",
    "        for path in paths_ds:\n",
    "            if forward_kwargs is not None:\n",
    "                if target is not None:\n",
    "                    paths_b, kwargs_b, target_b = path\n",
    "                else:\n",
    "                    paths_b, kwargs_b = path\n",
    "                    target_b = None\n",
    "            else:\n",
    "                kwargs_b = None\n",
    "                if target is not None:\n",
    "                    paths_b, target_b = path\n",
    "                else:\n",
    "                    paths_b, target_b = path, None\n",
    "\n",
    "            if self.layer is None:\n",
    "                grads_b = _gradients_input(self.model, paths_b, target_b, forward_kwargs=kwargs_b)\n",
    "\n",
    "            else:\n",
    "                grads_b = _gradients_layer(self.model,\n",
    "                                           self.layer,\n",
    "                                           self.orig_call,\n",
    "                                           self.orig_dummy_input,\n",
    "                                           paths_b,\n",
    "                                           target_b,\n",
    "                                           forward_kwargs=kwargs_b,\n",
    "                                           compute_layer_inputs_gradients=compute_layer_inputs_gradients)\n",
    "\n",
    "            batches.append(grads_b)\n",
    "\n",
    "        # calculate attributions from gradients batches\n",
    "        attributions = []\n",
    "        sum_int = _calculate_sum_int([batches], self.model,\n",
    "                                     target, target_paths,\n",
    "                                     self.n_steps, nb_samples,\n",
    "                                     step_sizes, 0)\n",
    "        #print('sum_int shape: ', sum_int.shape)\n",
    "        norm = X - baselines\n",
    "\n",
    "        attribution = norm * sum_int\n",
    "        attributions.append(attribution)\n",
    "\n",
    "        return attributions\n",
    "    def _mk(self) -> List:\n",
    "        step_sizes_func, mk_func = approximation_parameters(self.method)\n",
    "        step_sizes, mk = step_sizes_func(self.n_steps), mk_func(self.n_steps)\n",
    "        return mk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1J8DFouqmVQ"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape:  (13081, 1001, 32)\n",
      "xtrain_attr shape:  (13081, 1001, 32)\n",
      "ytrain shape:  (13081, 36)\n",
      "xvalidation shape:  (1454, 1001, 32)\n",
      "xvalidation_attr shape:  (1454, 1001, 32)\n",
      "yvalidation shape:  (1454, 36)\n",
      "newtrain shape:  (1000, 1001, 32)\n",
      "newvalidation shape:  (100, 1001, 32)\n",
      "attr_train shape:  (2000, 1001, 32)\n",
      "attr_validation shape:  (200, 1001, 32)\n"
     ]
    }
   ],
   "source": [
    "xtrain = loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Max-len-1000/x_train[0]_0.npy')\n",
    "xtrain_attr = loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Attribution_all/x_newtrain_attribution_code.npy')\n",
    "ytrain = loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Max-len-1000/y_train[0]_0.npy')\n",
    "xvalidation = loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Max-len-1000/x_validation[0]_0.npy')\n",
    "xvalidation_attr = loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Attribution_all/x_newvalidation_attribution_code.npy')\n",
    "yvalidation = loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Max-len-1000/y_validation[0]_0.npy')\n",
    "xtrain = model.layers[1](xtrain)[0]\n",
    "xvalidation = model.layers[1](xvalidation)[0]\n",
    "print('xtrain shape: ', xtrain.shape)\n",
    "print('xtrain_attr shape: ', xtrain_attr.shape)\n",
    "print('ytrain shape: ', ytrain.shape)\n",
    "print('xvalidation shape: ', xvalidation.shape)\n",
    "print('xvalidation_attr shape: ', xvalidation_attr.shape)\n",
    "print('yvalidation shape: ', yvalidation.shape)\n",
    "num_train = len(xtrain) #215 len(xtrain)\n",
    "num_validation = len(xvalidation) # 215 len(xvalidation)\n",
    "newtrain = np.zeros( (num_train, 1001, 32) )\n",
    "newtrain = np.asarray(newtrain).astype('float32')\n",
    "print('newtrain shape: ', newtrain.shape)\n",
    "newvalidation = np.zeros( (num_validation, 1001, 32) )\n",
    "newvalidation = np.asarray(newvalidation).astype('float32')\n",
    "print('newvalidation shape: ', newvalidation.shape)\n",
    "attr_train = np.zeros( (num_train*2, 1001, 32) )\n",
    "attr_train = np.asarray(attr_train).astype('float32')\n",
    "print('attr_train shape: ', attr_train.shape)\n",
    "attr_validation = np.zeros( (num_validation*2, 1001, 32) )\n",
    "attr_validation = np.asarray(attr_validation).astype('float32')\n",
    "print('attr_validation shape: ', attr_validation.shape)\n",
    "binary_acc_train = []\n",
    "binary_acc_validation = []\n",
    "attr_mse_train = []\n",
    "attr_mse_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  [1674]\n",
      "----- loop 0 :  [1674]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.22875928878784\n",
      "train data delta_a time:  1353.5297305583954\n",
      "train data time:  1419.7584898471832\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.630934953689575\n",
      "validation data delta_a time:  122.06603646278381\n",
      "validation data time:  128.6969714164734\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 19s - loss: 0.8997 - binary_accuracy: 0.9371 - val_loss: 0.6323 - val_binary_accuracy: 0.9360 - 19s/epoch - 304ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.5011 - binary_accuracy: 0.9339 - val_loss: 0.4003 - val_binary_accuracy: 0.9257 - 8s/epoch - 122ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 0.3440 - binary_accuracy: 0.9281 - val_loss: 0.3055 - val_binary_accuracy: 0.9250 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 0.2785 - binary_accuracy: 0.9279 - val_loss: 0.2566 - val_binary_accuracy: 0.9289 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 0.2465 - binary_accuracy: 0.9311 - val_loss: 0.2338 - val_binary_accuracy: 0.9317 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 0.2203 - binary_accuracy: 0.9350 - val_loss: 0.2168 - val_binary_accuracy: 0.9385 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 0.2068 - binary_accuracy: 0.9390 - val_loss: 0.2100 - val_binary_accuracy: 0.9374 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 0.1907 - binary_accuracy: 0.9424 - val_loss: 0.1930 - val_binary_accuracy: 0.9431 - 8s/epoch - 122ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 0.1792 - binary_accuracy: 0.9459 - val_loss: 0.1799 - val_binary_accuracy: 0.9456 - 8s/epoch - 122ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 0.1722 - binary_accuracy: 0.9478 - val_loss: 0.1757 - val_binary_accuracy: 0.9472 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 0.1637 - binary_accuracy: 0.9496 - val_loss: 0.1673 - val_binary_accuracy: 0.9490 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 0.1583 - binary_accuracy: 0.9514 - val_loss: 0.1663 - val_binary_accuracy: 0.9482 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 0.1548 - binary_accuracy: 0.9516 - val_loss: 0.1588 - val_binary_accuracy: 0.9507 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 0.1506 - binary_accuracy: 0.9532 - val_loss: 0.1565 - val_binary_accuracy: 0.9507 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 0.1466 - binary_accuracy: 0.9543 - val_loss: 0.1572 - val_binary_accuracy: 0.9539 - 8s/epoch - 120ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 0.1427 - binary_accuracy: 0.9541 - val_loss: 0.1523 - val_binary_accuracy: 0.9549 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 0.1402 - binary_accuracy: 0.9552 - val_loss: 0.1507 - val_binary_accuracy: 0.9542 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 0.1376 - binary_accuracy: 0.9556 - val_loss: 0.1473 - val_binary_accuracy: 0.9554 - 8s/epoch - 122ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 0.1324 - binary_accuracy: 0.9567 - val_loss: 0.1494 - val_binary_accuracy: 0.9551 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 0.1324 - binary_accuracy: 0.9570 - val_loss: 0.1453 - val_binary_accuracy: 0.9560 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 0.1297 - binary_accuracy: 0.9577 - val_loss: 0.1447 - val_binary_accuracy: 0.9557 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 0.1261 - binary_accuracy: 0.9586 - val_loss: 0.1415 - val_binary_accuracy: 0.9571 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 0.1245 - binary_accuracy: 0.9589 - val_loss: 0.1393 - val_binary_accuracy: 0.9578 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 0.1234 - binary_accuracy: 0.9590 - val_loss: 0.1430 - val_binary_accuracy: 0.9568 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 0.1201 - binary_accuracy: 0.9598 - val_loss: 0.1366 - val_binary_accuracy: 0.9579 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 0.1169 - binary_accuracy: 0.9608 - val_loss: 0.1369 - val_binary_accuracy: 0.9581 - 8s/epoch - 123ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 0.1160 - binary_accuracy: 0.9607 - val_loss: 0.1399 - val_binary_accuracy: 0.9582 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 0.1142 - binary_accuracy: 0.9609 - val_loss: 0.1381 - val_binary_accuracy: 0.9588 - 8s/epoch - 122ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 0.1107 - binary_accuracy: 0.9619 - val_loss: 0.1328 - val_binary_accuracy: 0.9600 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 0.1110 - binary_accuracy: 0.9618 - val_loss: 0.1336 - val_binary_accuracy: 0.9600 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 0.1087 - binary_accuracy: 0.9624 - val_loss: 0.1334 - val_binary_accuracy: 0.9583 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 0.1048 - binary_accuracy: 0.9636 - val_loss: 0.1339 - val_binary_accuracy: 0.9600 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 0.1048 - binary_accuracy: 0.9635 - val_loss: 0.1326 - val_binary_accuracy: 0.9599 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 0.1016 - binary_accuracy: 0.9647 - val_loss: 0.1319 - val_binary_accuracy: 0.9607 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 0.1000 - binary_accuracy: 0.9653 - val_loss: 0.1316 - val_binary_accuracy: 0.9610 - 8s/epoch - 123ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 0.0980 - binary_accuracy: 0.9656 - val_loss: 0.1315 - val_binary_accuracy: 0.9597 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 0.0955 - binary_accuracy: 0.9663 - val_loss: 0.1263 - val_binary_accuracy: 0.9607 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 0.0956 - binary_accuracy: 0.9666 - val_loss: 0.1303 - val_binary_accuracy: 0.9601 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 0.0927 - binary_accuracy: 0.9670 - val_loss: 0.1280 - val_binary_accuracy: 0.9613 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 0.0911 - binary_accuracy: 0.9680 - val_loss: 0.1269 - val_binary_accuracy: 0.9610 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 0.0885 - binary_accuracy: 0.9691 - val_loss: 0.1248 - val_binary_accuracy: 0.9601 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 0.0887 - binary_accuracy: 0.9681 - val_loss: 0.1219 - val_binary_accuracy: 0.9625 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 0.0858 - binary_accuracy: 0.9696 - val_loss: 0.1240 - val_binary_accuracy: 0.9614 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 0.0833 - binary_accuracy: 0.9703 - val_loss: 0.1252 - val_binary_accuracy: 0.9625 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 0.0824 - binary_accuracy: 0.9707 - val_loss: 0.1206 - val_binary_accuracy: 0.9633 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 0.0806 - binary_accuracy: 0.9713 - val_loss: 0.1210 - val_binary_accuracy: 0.9629 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 0.0780 - binary_accuracy: 0.9716 - val_loss: 0.1200 - val_binary_accuracy: 0.9639 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 0.0760 - binary_accuracy: 0.9730 - val_loss: 0.1178 - val_binary_accuracy: 0.9644 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 0.0744 - binary_accuracy: 0.9731 - val_loss: 0.1190 - val_binary_accuracy: 0.9635 - 8s/epoch - 122ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 0.0735 - binary_accuracy: 0.9736 - val_loss: 0.1186 - val_binary_accuracy: 0.9628 - 8s/epoch - 122ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 0.0705 - binary_accuracy: 0.9744 - val_loss: 0.1174 - val_binary_accuracy: 0.9646 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 0.0702 - binary_accuracy: 0.9745 - val_loss: 0.1202 - val_binary_accuracy: 0.9629 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 0.0664 - binary_accuracy: 0.9761 - val_loss: 0.1203 - val_binary_accuracy: 0.9628 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 0.0656 - binary_accuracy: 0.9760 - val_loss: 0.1197 - val_binary_accuracy: 0.9635 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 0.0650 - binary_accuracy: 0.9761 - val_loss: 0.1149 - val_binary_accuracy: 0.9638 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 0.0620 - binary_accuracy: 0.9776 - val_loss: 0.1154 - val_binary_accuracy: 0.9642 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 0.0614 - binary_accuracy: 0.9783 - val_loss: 0.1155 - val_binary_accuracy: 0.9653 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 0.0601 - binary_accuracy: 0.9779 - val_loss: 0.1186 - val_binary_accuracy: 0.9647 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 0.0577 - binary_accuracy: 0.9794 - val_loss: 0.1161 - val_binary_accuracy: 0.9664 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 0.0561 - binary_accuracy: 0.9797 - val_loss: 0.1188 - val_binary_accuracy: 0.9646 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 0.0545 - binary_accuracy: 0.9800 - val_loss: 0.1135 - val_binary_accuracy: 0.9649 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 0.0544 - binary_accuracy: 0.9805 - val_loss: 0.1140 - val_binary_accuracy: 0.9639 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 0.0528 - binary_accuracy: 0.9808 - val_loss: 0.1172 - val_binary_accuracy: 0.9654 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 0.0509 - binary_accuracy: 0.9813 - val_loss: 0.1159 - val_binary_accuracy: 0.9656 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 0.0502 - binary_accuracy: 0.9813 - val_loss: 0.1129 - val_binary_accuracy: 0.9656 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 0.0480 - binary_accuracy: 0.9825 - val_loss: 0.1137 - val_binary_accuracy: 0.9650 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 0.0472 - binary_accuracy: 0.9828 - val_loss: 0.1137 - val_binary_accuracy: 0.9651 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 0.0445 - binary_accuracy: 0.9841 - val_loss: 0.1244 - val_binary_accuracy: 0.9656 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 0.0436 - binary_accuracy: 0.9839 - val_loss: 0.1164 - val_binary_accuracy: 0.9669 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 0.0423 - binary_accuracy: 0.9847 - val_loss: 0.1203 - val_binary_accuracy: 0.9653 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 0.0404 - binary_accuracy: 0.9852 - val_loss: 0.1244 - val_binary_accuracy: 0.9661 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 0.0383 - binary_accuracy: 0.9855 - val_loss: 0.1207 - val_binary_accuracy: 0.9665 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 0.0382 - binary_accuracy: 0.9863 - val_loss: 0.1194 - val_binary_accuracy: 0.9669 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 0.0374 - binary_accuracy: 0.9865 - val_loss: 0.1247 - val_binary_accuracy: 0.9664 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 0.0358 - binary_accuracy: 0.9871 - val_loss: 0.1236 - val_binary_accuracy: 0.9674 - 8s/epoch - 122ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 0.0353 - binary_accuracy: 0.9873 - val_loss: 0.1193 - val_binary_accuracy: 0.9678 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 0.0330 - binary_accuracy: 0.9882 - val_loss: 0.1216 - val_binary_accuracy: 0.9682 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 0.0319 - binary_accuracy: 0.9887 - val_loss: 0.1243 - val_binary_accuracy: 0.9664 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 0.0325 - binary_accuracy: 0.9889 - val_loss: 0.1210 - val_binary_accuracy: 0.9686 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 0.0299 - binary_accuracy: 0.9896 - val_loss: 0.1210 - val_binary_accuracy: 0.9687 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 0.0295 - binary_accuracy: 0.9894 - val_loss: 0.1215 - val_binary_accuracy: 0.9683 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 0.0289 - binary_accuracy: 0.9899 - val_loss: 0.1288 - val_binary_accuracy: 0.9675 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 0.0279 - binary_accuracy: 0.9907 - val_loss: 0.1260 - val_binary_accuracy: 0.9694 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 0.0263 - binary_accuracy: 0.9904 - val_loss: 0.1195 - val_binary_accuracy: 0.9688 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 0.0256 - binary_accuracy: 0.9907 - val_loss: 0.1203 - val_binary_accuracy: 0.9689 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 0.0247 - binary_accuracy: 0.9913 - val_loss: 0.1248 - val_binary_accuracy: 0.9707 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 0.0241 - binary_accuracy: 0.9913 - val_loss: 0.1231 - val_binary_accuracy: 0.9689 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 0.0230 - binary_accuracy: 0.9918 - val_loss: 0.1191 - val_binary_accuracy: 0.9703 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 0.0224 - binary_accuracy: 0.9921 - val_loss: 0.1286 - val_binary_accuracy: 0.9685 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 0.0214 - binary_accuracy: 0.9923 - val_loss: 0.1265 - val_binary_accuracy: 0.9688 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 0.0207 - binary_accuracy: 0.9927 - val_loss: 0.1240 - val_binary_accuracy: 0.9699 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 0.0200 - binary_accuracy: 0.9931 - val_loss: 0.1185 - val_binary_accuracy: 0.9706 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 0.0202 - binary_accuracy: 0.9932 - val_loss: 0.1276 - val_binary_accuracy: 0.9707 - 8s/epoch - 120ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 0.0186 - binary_accuracy: 0.9934 - val_loss: 0.1249 - val_binary_accuracy: 0.9706 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 0.0185 - binary_accuracy: 0.9938 - val_loss: 0.1253 - val_binary_accuracy: 0.9710 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 0.0176 - binary_accuracy: 0.9936 - val_loss: 0.1274 - val_binary_accuracy: 0.9706 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 0.0163 - binary_accuracy: 0.9944 - val_loss: 0.1258 - val_binary_accuracy: 0.9692 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 0.0164 - binary_accuracy: 0.9943 - val_loss: 0.1303 - val_binary_accuracy: 0.9696 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 0.0156 - binary_accuracy: 0.9946 - val_loss: 0.1338 - val_binary_accuracy: 0.9693 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 7s - loss: 0.0149 - binary_accuracy: 0.9950 - val_loss: 0.1306 - val_binary_accuracy: 0.9715 - 7s/epoch - 119ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.9949724674224854\n",
      "binary_accuracy validation:  0.9715276956558228\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049116034\n",
      "train attribution time:  403.5409655570984\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03808578\n",
      "validation attribution time:  40.45628762245178\n",
      "time:  2768.4370653629303\n",
      "----- loop 1 :  [1695]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  65.29773211479187\n",
      "train data delta_a time:  1340.0521700382233\n",
      "train data time:  1405.3499021530151\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.457917928695679\n",
      "validation data delta_a time:  122.24373626708984\n",
      "validation data time:  128.70165419578552\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0619 - binary_accuracy: 0.9833 - val_loss: 0.0913 - val_binary_accuracy: 0.9718 - 18s/epoch - 291ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.0492 - binary_accuracy: 0.9842 - val_loss: 0.0884 - val_binary_accuracy: 0.9729 - 8s/epoch - 119ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 0.0442 - binary_accuracy: 0.9855 - val_loss: 0.0855 - val_binary_accuracy: 0.9726 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 0.0399 - binary_accuracy: 0.9871 - val_loss: 0.0870 - val_binary_accuracy: 0.9740 - 8s/epoch - 119ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 0.0368 - binary_accuracy: 0.9875 - val_loss: 0.0834 - val_binary_accuracy: 0.9746 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 0.0358 - binary_accuracy: 0.9879 - val_loss: 0.0798 - val_binary_accuracy: 0.9765 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 0.0320 - binary_accuracy: 0.9887 - val_loss: 0.0864 - val_binary_accuracy: 0.9746 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 0.0298 - binary_accuracy: 0.9897 - val_loss: 0.0826 - val_binary_accuracy: 0.9754 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 0.0296 - binary_accuracy: 0.9901 - val_loss: 0.0817 - val_binary_accuracy: 0.9774 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 0.0279 - binary_accuracy: 0.9905 - val_loss: 0.0787 - val_binary_accuracy: 0.9769 - 8s/epoch - 120ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 0.0277 - binary_accuracy: 0.9906 - val_loss: 0.0762 - val_binary_accuracy: 0.9765 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 0.0260 - binary_accuracy: 0.9913 - val_loss: 0.0823 - val_binary_accuracy: 0.9767 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 0.0245 - binary_accuracy: 0.9914 - val_loss: 0.0782 - val_binary_accuracy: 0.9767 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 0.0235 - binary_accuracy: 0.9921 - val_loss: 0.0797 - val_binary_accuracy: 0.9767 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 0.0224 - binary_accuracy: 0.9923 - val_loss: 0.0777 - val_binary_accuracy: 0.9772 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 0.0212 - binary_accuracy: 0.9925 - val_loss: 0.0764 - val_binary_accuracy: 0.9778 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 0.0197 - binary_accuracy: 0.9932 - val_loss: 0.0791 - val_binary_accuracy: 0.9775 - 8s/epoch - 120ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 0.0197 - binary_accuracy: 0.9937 - val_loss: 0.0772 - val_binary_accuracy: 0.9772 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 0.0192 - binary_accuracy: 0.9937 - val_loss: 0.0780 - val_binary_accuracy: 0.9779 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 0.0169 - binary_accuracy: 0.9942 - val_loss: 0.0779 - val_binary_accuracy: 0.9776 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 0.0165 - binary_accuracy: 0.9944 - val_loss: 0.0815 - val_binary_accuracy: 0.9768 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 0.0161 - binary_accuracy: 0.9946 - val_loss: 0.0744 - val_binary_accuracy: 0.9775 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 0.0156 - binary_accuracy: 0.9947 - val_loss: 0.0774 - val_binary_accuracy: 0.9783 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 0.0147 - binary_accuracy: 0.9950 - val_loss: 0.0762 - val_binary_accuracy: 0.9782 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 0.0149 - binary_accuracy: 0.9950 - val_loss: 0.0781 - val_binary_accuracy: 0.9794 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 0.0142 - binary_accuracy: 0.9953 - val_loss: 0.0792 - val_binary_accuracy: 0.9789 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 0.0138 - binary_accuracy: 0.9954 - val_loss: 0.0798 - val_binary_accuracy: 0.9774 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 0.0122 - binary_accuracy: 0.9961 - val_loss: 0.0783 - val_binary_accuracy: 0.9782 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 0.0109 - binary_accuracy: 0.9964 - val_loss: 0.0780 - val_binary_accuracy: 0.9789 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 0.0113 - binary_accuracy: 0.9963 - val_loss: 0.0752 - val_binary_accuracy: 0.9785 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 0.0115 - binary_accuracy: 0.9962 - val_loss: 0.0756 - val_binary_accuracy: 0.9782 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 0.0105 - binary_accuracy: 0.9963 - val_loss: 0.0846 - val_binary_accuracy: 0.9782 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 0.0099 - binary_accuracy: 0.9967 - val_loss: 0.0765 - val_binary_accuracy: 0.9801 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 0.0100 - binary_accuracy: 0.9966 - val_loss: 0.0780 - val_binary_accuracy: 0.9803 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 0.0106 - binary_accuracy: 0.9967 - val_loss: 0.0815 - val_binary_accuracy: 0.9793 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 0.0088 - binary_accuracy: 0.9973 - val_loss: 0.0794 - val_binary_accuracy: 0.9806 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 0.0088 - binary_accuracy: 0.9972 - val_loss: 0.0846 - val_binary_accuracy: 0.9785 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 0.0084 - binary_accuracy: 0.9972 - val_loss: 0.0844 - val_binary_accuracy: 0.9783 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 0.0078 - binary_accuracy: 0.9975 - val_loss: 0.0815 - val_binary_accuracy: 0.9807 - 8s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 0.0081 - binary_accuracy: 0.9973 - val_loss: 0.0804 - val_binary_accuracy: 0.9796 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 0.0076 - binary_accuracy: 0.9977 - val_loss: 0.0817 - val_binary_accuracy: 0.9801 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 0.0073 - binary_accuracy: 0.9977 - val_loss: 0.0806 - val_binary_accuracy: 0.9801 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 0.0074 - binary_accuracy: 0.9977 - val_loss: 0.0844 - val_binary_accuracy: 0.9796 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 0.0073 - binary_accuracy: 0.9977 - val_loss: 0.0796 - val_binary_accuracy: 0.9796 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 0.0065 - binary_accuracy: 0.9980 - val_loss: 0.0820 - val_binary_accuracy: 0.9794 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 0.0068 - binary_accuracy: 0.9977 - val_loss: 0.0794 - val_binary_accuracy: 0.9804 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 0.0061 - binary_accuracy: 0.9981 - val_loss: 0.0848 - val_binary_accuracy: 0.9792 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 0.0065 - binary_accuracy: 0.9981 - val_loss: 0.0846 - val_binary_accuracy: 0.9808 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 0.0066 - binary_accuracy: 0.9980 - val_loss: 0.0806 - val_binary_accuracy: 0.9807 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 0.0053 - binary_accuracy: 0.9985 - val_loss: 0.0816 - val_binary_accuracy: 0.9807 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 0.0053 - binary_accuracy: 0.9985 - val_loss: 0.0846 - val_binary_accuracy: 0.9797 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 0.0053 - binary_accuracy: 0.9986 - val_loss: 0.0820 - val_binary_accuracy: 0.9804 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 0.0047 - binary_accuracy: 0.9986 - val_loss: 0.0876 - val_binary_accuracy: 0.9803 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 0.0052 - binary_accuracy: 0.9984 - val_loss: 0.0820 - val_binary_accuracy: 0.9804 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 0.0049 - binary_accuracy: 0.9987 - val_loss: 0.0869 - val_binary_accuracy: 0.9815 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 0.0045 - binary_accuracy: 0.9987 - val_loss: 0.0967 - val_binary_accuracy: 0.9806 - 8s/epoch - 120ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 0.0044 - binary_accuracy: 0.9987 - val_loss: 0.0839 - val_binary_accuracy: 0.9803 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 0.0041 - binary_accuracy: 0.9988 - val_loss: 0.0890 - val_binary_accuracy: 0.9811 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 0.0041 - binary_accuracy: 0.9989 - val_loss: 0.0888 - val_binary_accuracy: 0.9803 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 0.0037 - binary_accuracy: 0.9991 - val_loss: 0.0946 - val_binary_accuracy: 0.9796 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 0.0036 - binary_accuracy: 0.9991 - val_loss: 0.0871 - val_binary_accuracy: 0.9794 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 0.0041 - binary_accuracy: 0.9988 - val_loss: 0.0899 - val_binary_accuracy: 0.9807 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 0.0038 - binary_accuracy: 0.9989 - val_loss: 0.0932 - val_binary_accuracy: 0.9811 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 0.0037 - binary_accuracy: 0.9990 - val_loss: 0.0914 - val_binary_accuracy: 0.9803 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 0.0041 - binary_accuracy: 0.9987 - val_loss: 0.0883 - val_binary_accuracy: 0.9807 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 0.0034 - binary_accuracy: 0.9991 - val_loss: 0.0892 - val_binary_accuracy: 0.9811 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 0.0030 - binary_accuracy: 0.9992 - val_loss: 0.0919 - val_binary_accuracy: 0.9810 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 0.0031 - binary_accuracy: 0.9992 - val_loss: 0.0837 - val_binary_accuracy: 0.9821 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 0.0027 - binary_accuracy: 0.9993 - val_loss: 0.0904 - val_binary_accuracy: 0.9815 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 0.0031 - binary_accuracy: 0.9991 - val_loss: 0.0921 - val_binary_accuracy: 0.9810 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 0.0030 - binary_accuracy: 0.9992 - val_loss: 0.0864 - val_binary_accuracy: 0.9824 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 0.0027 - binary_accuracy: 0.9994 - val_loss: 0.0947 - val_binary_accuracy: 0.9818 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 0.0024 - binary_accuracy: 0.9993 - val_loss: 0.0872 - val_binary_accuracy: 0.9824 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 0.0025 - binary_accuracy: 0.9994 - val_loss: 0.0870 - val_binary_accuracy: 0.9815 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 0.0026 - binary_accuracy: 0.9994 - val_loss: 0.0923 - val_binary_accuracy: 0.9806 - 8s/epoch - 120ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 0.0023 - binary_accuracy: 0.9994 - val_loss: 0.0918 - val_binary_accuracy: 0.9810 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 0.0025 - binary_accuracy: 0.9994 - val_loss: 0.0968 - val_binary_accuracy: 0.9813 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 0.0023 - binary_accuracy: 0.9995 - val_loss: 0.1014 - val_binary_accuracy: 0.9811 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 0.0022 - binary_accuracy: 0.9994 - val_loss: 0.0996 - val_binary_accuracy: 0.9810 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 0.0022 - binary_accuracy: 0.9994 - val_loss: 0.0927 - val_binary_accuracy: 0.9812 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 0.0020 - binary_accuracy: 0.9995 - val_loss: 0.0915 - val_binary_accuracy: 0.9815 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 0.0023 - binary_accuracy: 0.9994 - val_loss: 0.0977 - val_binary_accuracy: 0.9819 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 0.0018 - binary_accuracy: 0.9996 - val_loss: 0.1035 - val_binary_accuracy: 0.9804 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 0.0019 - binary_accuracy: 0.9996 - val_loss: 0.0959 - val_binary_accuracy: 0.9814 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 0.0021 - binary_accuracy: 0.9995 - val_loss: 0.0963 - val_binary_accuracy: 0.9808 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0932 - val_binary_accuracy: 0.9818 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 0.0020 - binary_accuracy: 0.9995 - val_loss: 0.0899 - val_binary_accuracy: 0.9819 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 0.0018 - binary_accuracy: 0.9996 - val_loss: 0.0992 - val_binary_accuracy: 0.9808 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 0.0017 - binary_accuracy: 0.9996 - val_loss: 0.0945 - val_binary_accuracy: 0.9815 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 0.0021 - binary_accuracy: 0.9994 - val_loss: 0.1020 - val_binary_accuracy: 0.9821 - 8s/epoch - 122ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 0.0017 - binary_accuracy: 0.9996 - val_loss: 0.0987 - val_binary_accuracy: 0.9797 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 0.0015 - binary_accuracy: 0.9996 - val_loss: 0.0999 - val_binary_accuracy: 0.9824 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 0.0015 - binary_accuracy: 0.9996 - val_loss: 0.1014 - val_binary_accuracy: 0.9814 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 0.0014 - binary_accuracy: 0.9996 - val_loss: 0.1070 - val_binary_accuracy: 0.9810 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 0.0013 - binary_accuracy: 0.9997 - val_loss: 0.0991 - val_binary_accuracy: 0.9814 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 0.0015 - binary_accuracy: 0.9997 - val_loss: 0.1014 - val_binary_accuracy: 0.9804 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 0.0011 - binary_accuracy: 0.9998 - val_loss: 0.1049 - val_binary_accuracy: 0.9808 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 0.0013 - binary_accuracy: 0.9998 - val_loss: 0.1003 - val_binary_accuracy: 0.9821 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 0.0015 - binary_accuracy: 0.9996 - val_loss: 0.1058 - val_binary_accuracy: 0.9822 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 0.0015 - binary_accuracy: 0.9997 - val_loss: 0.0991 - val_binary_accuracy: 0.9803 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.999694287776947\n",
      "binary_accuracy validation:  0.9802777171134949\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049176626\n",
      "train attribution time:  402.4188210964203\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03798837\n",
      "validation attribution time:  40.765668630599976\n",
      "time:  2749.2699563503265\n",
      "----- loop 2 :  [1697]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.39170694351196\n",
      "train data delta_a time:  1337.1609075069427\n",
      "train data time:  1403.5526144504547\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.49711799621582\n",
      "validation data delta_a time:  121.62861371040344\n",
      "validation data time:  129.12573170661926\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 19s - loss: 0.0138 - binary_accuracy: 0.9963 - val_loss: 0.0766 - val_binary_accuracy: 0.9825 - 19s/epoch - 295ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.0087 - binary_accuracy: 0.9972 - val_loss: 0.0713 - val_binary_accuracy: 0.9824 - 8s/epoch - 119ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 0.0068 - binary_accuracy: 0.9975 - val_loss: 0.0698 - val_binary_accuracy: 0.9842 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 0.0055 - binary_accuracy: 0.9981 - val_loss: 0.0714 - val_binary_accuracy: 0.9853 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 0.0044 - binary_accuracy: 0.9985 - val_loss: 0.0691 - val_binary_accuracy: 0.9851 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 0.0042 - binary_accuracy: 0.9985 - val_loss: 0.0685 - val_binary_accuracy: 0.9863 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 0.0034 - binary_accuracy: 0.9990 - val_loss: 0.0669 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 0.0033 - binary_accuracy: 0.9989 - val_loss: 0.0707 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 0.0028 - binary_accuracy: 0.9991 - val_loss: 0.0680 - val_binary_accuracy: 0.9857 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 0.0035 - binary_accuracy: 0.9989 - val_loss: 0.0687 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 0.0027 - binary_accuracy: 0.9991 - val_loss: 0.0679 - val_binary_accuracy: 0.9853 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 0.0024 - binary_accuracy: 0.9993 - val_loss: 0.0709 - val_binary_accuracy: 0.9844 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 0.0022 - binary_accuracy: 0.9992 - val_loss: 0.0684 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 0.0020 - binary_accuracy: 0.9994 - val_loss: 0.0699 - val_binary_accuracy: 0.9851 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 0.0023 - binary_accuracy: 0.9993 - val_loss: 0.0692 - val_binary_accuracy: 0.9853 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 0.0023 - binary_accuracy: 0.9991 - val_loss: 0.0712 - val_binary_accuracy: 0.9844 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 0.0020 - binary_accuracy: 0.9994 - val_loss: 0.0703 - val_binary_accuracy: 0.9857 - 8s/epoch - 120ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 0.0017 - binary_accuracy: 0.9995 - val_loss: 0.0744 - val_binary_accuracy: 0.9854 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 0.0018 - binary_accuracy: 0.9996 - val_loss: 0.0713 - val_binary_accuracy: 0.9850 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 0.0017 - binary_accuracy: 0.9996 - val_loss: 0.0755 - val_binary_accuracy: 0.9844 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 0.0016 - binary_accuracy: 0.9995 - val_loss: 0.0749 - val_binary_accuracy: 0.9847 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 0.0014 - binary_accuracy: 0.9997 - val_loss: 0.0785 - val_binary_accuracy: 0.9842 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 0.0014 - binary_accuracy: 0.9996 - val_loss: 0.0737 - val_binary_accuracy: 0.9850 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 0.0013 - binary_accuracy: 0.9997 - val_loss: 0.0710 - val_binary_accuracy: 0.9851 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 0.0011 - binary_accuracy: 0.9997 - val_loss: 0.0770 - val_binary_accuracy: 0.9847 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 0.0013 - binary_accuracy: 0.9997 - val_loss: 0.0766 - val_binary_accuracy: 0.9856 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 0.0011 - binary_accuracy: 0.9997 - val_loss: 0.0761 - val_binary_accuracy: 0.9835 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 0.0014 - binary_accuracy: 0.9995 - val_loss: 0.0754 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 0.0768 - val_binary_accuracy: 0.9856 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 0.0011 - binary_accuracy: 0.9997 - val_loss: 0.0813 - val_binary_accuracy: 0.9853 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 0.0011 - binary_accuracy: 0.9998 - val_loss: 0.0760 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 9.2879e-04 - binary_accuracy: 0.9998 - val_loss: 0.0796 - val_binary_accuracy: 0.9851 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 0.0011 - binary_accuracy: 0.9997 - val_loss: 0.0786 - val_binary_accuracy: 0.9851 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 9.6067e-04 - binary_accuracy: 0.9997 - val_loss: 0.0773 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 8.0829e-04 - binary_accuracy: 0.9999 - val_loss: 0.0823 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 9.9274e-04 - binary_accuracy: 0.9997 - val_loss: 0.0746 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 9.5762e-04 - binary_accuracy: 0.9997 - val_loss: 0.0803 - val_binary_accuracy: 0.9854 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 7.2988e-04 - binary_accuracy: 0.9998 - val_loss: 0.0790 - val_binary_accuracy: 0.9857 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 6.1284e-04 - binary_accuracy: 0.9999 - val_loss: 0.0796 - val_binary_accuracy: 0.9853 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 6.8027e-04 - binary_accuracy: 0.9999 - val_loss: 0.0846 - val_binary_accuracy: 0.9854 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 6.6541e-04 - binary_accuracy: 0.9999 - val_loss: 0.0831 - val_binary_accuracy: 0.9850 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 8.9613e-04 - binary_accuracy: 0.9998 - val_loss: 0.0850 - val_binary_accuracy: 0.9853 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 7.5130e-04 - binary_accuracy: 0.9998 - val_loss: 0.0809 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 8.2470e-04 - binary_accuracy: 0.9998 - val_loss: 0.0781 - val_binary_accuracy: 0.9856 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 6.3195e-04 - binary_accuracy: 0.9999 - val_loss: 0.0754 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 5.3472e-04 - binary_accuracy: 0.9999 - val_loss: 0.0760 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 5.7223e-04 - binary_accuracy: 0.9999 - val_loss: 0.0756 - val_binary_accuracy: 0.9857 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 5.8599e-04 - binary_accuracy: 0.9999 - val_loss: 0.0830 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 6.1445e-04 - binary_accuracy: 0.9998 - val_loss: 0.0817 - val_binary_accuracy: 0.9861 - 8s/epoch - 119ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 6.3227e-04 - binary_accuracy: 0.9998 - val_loss: 0.0763 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 5.7867e-04 - binary_accuracy: 0.9999 - val_loss: 0.0793 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 6.4460e-04 - binary_accuracy: 0.9998 - val_loss: 0.0800 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 5.9799e-04 - binary_accuracy: 0.9998 - val_loss: 0.0801 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 5.7000e-04 - binary_accuracy: 0.9999 - val_loss: 0.0844 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 4.7144e-04 - binary_accuracy: 0.9999 - val_loss: 0.0790 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 5.2576e-04 - binary_accuracy: 0.9999 - val_loss: 0.0792 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 4.6212e-04 - binary_accuracy: 0.9999 - val_loss: 0.0798 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 4.3539e-04 - binary_accuracy: 0.9999 - val_loss: 0.0805 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 5.0850e-04 - binary_accuracy: 0.9999 - val_loss: 0.0764 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 7.3524e-04 - binary_accuracy: 0.9998 - val_loss: 0.0808 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 4.1324e-04 - binary_accuracy: 0.9999 - val_loss: 0.0776 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 3.6174e-04 - binary_accuracy: 0.9999 - val_loss: 0.0792 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 6.6124e-04 - binary_accuracy: 0.9998 - val_loss: 0.0820 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 4.8634e-04 - binary_accuracy: 0.9999 - val_loss: 0.0788 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 4.6010e-04 - binary_accuracy: 0.9998 - val_loss: 0.0841 - val_binary_accuracy: 0.9863 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 4.8772e-04 - binary_accuracy: 0.9999 - val_loss: 0.0817 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 3.8625e-04 - binary_accuracy: 0.9999 - val_loss: 0.0837 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.8802e-04 - binary_accuracy: 0.9999 - val_loss: 0.0814 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 3.4682e-04 - binary_accuracy: 0.9999 - val_loss: 0.0794 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 4.3816e-04 - binary_accuracy: 0.9999 - val_loss: 0.0855 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 3.1556e-04 - binary_accuracy: 1.0000 - val_loss: 0.0819 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 4.7741e-04 - binary_accuracy: 0.9999 - val_loss: 0.0785 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 3.9033e-04 - binary_accuracy: 0.9999 - val_loss: 0.0845 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 4.1772e-04 - binary_accuracy: 0.9999 - val_loss: 0.0837 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 4.0175e-04 - binary_accuracy: 0.9999 - val_loss: 0.0804 - val_binary_accuracy: 0.9856 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 3.4971e-04 - binary_accuracy: 0.9999 - val_loss: 0.0835 - val_binary_accuracy: 0.9853 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 3.5758e-04 - binary_accuracy: 0.9999 - val_loss: 0.0855 - val_binary_accuracy: 0.9849 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 5.0676e-04 - binary_accuracy: 0.9998 - val_loss: 0.0892 - val_binary_accuracy: 0.9851 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 3.5025e-04 - binary_accuracy: 0.9999 - val_loss: 0.0831 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 4.2181e-04 - binary_accuracy: 0.9999 - val_loss: 0.0808 - val_binary_accuracy: 0.9858 - 8s/epoch - 119ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 3.5691e-04 - binary_accuracy: 0.9999 - val_loss: 0.0803 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.7278e-04 - binary_accuracy: 0.9999 - val_loss: 0.0884 - val_binary_accuracy: 0.9856 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 4.0825e-04 - binary_accuracy: 0.9999 - val_loss: 0.0842 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 3.4253e-04 - binary_accuracy: 0.9999 - val_loss: 0.0818 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.9351e-04 - binary_accuracy: 0.9999 - val_loss: 0.0823 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 2.3744e-04 - binary_accuracy: 1.0000 - val_loss: 0.0835 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.6589e-04 - binary_accuracy: 1.0000 - val_loss: 0.0874 - val_binary_accuracy: 0.9853 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.5929e-04 - binary_accuracy: 0.9999 - val_loss: 0.0827 - val_binary_accuracy: 0.9856 - 8s/epoch - 120ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 6.5118e-04 - binary_accuracy: 0.9998 - val_loss: 0.0910 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 3.2292e-04 - binary_accuracy: 0.9999 - val_loss: 0.0830 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.3482e-04 - binary_accuracy: 1.0000 - val_loss: 0.0904 - val_binary_accuracy: 0.9851 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.1904e-04 - binary_accuracy: 0.9999 - val_loss: 0.0840 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.1729e-04 - binary_accuracy: 1.0000 - val_loss: 0.0842 - val_binary_accuracy: 0.9858 - 8s/epoch - 120ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.8606e-04 - binary_accuracy: 0.9999 - val_loss: 0.0812 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 2.2425e-04 - binary_accuracy: 0.9999 - val_loss: 0.0840 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.7128e-04 - binary_accuracy: 0.9999 - val_loss: 0.0878 - val_binary_accuracy: 0.9863 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.5128e-04 - binary_accuracy: 1.0000 - val_loss: 0.0906 - val_binary_accuracy: 0.9858 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.4836e-04 - binary_accuracy: 1.0000 - val_loss: 0.0893 - val_binary_accuracy: 0.9853 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 3.0695e-04 - binary_accuracy: 0.9999 - val_loss: 0.0873 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 3.1691e-04 - binary_accuracy: 1.0000 - val_loss: 0.0926 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.9999722242355347\n",
      "binary_accuracy validation:  0.9859722256660461\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04920158\n",
      "train attribution time:  403.09050035476685\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037894834\n",
      "validation attribution time:  40.56113886833191\n",
      "time:  2748.0936489105225\n",
      "----- loop 3 :  [1690]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.0529351234436\n",
      "train data delta_a time:  1340.822667837143\n",
      "train data time:  1408.8756029605865\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.267815828323364\n",
      "validation data delta_a time:  119.648517370224\n",
      "validation data time:  126.91633319854736\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0043 - binary_accuracy: 0.9988 - val_loss: 0.0798 - val_binary_accuracy: 0.9860 - 18s/epoch - 290ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.0024 - binary_accuracy: 0.9993 - val_loss: 0.0720 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 7s - loss: 0.0013 - binary_accuracy: 0.9996 - val_loss: 0.0759 - val_binary_accuracy: 0.9864 - 7s/epoch - 119ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 0.0016 - binary_accuracy: 0.9994 - val_loss: 0.0760 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 9.6955e-04 - binary_accuracy: 0.9996 - val_loss: 0.0756 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 6.9077e-04 - binary_accuracy: 0.9999 - val_loss: 0.0746 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 8.1964e-04 - binary_accuracy: 0.9997 - val_loss: 0.0710 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 7.0090e-04 - binary_accuracy: 0.9998 - val_loss: 0.0763 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 5.6831e-04 - binary_accuracy: 0.9998 - val_loss: 0.0763 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 4.5328e-04 - binary_accuracy: 0.9999 - val_loss: 0.0753 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 5.1179e-04 - binary_accuracy: 0.9999 - val_loss: 0.0779 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 5.3613e-04 - binary_accuracy: 0.9998 - val_loss: 0.0772 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 4.9076e-04 - binary_accuracy: 0.9999 - val_loss: 0.0754 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 4.0005e-04 - binary_accuracy: 0.9999 - val_loss: 0.0786 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 2.7860e-04 - binary_accuracy: 1.0000 - val_loss: 0.0789 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 3.3244e-04 - binary_accuracy: 0.9999 - val_loss: 0.0765 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 2.5979e-04 - binary_accuracy: 1.0000 - val_loss: 0.0818 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 2.4768e-04 - binary_accuracy: 1.0000 - val_loss: 0.0803 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 2.1287e-04 - binary_accuracy: 1.0000 - val_loss: 0.0805 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.0705e-04 - binary_accuracy: 0.9999 - val_loss: 0.0850 - val_binary_accuracy: 0.9858 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 3.0150e-04 - binary_accuracy: 0.9999 - val_loss: 0.0822 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 3.0315e-04 - binary_accuracy: 0.9999 - val_loss: 0.0791 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.7968e-04 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.8120e-04 - binary_accuracy: 0.9999 - val_loss: 0.0732 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 9s - loss: 2.4834e-04 - binary_accuracy: 1.0000 - val_loss: 0.0732 - val_binary_accuracy: 0.9874 - 9s/epoch - 135ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.4323e-04 - binary_accuracy: 1.0000 - val_loss: 0.0782 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 2.7125e-04 - binary_accuracy: 1.0000 - val_loss: 0.0838 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.7443e-04 - binary_accuracy: 1.0000 - val_loss: 0.0805 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 2.6956e-04 - binary_accuracy: 0.9999 - val_loss: 0.0764 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 2.0549e-04 - binary_accuracy: 1.0000 - val_loss: 0.0797 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.8334e-04 - binary_accuracy: 1.0000 - val_loss: 0.0837 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.6288e-04 - binary_accuracy: 0.9999 - val_loss: 0.0774 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.0950e-04 - binary_accuracy: 1.0000 - val_loss: 0.0803 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 2.9596e-04 - binary_accuracy: 0.9999 - val_loss: 0.0840 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.1713e-04 - binary_accuracy: 1.0000 - val_loss: 0.0801 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.7696e-04 - binary_accuracy: 1.0000 - val_loss: 0.0869 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 3.2700e-04 - binary_accuracy: 0.9999 - val_loss: 0.0806 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 4.7249e-04 - binary_accuracy: 0.9999 - val_loss: 0.0832 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 4.4299e-04 - binary_accuracy: 0.9999 - val_loss: 0.0825 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.5852e-04 - binary_accuracy: 1.0000 - val_loss: 0.0803 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.2762e-04 - binary_accuracy: 1.0000 - val_loss: 0.0873 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.7020e-04 - binary_accuracy: 1.0000 - val_loss: 0.0834 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.3106e-04 - binary_accuracy: 1.0000 - val_loss: 0.0832 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.4389e-04 - binary_accuracy: 1.0000 - val_loss: 0.0831 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.6094e-04 - binary_accuracy: 1.0000 - val_loss: 0.0776 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.2316e-04 - binary_accuracy: 1.0000 - val_loss: 0.0940 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.4318e-04 - binary_accuracy: 1.0000 - val_loss: 0.0815 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.6945e-04 - binary_accuracy: 0.9999 - val_loss: 0.0878 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.2716e-04 - binary_accuracy: 0.9999 - val_loss: 0.0744 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.0450e-04 - binary_accuracy: 0.9999 - val_loss: 0.0791 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.0747e-04 - binary_accuracy: 1.0000 - val_loss: 0.0902 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 9.4222e-05 - binary_accuracy: 1.0000 - val_loss: 0.0828 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.4692e-04 - binary_accuracy: 1.0000 - val_loss: 0.0893 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.3217e-04 - binary_accuracy: 0.9999 - val_loss: 0.0844 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.4463e-04 - binary_accuracy: 1.0000 - val_loss: 0.0849 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 9.7699e-05 - binary_accuracy: 1.0000 - val_loss: 0.0848 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 9.5238e-05 - binary_accuracy: 1.0000 - val_loss: 0.0882 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 3.6129e-04 - binary_accuracy: 0.9999 - val_loss: 0.0847 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 2.2570e-04 - binary_accuracy: 1.0000 - val_loss: 0.0834 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 9.7565e-05 - binary_accuracy: 1.0000 - val_loss: 0.0957 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.9929e-04 - binary_accuracy: 1.0000 - val_loss: 0.0909 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 8.8328e-05 - binary_accuracy: 1.0000 - val_loss: 0.0865 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.7343e-04 - binary_accuracy: 0.9999 - val_loss: 0.0887 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.7236e-04 - binary_accuracy: 1.0000 - val_loss: 0.0832 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.1267e-04 - binary_accuracy: 1.0000 - val_loss: 0.0832 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.2641e-04 - binary_accuracy: 1.0000 - val_loss: 0.0860 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 6.3001e-05 - binary_accuracy: 1.0000 - val_loss: 0.0856 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.0393e-04 - binary_accuracy: 1.0000 - val_loss: 0.0896 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.1185e-04 - binary_accuracy: 1.0000 - val_loss: 0.0919 - val_binary_accuracy: 0.9856 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 3.5954e-04 - binary_accuracy: 0.9999 - val_loss: 0.0954 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.5083e-04 - binary_accuracy: 1.0000 - val_loss: 0.0882 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 8.1315e-05 - binary_accuracy: 1.0000 - val_loss: 0.0948 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.1518e-04 - binary_accuracy: 0.9999 - val_loss: 0.0864 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.1422e-04 - binary_accuracy: 1.0000 - val_loss: 0.0929 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 7.6681e-05 - binary_accuracy: 1.0000 - val_loss: 0.0863 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.0115e-04 - binary_accuracy: 1.0000 - val_loss: 0.0842 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 5.5532e-05 - binary_accuracy: 1.0000 - val_loss: 0.0913 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 7.8814e-05 - binary_accuracy: 1.0000 - val_loss: 0.0861 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.7634e-04 - binary_accuracy: 0.9999 - val_loss: 0.0840 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.1986e-04 - binary_accuracy: 1.0000 - val_loss: 0.0833 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 5.8445e-05 - binary_accuracy: 1.0000 - val_loss: 0.0910 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 7.1056e-05 - binary_accuracy: 1.0000 - val_loss: 0.0885 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.0834e-04 - binary_accuracy: 1.0000 - val_loss: 0.0788 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.0039e-04 - binary_accuracy: 1.0000 - val_loss: 0.0951 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 5.2994e-04 - binary_accuracy: 0.9998 - val_loss: 0.0921 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 4.7010e-04 - binary_accuracy: 0.9998 - val_loss: 0.0822 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.0607e-04 - binary_accuracy: 0.9999 - val_loss: 0.0848 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 8.9672e-05 - binary_accuracy: 1.0000 - val_loss: 0.0853 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 6.8447e-05 - binary_accuracy: 1.0000 - val_loss: 0.0849 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 4.6269e-05 - binary_accuracy: 1.0000 - val_loss: 0.0859 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 3.9072e-05 - binary_accuracy: 1.0000 - val_loss: 0.0840 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.7382e-05 - binary_accuracy: 1.0000 - val_loss: 0.0908 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 4.3805e-05 - binary_accuracy: 1.0000 - val_loss: 0.0832 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 7.3111e-05 - binary_accuracy: 1.0000 - val_loss: 0.0882 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 2.1847e-04 - binary_accuracy: 0.9999 - val_loss: 0.0991 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.0696e-04 - binary_accuracy: 1.0000 - val_loss: 0.0808 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 6.7664e-05 - binary_accuracy: 1.0000 - val_loss: 0.0914 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 9.0247e-05 - binary_accuracy: 1.0000 - val_loss: 0.0912 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 7.1911e-05 - binary_accuracy: 1.0000 - val_loss: 0.0863 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 5.8426e-05 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9881944060325623\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049238306\n",
      "train attribution time:  404.4732880592346\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037900344\n",
      "validation attribution time:  40.532864570617676\n",
      "time:  2755.434907913208\n",
      "----- loop 4 :  [1692]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.92289018630981\n",
      "train data delta_a time:  1339.1983494758606\n",
      "train data time:  1407.1212396621704\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.135030508041382\n",
      "validation data delta_a time:  119.4269905090332\n",
      "validation data time:  126.56202101707458\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0027 - binary_accuracy: 0.9994 - val_loss: 0.0816 - val_binary_accuracy: 0.9882 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.0012 - binary_accuracy: 0.9997 - val_loss: 0.0830 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 9.8705e-04 - binary_accuracy: 0.9998 - val_loss: 0.0820 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 7.6028e-04 - binary_accuracy: 0.9999 - val_loss: 0.0829 - val_binary_accuracy: 0.9872 - 8s/epoch - 119ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 5.3200e-04 - binary_accuracy: 0.9999 - val_loss: 0.0890 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 4.8283e-04 - binary_accuracy: 0.9999 - val_loss: 0.0849 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 3.5225e-04 - binary_accuracy: 0.9999 - val_loss: 0.0814 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.5686e-04 - binary_accuracy: 0.9998 - val_loss: 0.0853 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 4.8849e-04 - binary_accuracy: 0.9998 - val_loss: 0.0866 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.9669e-04 - binary_accuracy: 0.9999 - val_loss: 0.0876 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 4.2234e-04 - binary_accuracy: 0.9999 - val_loss: 0.0787 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.3182e-04 - binary_accuracy: 1.0000 - val_loss: 0.0814 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.0908e-04 - binary_accuracy: 0.9999 - val_loss: 0.0864 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.0315e-04 - binary_accuracy: 1.0000 - val_loss: 0.0823 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.4661e-04 - binary_accuracy: 1.0000 - val_loss: 0.0869 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.2072e-04 - binary_accuracy: 1.0000 - val_loss: 0.0866 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.2563e-04 - binary_accuracy: 1.0000 - val_loss: 0.0875 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.0966e-04 - binary_accuracy: 1.0000 - val_loss: 0.0844 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 7.0957e-05 - binary_accuracy: 1.0000 - val_loss: 0.0899 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 7.6375e-05 - binary_accuracy: 1.0000 - val_loss: 0.0893 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 8.5884e-05 - binary_accuracy: 1.0000 - val_loss: 0.0859 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.4124e-04 - binary_accuracy: 1.0000 - val_loss: 0.0785 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.1265e-04 - binary_accuracy: 1.0000 - val_loss: 0.0854 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.6385e-04 - binary_accuracy: 0.9999 - val_loss: 0.0863 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 6.0729e-05 - binary_accuracy: 1.0000 - val_loss: 0.0874 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.6173e-04 - binary_accuracy: 1.0000 - val_loss: 0.0868 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.8455e-04 - binary_accuracy: 0.9999 - val_loss: 0.0862 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 4.9749e-05 - binary_accuracy: 1.0000 - val_loss: 0.0847 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 5.6368e-05 - binary_accuracy: 1.0000 - val_loss: 0.0836 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 9.8583e-05 - binary_accuracy: 1.0000 - val_loss: 0.0867 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 7.6983e-05 - binary_accuracy: 1.0000 - val_loss: 0.0846 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 7.5218e-05 - binary_accuracy: 1.0000 - val_loss: 0.0848 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 8.2659e-05 - binary_accuracy: 1.0000 - val_loss: 0.0870 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 3.0204e-04 - binary_accuracy: 0.9999 - val_loss: 0.0874 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.0274e-04 - binary_accuracy: 1.0000 - val_loss: 0.0845 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 4.6330e-05 - binary_accuracy: 1.0000 - val_loss: 0.0859 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 5.9904e-05 - binary_accuracy: 1.0000 - val_loss: 0.0812 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 5.2607e-05 - binary_accuracy: 1.0000 - val_loss: 0.0880 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 5.3163e-05 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 8.4157e-05 - binary_accuracy: 1.0000 - val_loss: 0.0868 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 7.0337e-05 - binary_accuracy: 1.0000 - val_loss: 0.0879 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 2.8352e-05 - binary_accuracy: 1.0000 - val_loss: 0.0893 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 2.6509e-05 - binary_accuracy: 1.0000 - val_loss: 0.0898 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.8746e-05 - binary_accuracy: 1.0000 - val_loss: 0.0883 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 2.4600e-05 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.5645e-05 - binary_accuracy: 1.0000 - val_loss: 0.0870 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 3.8678e-05 - binary_accuracy: 1.0000 - val_loss: 0.0925 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.5948e-05 - binary_accuracy: 1.0000 - val_loss: 0.0880 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 2.1373e-05 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 8.8599e-05 - binary_accuracy: 1.0000 - val_loss: 0.0979 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 5.6783e-05 - binary_accuracy: 1.0000 - val_loss: 0.0912 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.4559e-04 - binary_accuracy: 0.9999 - val_loss: 0.0837 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.7125e-04 - binary_accuracy: 0.9999 - val_loss: 0.0933 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.2971e-04 - binary_accuracy: 1.0000 - val_loss: 0.0867 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 3.4038e-04 - binary_accuracy: 0.9999 - val_loss: 0.0948 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.0358e-04 - binary_accuracy: 1.0000 - val_loss: 0.0996 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.4450e-04 - binary_accuracy: 1.0000 - val_loss: 0.0910 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.0690e-04 - binary_accuracy: 1.0000 - val_loss: 0.0913 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 5.9638e-05 - binary_accuracy: 1.0000 - val_loss: 0.0937 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 3.6626e-05 - binary_accuracy: 1.0000 - val_loss: 0.0874 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 3.8541e-05 - binary_accuracy: 1.0000 - val_loss: 0.0878 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 3.7342e-05 - binary_accuracy: 1.0000 - val_loss: 0.0935 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 4.4604e-05 - binary_accuracy: 1.0000 - val_loss: 0.0877 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 8.7095e-05 - binary_accuracy: 1.0000 - val_loss: 0.0882 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 4.9967e-05 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 7.8697e-05 - binary_accuracy: 1.0000 - val_loss: 0.0894 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.2849e-04 - binary_accuracy: 0.9999 - val_loss: 0.0925 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 6.4601e-05 - binary_accuracy: 1.0000 - val_loss: 0.0920 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 2.0026e-05 - binary_accuracy: 1.0000 - val_loss: 0.0859 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 3.0016e-05 - binary_accuracy: 1.0000 - val_loss: 0.0859 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.5465e-04 - binary_accuracy: 1.0000 - val_loss: 0.0905 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.6164e-05 - binary_accuracy: 1.0000 - val_loss: 0.0903 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.8731e-05 - binary_accuracy: 1.0000 - val_loss: 0.0918 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 5.7442e-05 - binary_accuracy: 1.0000 - val_loss: 0.0811 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.3125e-04 - binary_accuracy: 1.0000 - val_loss: 0.0861 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.2240e-04 - binary_accuracy: 0.9999 - val_loss: 0.0774 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 4.9115e-05 - binary_accuracy: 1.0000 - val_loss: 0.0857 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 3.2553e-05 - binary_accuracy: 1.0000 - val_loss: 0.0854 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 2.4630e-05 - binary_accuracy: 1.0000 - val_loss: 0.0863 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 2.3306e-04 - binary_accuracy: 0.9999 - val_loss: 0.0794 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 2.3246e-04 - binary_accuracy: 0.9999 - val_loss: 0.0804 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 4.7439e-05 - binary_accuracy: 1.0000 - val_loss: 0.0833 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 3.0043e-05 - binary_accuracy: 1.0000 - val_loss: 0.0835 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 4.3946e-05 - binary_accuracy: 1.0000 - val_loss: 0.0817 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 3.6725e-05 - binary_accuracy: 1.0000 - val_loss: 0.0827 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 3.2870e-05 - binary_accuracy: 1.0000 - val_loss: 0.0844 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.2373e-05 - binary_accuracy: 1.0000 - val_loss: 0.0840 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.4731e-05 - binary_accuracy: 1.0000 - val_loss: 0.0798 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.6201e-05 - binary_accuracy: 1.0000 - val_loss: 0.0850 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.5797e-05 - binary_accuracy: 1.0000 - val_loss: 0.0847 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.4640e-05 - binary_accuracy: 1.0000 - val_loss: 0.0858 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.7824e-05 - binary_accuracy: 1.0000 - val_loss: 0.0896 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.4361e-05 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.9849e-05 - binary_accuracy: 1.0000 - val_loss: 0.0973 - val_binary_accuracy: 0.9860 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.1309e-05 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.5499e-05 - binary_accuracy: 1.0000 - val_loss: 0.0880 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 3.6764e-05 - binary_accuracy: 1.0000 - val_loss: 0.0821 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 3.0148e-05 - binary_accuracy: 1.0000 - val_loss: 0.0902 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.5440e-05 - binary_accuracy: 1.0000 - val_loss: 0.0841 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.7241e-05 - binary_accuracy: 1.0000 - val_loss: 0.0857 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9876388311386108\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049185075\n",
      "train attribution time:  402.13101983070374\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03796342\n",
      "validation attribution time:  39.84533071517944\n",
      "time:  2749.3877489566803\n",
      "----- loop 5 :  [1681]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.16505312919617\n",
      "train data delta_a time:  1340.0501852035522\n",
      "train data time:  1408.2152383327484\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.045814514160156\n",
      "validation data delta_a time:  123.11259603500366\n",
      "validation data time:  130.15841054916382\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0024 - binary_accuracy: 0.9995 - val_loss: 0.0849 - val_binary_accuracy: 0.9876 - 18s/epoch - 285ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.0012 - binary_accuracy: 0.9997 - val_loss: 0.0850 - val_binary_accuracy: 0.9872 - 8s/epoch - 119ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 5.7887e-04 - binary_accuracy: 0.9999 - val_loss: 0.0858 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 7s - loss: 2.9298e-04 - binary_accuracy: 0.9999 - val_loss: 0.0799 - val_binary_accuracy: 0.9871 - 7s/epoch - 119ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 4.0591e-04 - binary_accuracy: 0.9999 - val_loss: 0.0799 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.4186e-04 - binary_accuracy: 0.9999 - val_loss: 0.0822 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 3.1660e-04 - binary_accuracy: 0.9999 - val_loss: 0.0833 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.6034e-04 - binary_accuracy: 0.9999 - val_loss: 0.0863 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.0534e-04 - binary_accuracy: 0.9999 - val_loss: 0.0794 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 4.7681e-04 - binary_accuracy: 0.9999 - val_loss: 0.0825 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.0090e-04 - binary_accuracy: 0.9999 - val_loss: 0.0834 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.2281e-04 - binary_accuracy: 1.0000 - val_loss: 0.0832 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 6.9206e-05 - binary_accuracy: 1.0000 - val_loss: 0.0848 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 7.2978e-05 - binary_accuracy: 1.0000 - val_loss: 0.0815 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 6.9738e-05 - binary_accuracy: 1.0000 - val_loss: 0.0802 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 7.9306e-05 - binary_accuracy: 1.0000 - val_loss: 0.0821 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 5.1046e-05 - binary_accuracy: 1.0000 - val_loss: 0.0785 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.6788e-05 - binary_accuracy: 1.0000 - val_loss: 0.0842 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 6.2792e-05 - binary_accuracy: 1.0000 - val_loss: 0.0787 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 5.7197e-05 - binary_accuracy: 1.0000 - val_loss: 0.0820 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 7.4408e-05 - binary_accuracy: 1.0000 - val_loss: 0.0815 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.8741e-04 - binary_accuracy: 0.9999 - val_loss: 0.0819 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 4.6484e-05 - binary_accuracy: 1.0000 - val_loss: 0.0866 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.0677e-04 - binary_accuracy: 1.0000 - val_loss: 0.0797 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 3.5235e-05 - binary_accuracy: 1.0000 - val_loss: 0.0807 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.9688e-05 - binary_accuracy: 1.0000 - val_loss: 0.0809 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.8481e-05 - binary_accuracy: 1.0000 - val_loss: 0.0797 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 2.7778e-05 - binary_accuracy: 1.0000 - val_loss: 0.0829 - val_binary_accuracy: 0.9867 - 8s/epoch - 119ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 2.9524e-05 - binary_accuracy: 1.0000 - val_loss: 0.0866 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 3.4292e-05 - binary_accuracy: 1.0000 - val_loss: 0.0836 - val_binary_accuracy: 0.9869 - 8s/epoch - 119ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.2843e-05 - binary_accuracy: 1.0000 - val_loss: 0.0861 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.2647e-05 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 4.1987e-05 - binary_accuracy: 1.0000 - val_loss: 0.0885 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 9.8558e-05 - binary_accuracy: 1.0000 - val_loss: 0.0867 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 6.6385e-05 - binary_accuracy: 1.0000 - val_loss: 0.0863 - val_binary_accuracy: 0.9869 - 8s/epoch - 119ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 3.1592e-05 - binary_accuracy: 1.0000 - val_loss: 0.0853 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 2.0614e-05 - binary_accuracy: 1.0000 - val_loss: 0.0880 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 3.3661e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.3375e-04 - binary_accuracy: 0.9999 - val_loss: 0.0971 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 2.1840e-04 - binary_accuracy: 0.9999 - val_loss: 0.0932 - val_binary_accuracy: 0.9861 - 8s/epoch - 119ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 5.4218e-05 - binary_accuracy: 1.0000 - val_loss: 0.0906 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 3.0315e-05 - binary_accuracy: 1.0000 - val_loss: 0.0921 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.3497e-04 - binary_accuracy: 1.0000 - val_loss: 0.0920 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 5.9791e-05 - binary_accuracy: 1.0000 - val_loss: 0.0905 - val_binary_accuracy: 0.9856 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.7637e-05 - binary_accuracy: 1.0000 - val_loss: 0.0898 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.5639e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.7211e-05 - binary_accuracy: 1.0000 - val_loss: 0.0913 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 3.7653e-05 - binary_accuracy: 1.0000 - val_loss: 0.0945 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.9043e-04 - binary_accuracy: 1.0000 - val_loss: 0.0899 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 4.0442e-05 - binary_accuracy: 1.0000 - val_loss: 0.0921 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 3.2299e-05 - binary_accuracy: 1.0000 - val_loss: 0.0933 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.0991e-04 - binary_accuracy: 0.9999 - val_loss: 0.0912 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 5.4647e-05 - binary_accuracy: 1.0000 - val_loss: 0.0880 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.0661e-05 - binary_accuracy: 1.0000 - val_loss: 0.0927 - val_binary_accuracy: 0.9857 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.0329e-05 - binary_accuracy: 1.0000 - val_loss: 0.0917 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.4564e-05 - binary_accuracy: 1.0000 - val_loss: 0.0913 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 2.4399e-05 - binary_accuracy: 1.0000 - val_loss: 0.0884 - val_binary_accuracy: 0.9858 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.3801e-05 - binary_accuracy: 1.0000 - val_loss: 0.0927 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.1818e-05 - binary_accuracy: 1.0000 - val_loss: 0.0923 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 2.2228e-05 - binary_accuracy: 1.0000 - val_loss: 0.0911 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.1164e-05 - binary_accuracy: 1.0000 - val_loss: 0.0930 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 7s - loss: 1.1293e-05 - binary_accuracy: 1.0000 - val_loss: 0.0906 - val_binary_accuracy: 0.9867 - 7s/epoch - 119ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 2.5930e-05 - binary_accuracy: 1.0000 - val_loss: 0.0903 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.7365e-05 - binary_accuracy: 1.0000 - val_loss: 0.0923 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.9135e-05 - binary_accuracy: 1.0000 - val_loss: 0.0915 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 2.6376e-05 - binary_accuracy: 1.0000 - val_loss: 0.0877 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 5.8429e-05 - binary_accuracy: 1.0000 - val_loss: 0.0907 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.6085e-05 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.0448e-05 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.4755e-05 - binary_accuracy: 1.0000 - val_loss: 0.0898 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.4376e-05 - binary_accuracy: 1.0000 - val_loss: 0.0993 - val_binary_accuracy: 0.9858 - 8s/epoch - 119ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.0295e-05 - binary_accuracy: 1.0000 - val_loss: 0.0957 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 9.7462e-06 - binary_accuracy: 1.0000 - val_loss: 0.0894 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.2430e-04 - binary_accuracy: 1.0000 - val_loss: 0.0953 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 4.7872e-05 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 2.6613e-05 - binary_accuracy: 1.0000 - val_loss: 0.0979 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 3.1036e-05 - binary_accuracy: 1.0000 - val_loss: 0.0926 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.5135e-05 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.1084e-05 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.0089e-05 - binary_accuracy: 1.0000 - val_loss: 0.0971 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.3818e-04 - binary_accuracy: 1.0000 - val_loss: 0.0899 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.0946e-04 - binary_accuracy: 0.9999 - val_loss: 0.0889 - val_binary_accuracy: 0.9868 - 8s/epoch - 119ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 5.4210e-05 - binary_accuracy: 1.0000 - val_loss: 0.0932 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.3496e-04 - binary_accuracy: 0.9999 - val_loss: 0.0964 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 6.3631e-05 - binary_accuracy: 1.0000 - val_loss: 0.0946 - val_binary_accuracy: 0.9857 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 8.2431e-05 - binary_accuracy: 1.0000 - val_loss: 0.0928 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 9.2174e-05 - binary_accuracy: 1.0000 - val_loss: 0.1015 - val_binary_accuracy: 0.9856 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 5.3705e-05 - binary_accuracy: 1.0000 - val_loss: 0.0939 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.1046e-04 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 7.9530e-05 - binary_accuracy: 1.0000 - val_loss: 0.0940 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 6.7943e-05 - binary_accuracy: 1.0000 - val_loss: 0.0973 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.1293e-04 - binary_accuracy: 1.0000 - val_loss: 0.0872 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 4.3220e-05 - binary_accuracy: 1.0000 - val_loss: 0.0869 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 3.0443e-05 - binary_accuracy: 1.0000 - val_loss: 0.0890 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 7.5998e-05 - binary_accuracy: 1.0000 - val_loss: 0.0849 - val_binary_accuracy: 0.9871 - 8s/epoch - 123ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.0311e-05 - binary_accuracy: 1.0000 - val_loss: 0.0819 - val_binary_accuracy: 0.9882 - 8s/epoch - 123ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.2999e-05 - binary_accuracy: 1.0000 - val_loss: 0.0843 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.0118e-05 - binary_accuracy: 1.0000 - val_loss: 0.0870 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.7547e-05 - binary_accuracy: 1.0000 - val_loss: 0.0826 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.0767e-05 - binary_accuracy: 1.0000 - val_loss: 0.0828 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9879166483879089\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04918322\n",
      "train attribution time:  402.49025869369507\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03799295\n",
      "validation attribution time:  40.076664447784424\n",
      "time:  2750.095566034317\n",
      "----- loop 6 :  [1676]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  69.09512209892273\n",
      "train data delta_a time:  1331.6800773143768\n",
      "train data time:  1400.7751994132996\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.475088357925415\n",
      "validation data delta_a time:  120.48954463005066\n",
      "validation data time:  126.96463298797607\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0013 - binary_accuracy: 0.9996 - val_loss: 0.0887 - val_binary_accuracy: 0.9865 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 6.1279e-04 - binary_accuracy: 0.9998 - val_loss: 0.0969 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.5026e-04 - binary_accuracy: 1.0000 - val_loss: 0.0901 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.5499e-04 - binary_accuracy: 0.9999 - val_loss: 0.0984 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.0385e-04 - binary_accuracy: 1.0000 - val_loss: 0.0943 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.0322e-04 - binary_accuracy: 1.0000 - val_loss: 0.0890 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 2.0654e-04 - binary_accuracy: 0.9999 - val_loss: 0.0882 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.2696e-04 - binary_accuracy: 0.9999 - val_loss: 0.0904 - val_binary_accuracy: 0.9882 - 8s/epoch - 134ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 7.1249e-05 - binary_accuracy: 1.0000 - val_loss: 0.0931 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.2377e-04 - binary_accuracy: 1.0000 - val_loss: 0.0949 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 5.9980e-05 - binary_accuracy: 1.0000 - val_loss: 0.0913 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 8.8075e-05 - binary_accuracy: 1.0000 - val_loss: 0.0886 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 5.2383e-05 - binary_accuracy: 1.0000 - val_loss: 0.0900 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 4.7365e-05 - binary_accuracy: 1.0000 - val_loss: 0.0932 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 3.5830e-05 - binary_accuracy: 1.0000 - val_loss: 0.0942 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 9.6774e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 9.7129e-05 - binary_accuracy: 1.0000 - val_loss: 0.0877 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.2053e-05 - binary_accuracy: 1.0000 - val_loss: 0.0906 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 2.0883e-05 - binary_accuracy: 1.0000 - val_loss: 0.0889 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.0564e-05 - binary_accuracy: 1.0000 - val_loss: 0.0893 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 5.5428e-05 - binary_accuracy: 1.0000 - val_loss: 0.0861 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 5.7706e-05 - binary_accuracy: 1.0000 - val_loss: 0.0885 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 2.2563e-05 - binary_accuracy: 1.0000 - val_loss: 0.0872 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 3.8458e-05 - binary_accuracy: 1.0000 - val_loss: 0.0841 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.4585e-04 - binary_accuracy: 0.9999 - val_loss: 0.0892 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 5.8804e-05 - binary_accuracy: 1.0000 - val_loss: 0.0857 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 6.4059e-05 - binary_accuracy: 1.0000 - val_loss: 0.0796 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 3.0626e-05 - binary_accuracy: 1.0000 - val_loss: 0.0816 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 3.2143e-05 - binary_accuracy: 1.0000 - val_loss: 0.0843 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.9355e-05 - binary_accuracy: 1.0000 - val_loss: 0.0832 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.9349e-05 - binary_accuracy: 1.0000 - val_loss: 0.0835 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.6728e-05 - binary_accuracy: 1.0000 - val_loss: 0.0865 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.3955e-05 - binary_accuracy: 1.0000 - val_loss: 0.0886 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 5.4251e-05 - binary_accuracy: 1.0000 - val_loss: 0.0890 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.7657e-04 - binary_accuracy: 1.0000 - val_loss: 0.0858 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 6.3432e-05 - binary_accuracy: 1.0000 - val_loss: 0.0904 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 4.1159e-05 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 7.5266e-05 - binary_accuracy: 1.0000 - val_loss: 0.0932 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.5131e-05 - binary_accuracy: 1.0000 - val_loss: 0.0934 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.3194e-05 - binary_accuracy: 1.0000 - val_loss: 0.0901 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.5016e-05 - binary_accuracy: 1.0000 - val_loss: 0.0923 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 2.0499e-05 - binary_accuracy: 1.0000 - val_loss: 0.0956 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 3.4761e-05 - binary_accuracy: 1.0000 - val_loss: 0.0919 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.1320e-05 - binary_accuracy: 1.0000 - val_loss: 0.0926 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.0295e-05 - binary_accuracy: 1.0000 - val_loss: 0.0916 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 7.0138e-06 - binary_accuracy: 1.0000 - val_loss: 0.0921 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 7.7882e-06 - binary_accuracy: 1.0000 - val_loss: 0.0909 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.1762e-05 - binary_accuracy: 1.0000 - val_loss: 0.0962 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 6.2226e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.0000e-05 - binary_accuracy: 1.0000 - val_loss: 0.0934 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 9.8404e-06 - binary_accuracy: 1.0000 - val_loss: 0.0901 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 9.0023e-06 - binary_accuracy: 1.0000 - val_loss: 0.0900 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 4.9383e-06 - binary_accuracy: 1.0000 - val_loss: 0.0913 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 6.2309e-06 - binary_accuracy: 1.0000 - val_loss: 0.0927 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 7.9378e-06 - binary_accuracy: 1.0000 - val_loss: 0.0931 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 6.9447e-06 - binary_accuracy: 1.0000 - val_loss: 0.0912 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.2438e-05 - binary_accuracy: 1.0000 - val_loss: 0.0900 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 4.0043e-05 - binary_accuracy: 1.0000 - val_loss: 0.0987 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 3.3126e-05 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 2.8038e-05 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 3.4703e-05 - binary_accuracy: 1.0000 - val_loss: 0.0949 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.5137e-04 - binary_accuracy: 1.0000 - val_loss: 0.0940 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.7764e-04 - binary_accuracy: 0.9999 - val_loss: 0.1041 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 7.6701e-05 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.0189e-05 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.9087e-05 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.9863e-05 - binary_accuracy: 1.0000 - val_loss: 0.0946 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 8.8709e-06 - binary_accuracy: 1.0000 - val_loss: 0.0963 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.2289e-05 - binary_accuracy: 1.0000 - val_loss: 0.0990 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.2695e-05 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 7.8849e-06 - binary_accuracy: 1.0000 - val_loss: 0.0962 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 7.0338e-06 - binary_accuracy: 1.0000 - val_loss: 0.0971 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 6.0442e-06 - binary_accuracy: 1.0000 - val_loss: 0.0965 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 9.0405e-06 - binary_accuracy: 1.0000 - val_loss: 0.0937 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 4.7994e-06 - binary_accuracy: 1.0000 - val_loss: 0.0905 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 8.1619e-06 - binary_accuracy: 1.0000 - val_loss: 0.0914 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 3.9226e-06 - binary_accuracy: 1.0000 - val_loss: 0.0905 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 4.2143e-06 - binary_accuracy: 1.0000 - val_loss: 0.0921 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 3.2016e-06 - binary_accuracy: 1.0000 - val_loss: 0.0921 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 3.4545e-06 - binary_accuracy: 1.0000 - val_loss: 0.0940 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 6.0256e-06 - binary_accuracy: 1.0000 - val_loss: 0.0937 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 4.0226e-06 - binary_accuracy: 1.0000 - val_loss: 0.0923 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 4.2030e-06 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 5.6209e-06 - binary_accuracy: 1.0000 - val_loss: 0.0943 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 4.9279e-06 - binary_accuracy: 1.0000 - val_loss: 0.0949 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 3.7809e-05 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.4668e-04 - binary_accuracy: 0.9999 - val_loss: 0.1015 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 3.2118e-05 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.0883e-05 - binary_accuracy: 1.0000 - val_loss: 0.0964 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.4658e-05 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.0945e-05 - binary_accuracy: 1.0000 - val_loss: 0.0984 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.8301e-05 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9890 - 8s/epoch - 123ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.5646e-04 - binary_accuracy: 0.9999 - val_loss: 0.0991 - val_binary_accuracy: 0.9849 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.1086e-04 - binary_accuracy: 0.9999 - val_loss: 0.0881 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 6.4646e-05 - binary_accuracy: 1.0000 - val_loss: 0.0854 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 6.7309e-05 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 2.6953e-05 - binary_accuracy: 1.0000 - val_loss: 0.0971 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 3.4144e-05 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.1170e-05 - binary_accuracy: 1.0000 - val_loss: 0.0951 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.1391e-05 - binary_accuracy: 1.0000 - val_loss: 0.0883 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9886111617088318\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049220443\n",
      "train attribution time:  403.66627836227417\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038034014\n",
      "validation attribution time:  40.9442241191864\n",
      "time:  2748.637044906616\n",
      "----- loop 7 :  [1767]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.24904108047485\n",
      "train data delta_a time:  1327.9366114139557\n",
      "train data time:  1396.1856524944305\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.722372770309448\n",
      "validation data delta_a time:  121.22887063026428\n",
      "validation data time:  127.95124340057373\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0019 - binary_accuracy: 0.9996 - val_loss: 0.0811 - val_binary_accuracy: 0.9875 - 18s/epoch - 283ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 8.5179e-04 - binary_accuracy: 0.9998 - val_loss: 0.0820 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 5.8915e-04 - binary_accuracy: 0.9998 - val_loss: 0.0902 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.7422e-04 - binary_accuracy: 0.9999 - val_loss: 0.0855 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 3.2607e-04 - binary_accuracy: 0.9999 - val_loss: 0.0866 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.7262e-04 - binary_accuracy: 0.9999 - val_loss: 0.0817 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 7.7419e-05 - binary_accuracy: 1.0000 - val_loss: 0.0827 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 9.0298e-05 - binary_accuracy: 1.0000 - val_loss: 0.0834 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 4.7141e-05 - binary_accuracy: 1.0000 - val_loss: 0.0839 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 4.0793e-05 - binary_accuracy: 1.0000 - val_loss: 0.0881 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 6.1908e-05 - binary_accuracy: 1.0000 - val_loss: 0.0821 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 7.1771e-05 - binary_accuracy: 1.0000 - val_loss: 0.0844 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 8.2614e-05 - binary_accuracy: 1.0000 - val_loss: 0.0855 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.3779e-04 - binary_accuracy: 1.0000 - val_loss: 0.0762 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 6.2340e-05 - binary_accuracy: 1.0000 - val_loss: 0.0870 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 3.2326e-05 - binary_accuracy: 1.0000 - val_loss: 0.0848 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 4.5603e-05 - binary_accuracy: 1.0000 - val_loss: 0.0818 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 2.1288e-05 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 3.8240e-05 - binary_accuracy: 1.0000 - val_loss: 0.0874 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.5405e-05 - binary_accuracy: 1.0000 - val_loss: 0.0838 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.6118e-05 - binary_accuracy: 1.0000 - val_loss: 0.0858 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 3.4665e-05 - binary_accuracy: 1.0000 - val_loss: 0.0879 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 9.3749e-05 - binary_accuracy: 1.0000 - val_loss: 0.0897 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.6411e-05 - binary_accuracy: 1.0000 - val_loss: 0.0899 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 3.3352e-05 - binary_accuracy: 1.0000 - val_loss: 0.0906 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.2627e-04 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 4.0945e-05 - binary_accuracy: 1.0000 - val_loss: 0.0884 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 2.8852e-05 - binary_accuracy: 1.0000 - val_loss: 0.0913 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 4.3524e-05 - binary_accuracy: 1.0000 - val_loss: 0.0914 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.1855e-04 - binary_accuracy: 0.9999 - val_loss: 0.0892 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 5.9401e-05 - binary_accuracy: 1.0000 - val_loss: 0.0909 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.3717e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 4.6255e-05 - binary_accuracy: 1.0000 - val_loss: 0.0890 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 2.2139e-05 - binary_accuracy: 1.0000 - val_loss: 0.0888 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.3494e-05 - binary_accuracy: 1.0000 - val_loss: 0.0914 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.7390e-05 - binary_accuracy: 1.0000 - val_loss: 0.0890 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.4534e-05 - binary_accuracy: 1.0000 - val_loss: 0.0893 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.5639e-05 - binary_accuracy: 1.0000 - val_loss: 0.0928 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 2.0689e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 2.7154e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 3.7023e-05 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 7.0375e-05 - binary_accuracy: 1.0000 - val_loss: 0.0906 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.2118e-05 - binary_accuracy: 1.0000 - val_loss: 0.0920 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.2963e-05 - binary_accuracy: 1.0000 - val_loss: 0.0926 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 5.2326e-05 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.6663e-05 - binary_accuracy: 1.0000 - val_loss: 0.0896 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.7665e-05 - binary_accuracy: 1.0000 - val_loss: 0.0912 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.3973e-05 - binary_accuracy: 1.0000 - val_loss: 0.0902 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.1434e-05 - binary_accuracy: 1.0000 - val_loss: 0.0955 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.3119e-05 - binary_accuracy: 1.0000 - val_loss: 0.0940 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.2465e-05 - binary_accuracy: 1.0000 - val_loss: 0.0952 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 3.0856e-05 - binary_accuracy: 1.0000 - val_loss: 0.0937 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 8.5137e-06 - binary_accuracy: 1.0000 - val_loss: 0.0958 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.2624e-05 - binary_accuracy: 1.0000 - val_loss: 0.0943 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.0001e-04 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.0850e-05 - binary_accuracy: 1.0000 - val_loss: 0.0959 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.6768e-05 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 2.8537e-05 - binary_accuracy: 1.0000 - val_loss: 0.0925 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.3635e-05 - binary_accuracy: 1.0000 - val_loss: 0.0884 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.2917e-05 - binary_accuracy: 1.0000 - val_loss: 0.0958 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 8.6669e-06 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.3947e-04 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.3842e-05 - binary_accuracy: 1.0000 - val_loss: 0.0946 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 3.1801e-05 - binary_accuracy: 1.0000 - val_loss: 0.0963 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.3390e-04 - binary_accuracy: 1.0000 - val_loss: 0.0931 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.2037e-05 - binary_accuracy: 1.0000 - val_loss: 0.0928 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 6.9116e-06 - binary_accuracy: 1.0000 - val_loss: 0.0952 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 9.7403e-06 - binary_accuracy: 1.0000 - val_loss: 0.0939 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.3387e-05 - binary_accuracy: 1.0000 - val_loss: 0.0957 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 8.3403e-06 - binary_accuracy: 1.0000 - val_loss: 0.0945 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 6.1924e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 5.8975e-06 - binary_accuracy: 1.0000 - val_loss: 0.0948 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 7.5197e-06 - binary_accuracy: 1.0000 - val_loss: 0.0939 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 3.7516e-06 - binary_accuracy: 1.0000 - val_loss: 0.0901 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 3.0399e-05 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.6675e-05 - binary_accuracy: 1.0000 - val_loss: 0.0868 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 7.3613e-06 - binary_accuracy: 1.0000 - val_loss: 0.0882 - val_binary_accuracy: 0.9892 - 8s/epoch - 123ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 6.3115e-06 - binary_accuracy: 1.0000 - val_loss: 0.0888 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 2.0484e-05 - binary_accuracy: 1.0000 - val_loss: 0.0990 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 8.9103e-06 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 5.3589e-06 - binary_accuracy: 1.0000 - val_loss: 0.0931 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 4.0477e-05 - binary_accuracy: 1.0000 - val_loss: 0.0915 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.0021e-05 - binary_accuracy: 1.0000 - val_loss: 0.0912 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.1555e-05 - binary_accuracy: 1.0000 - val_loss: 0.0915 - val_binary_accuracy: 0.9879 - 8s/epoch - 123ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 5.4325e-06 - binary_accuracy: 1.0000 - val_loss: 0.0921 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 7.0686e-06 - binary_accuracy: 1.0000 - val_loss: 0.0990 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 4.7411e-06 - binary_accuracy: 1.0000 - val_loss: 0.0945 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 4.9368e-06 - binary_accuracy: 1.0000 - val_loss: 0.0905 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 3.9075e-06 - binary_accuracy: 1.0000 - val_loss: 0.0932 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.0327e-04 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 8.7118e-06 - binary_accuracy: 1.0000 - val_loss: 0.0948 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 7.4221e-06 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 5.6053e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 4.6915e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 6.8295e-06 - binary_accuracy: 1.0000 - val_loss: 0.0942 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 4.9919e-06 - binary_accuracy: 1.0000 - val_loss: 0.0974 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 7.0834e-06 - binary_accuracy: 1.0000 - val_loss: 0.1043 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 8.8612e-06 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 6.7600e-06 - binary_accuracy: 1.0000 - val_loss: 0.0979 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.2139e-05 - binary_accuracy: 1.0000 - val_loss: 0.0969 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9884722828865051\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04913484\n",
      "train attribution time:  403.8071963787079\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.0380305\n",
      "validation attribution time:  40.050861835479736\n",
      "time:  2742.2673597335815\n",
      "----- loop 8 :  [1769]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.87335729598999\n",
      "train data delta_a time:  1335.4955732822418\n",
      "train data time:  1403.3689305782318\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.39408540725708\n",
      "validation data delta_a time:  120.05673503875732\n",
      "validation data time:  126.4508204460144\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 19s - loss: 0.0013 - binary_accuracy: 0.9998 - val_loss: 0.1027 - val_binary_accuracy: 0.9869 - 19s/epoch - 304ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 1.7738e-04 - binary_accuracy: 0.9999 - val_loss: 0.1021 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 2.3495e-04 - binary_accuracy: 1.0000 - val_loss: 0.1075 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.4276e-04 - binary_accuracy: 0.9999 - val_loss: 0.0990 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 3.2451e-04 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.5213e-04 - binary_accuracy: 1.0000 - val_loss: 0.1015 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.2876e-04 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 2.8868e-05 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 3.5394e-05 - binary_accuracy: 1.0000 - val_loss: 0.1062 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 3.7033e-05 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.2514e-04 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.9107e-05 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.7022e-05 - binary_accuracy: 1.0000 - val_loss: 0.1064 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.8030e-05 - binary_accuracy: 1.0000 - val_loss: 0.1057 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.8914e-05 - binary_accuracy: 1.0000 - val_loss: 0.1039 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 3.6590e-05 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.0471e-05 - binary_accuracy: 1.0000 - val_loss: 0.1081 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 8.2307e-05 - binary_accuracy: 1.0000 - val_loss: 0.1071 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 4.6926e-05 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.2565e-05 - binary_accuracy: 1.0000 - val_loss: 0.1026 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.1409e-05 - binary_accuracy: 1.0000 - val_loss: 0.0978 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.2779e-05 - binary_accuracy: 1.0000 - val_loss: 0.0991 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 6.7348e-05 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.7925e-04 - binary_accuracy: 0.9999 - val_loss: 0.1014 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 6.9053e-05 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.9749e-05 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.4517e-05 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.6187e-05 - binary_accuracy: 1.0000 - val_loss: 0.1077 - val_binary_accuracy: 0.9872 - 8s/epoch - 123ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 7.5926e-06 - binary_accuracy: 1.0000 - val_loss: 0.1075 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 3.0072e-05 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.2904e-05 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.7344e-05 - binary_accuracy: 1.0000 - val_loss: 0.1052 - val_binary_accuracy: 0.9879 - 8s/epoch - 123ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 2.3086e-05 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.0793e-05 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.2627e-05 - binary_accuracy: 1.0000 - val_loss: 0.1060 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 6.6062e-06 - binary_accuracy: 1.0000 - val_loss: 0.1066 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 6.0951e-06 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 5.6037e-06 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.2154e-05 - binary_accuracy: 1.0000 - val_loss: 0.1062 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.2739e-05 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 7.1123e-06 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 5.9715e-06 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 9.9101e-06 - binary_accuracy: 1.0000 - val_loss: 0.1057 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 6.1568e-06 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 8.7206e-06 - binary_accuracy: 1.0000 - val_loss: 0.1043 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.3059e-05 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 5.2637e-06 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.9270e-05 - binary_accuracy: 1.0000 - val_loss: 0.1071 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.2395e-05 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.3327e-05 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 8.3056e-06 - binary_accuracy: 1.0000 - val_loss: 0.1106 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.7955e-06 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 3.6844e-06 - binary_accuracy: 1.0000 - val_loss: 0.1109 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 7.7885e-05 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.6849e-05 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 7.9388e-06 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 4.3982e-06 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 7.1124e-06 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.8296e-05 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.0284e-05 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9869 - 8s/epoch - 123ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 5.8400e-06 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 5.1408e-06 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 3.9405e-06 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.8952e-06 - binary_accuracy: 1.0000 - val_loss: 0.1109 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.7713e-05 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 3.9550e-06 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 5.5487e-06 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.0944e-06 - binary_accuracy: 1.0000 - val_loss: 0.1146 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 3.2989e-06 - binary_accuracy: 1.0000 - val_loss: 0.1202 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 2.8048e-06 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 3.0860e-06 - binary_accuracy: 1.0000 - val_loss: 0.1146 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.9376e-05 - binary_accuracy: 1.0000 - val_loss: 0.1081 - val_binary_accuracy: 0.9875 - 8s/epoch - 123ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 3.9105e-06 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 2.5755e-06 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 2.2934e-06 - binary_accuracy: 1.0000 - val_loss: 0.1099 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 2.9244e-06 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 3.5488e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.9200e-06 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.9786e-06 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 7.7161e-06 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 4.0240e-06 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.1655e-06 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 4.5679e-06 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 2.0433e-06 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 1.3706e-06 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.9263e-06 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.6992e-06 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 3.4911e-06 - binary_accuracy: 1.0000 - val_loss: 0.1095 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.7634e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.8548e-06 - binary_accuracy: 1.0000 - val_loss: 0.1075 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.9478e-06 - binary_accuracy: 1.0000 - val_loss: 0.1095 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 9.1411e-07 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.8329e-06 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.6083e-06 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.8451e-04 - binary_accuracy: 0.9999 - val_loss: 0.1181 - val_binary_accuracy: 0.9863 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.6720e-04 - binary_accuracy: 0.9999 - val_loss: 0.1012 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 2.7878e-05 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.6101e-05 - binary_accuracy: 1.0000 - val_loss: 0.1068 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.5514e-05 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.5507e-05 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9876388311386108\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049176376\n",
      "train attribution time:  401.45112109184265\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038038388\n",
      "validation attribution time:  40.752209424972534\n",
      "time:  2749.672203063965\n",
      "----- loop 9 :  [1771]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.02251744270325\n",
      "train data delta_a time:  1332.3811531066895\n",
      "train data time:  1400.4036705493927\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.770849943161011\n",
      "validation data delta_a time:  120.98365902900696\n",
      "validation data time:  127.75450897216797\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0012 - binary_accuracy: 0.9998 - val_loss: 0.0980 - val_binary_accuracy: 0.9882 - 18s/epoch - 282ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 4.2815e-04 - binary_accuracy: 0.9999 - val_loss: 0.0983 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.9538e-04 - binary_accuracy: 0.9999 - val_loss: 0.0947 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.1559e-04 - binary_accuracy: 1.0000 - val_loss: 0.0985 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 6.2025e-05 - binary_accuracy: 1.0000 - val_loss: 0.0930 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.2826e-04 - binary_accuracy: 1.0000 - val_loss: 0.0952 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.1332e-05 - binary_accuracy: 1.0000 - val_loss: 0.0933 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.0328e-04 - binary_accuracy: 1.0000 - val_loss: 0.0923 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 4.6924e-05 - binary_accuracy: 1.0000 - val_loss: 0.0954 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.5727e-05 - binary_accuracy: 1.0000 - val_loss: 0.0988 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 4.4074e-05 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.5000e-05 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.6162e-05 - binary_accuracy: 1.0000 - val_loss: 0.0944 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 3.2865e-05 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.2970e-05 - binary_accuracy: 1.0000 - val_loss: 0.0928 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 7.7650e-06 - binary_accuracy: 1.0000 - val_loss: 0.0897 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 9.0824e-06 - binary_accuracy: 1.0000 - val_loss: 0.0928 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 7.8445e-06 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.6378e-05 - binary_accuracy: 1.0000 - val_loss: 0.0949 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 7.1848e-06 - binary_accuracy: 1.0000 - val_loss: 0.0956 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 6.0224e-06 - binary_accuracy: 1.0000 - val_loss: 0.0953 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 6.8747e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.4800e-04 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 6.8462e-05 - binary_accuracy: 1.0000 - val_loss: 0.1008 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 3.0058e-05 - binary_accuracy: 1.0000 - val_loss: 0.0982 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.4105e-05 - binary_accuracy: 1.0000 - val_loss: 0.1009 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.5916e-05 - binary_accuracy: 1.0000 - val_loss: 0.0954 - val_binary_accuracy: 0.9890 - 8s/epoch - 123ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.3861e-05 - binary_accuracy: 1.0000 - val_loss: 0.0969 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 1.4486e-05 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 3.1223e-05 - binary_accuracy: 1.0000 - val_loss: 0.0958 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 3.0402e-05 - binary_accuracy: 1.0000 - val_loss: 0.0977 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 8.1319e-06 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 5.9495e-06 - binary_accuracy: 1.0000 - val_loss: 0.0974 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 5.2155e-06 - binary_accuracy: 1.0000 - val_loss: 0.0963 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.5669e-05 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 4.8085e-06 - binary_accuracy: 1.0000 - val_loss: 0.1009 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 2.4525e-05 - binary_accuracy: 1.0000 - val_loss: 0.0945 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 3.8873e-05 - binary_accuracy: 1.0000 - val_loss: 0.0963 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 2.7183e-05 - binary_accuracy: 1.0000 - val_loss: 0.0989 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.0804e-05 - binary_accuracy: 1.0000 - val_loss: 0.1003 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 6.0374e-06 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 7.2901e-06 - binary_accuracy: 1.0000 - val_loss: 0.0940 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 3.3503e-05 - binary_accuracy: 1.0000 - val_loss: 0.0952 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.0245e-05 - binary_accuracy: 1.0000 - val_loss: 0.0994 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.8006e-05 - binary_accuracy: 1.0000 - val_loss: 0.0979 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 6.6417e-06 - binary_accuracy: 1.0000 - val_loss: 0.0975 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 3.0067e-06 - binary_accuracy: 1.0000 - val_loss: 0.0965 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 4.1774e-06 - binary_accuracy: 1.0000 - val_loss: 0.0991 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.6831e-05 - binary_accuracy: 1.0000 - val_loss: 0.0982 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 3.9022e-06 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 7.9973e-06 - binary_accuracy: 1.0000 - val_loss: 0.0991 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 4.4463e-06 - binary_accuracy: 1.0000 - val_loss: 0.0955 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 3.9142e-06 - binary_accuracy: 1.0000 - val_loss: 0.0963 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.7100e-06 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.6810e-05 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 4.0430e-05 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 9.2040e-06 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 3.1178e-05 - binary_accuracy: 1.0000 - val_loss: 0.0852 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 6.9522e-05 - binary_accuracy: 1.0000 - val_loss: 0.0945 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 2.2170e-05 - binary_accuracy: 1.0000 - val_loss: 0.0939 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 6.6517e-06 - binary_accuracy: 1.0000 - val_loss: 0.0914 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 6.4003e-06 - binary_accuracy: 1.0000 - val_loss: 0.0902 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.0611e-04 - binary_accuracy: 1.0000 - val_loss: 0.1053 - val_binary_accuracy: 0.9894 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.4646e-05 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 5.5920e-06 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 3.4251e-06 - binary_accuracy: 1.0000 - val_loss: 0.0974 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 3.4877e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 4.5358e-06 - binary_accuracy: 1.0000 - val_loss: 0.0968 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 3.7415e-06 - binary_accuracy: 1.0000 - val_loss: 0.0977 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 3.3214e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 3.3695e-06 - binary_accuracy: 1.0000 - val_loss: 0.0979 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 3.7015e-05 - binary_accuracy: 1.0000 - val_loss: 0.0916 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.7548e-05 - binary_accuracy: 1.0000 - val_loss: 0.0909 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 6.5816e-06 - binary_accuracy: 1.0000 - val_loss: 0.0935 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 7.2848e-06 - binary_accuracy: 1.0000 - val_loss: 0.0959 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 4.6042e-06 - binary_accuracy: 1.0000 - val_loss: 0.0952 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 2.9191e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.1442e-04 - binary_accuracy: 0.9999 - val_loss: 0.0957 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 5.5795e-06 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9903 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 6.2763e-06 - binary_accuracy: 1.0000 - val_loss: 0.0996 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 3.0618e-06 - binary_accuracy: 1.0000 - val_loss: 0.0943 - val_binary_accuracy: 0.9906 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.2728e-06 - binary_accuracy: 1.0000 - val_loss: 0.0976 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 2.6049e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.9623e-06 - binary_accuracy: 1.0000 - val_loss: 0.0964 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 3.9910e-06 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 3.7655e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.0642e-06 - binary_accuracy: 1.0000 - val_loss: 0.0976 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 5.6301e-06 - binary_accuracy: 1.0000 - val_loss: 0.0950 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.1234e-06 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 4.3886e-05 - binary_accuracy: 1.0000 - val_loss: 0.0994 - val_binary_accuracy: 0.9892 - 8s/epoch - 123ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 6.0345e-04 - binary_accuracy: 0.9999 - val_loss: 0.0934 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 4.0097e-05 - binary_accuracy: 1.0000 - val_loss: 0.0937 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 6.7451e-06 - binary_accuracy: 1.0000 - val_loss: 0.0924 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.3126e-05 - binary_accuracy: 1.0000 - val_loss: 0.0969 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.6110e-05 - binary_accuracy: 1.0000 - val_loss: 0.0975 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.4317e-05 - binary_accuracy: 1.0000 - val_loss: 0.0989 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.2248e-04 - binary_accuracy: 1.0000 - val_loss: 0.0859 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.6894e-05 - binary_accuracy: 1.0000 - val_loss: 0.0916 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 5.1117e-06 - binary_accuracy: 1.0000 - val_loss: 0.0900 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.9167e-05 - binary_accuracy: 1.0000 - val_loss: 0.0959 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.9999861121177673\n",
      "binary_accuracy validation:  0.989027738571167\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049068235\n",
      "train attribution time:  401.5762474536896\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03793577\n",
      "validation attribution time:  38.908663272857666\n",
      "time:  2743.57860827446\n",
      "----- loop 10 :  [1773]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.31285071372986\n",
      "train data delta_a time:  1335.4150276184082\n",
      "train data time:  1403.727878332138\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.424997329711914\n",
      "validation data delta_a time:  118.90564703941345\n",
      "validation data time:  125.33064436912537\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 8.8433e-04 - binary_accuracy: 0.9998 - val_loss: 0.0971 - val_binary_accuracy: 0.9883 - 18s/epoch - 283ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 4.3148e-04 - binary_accuracy: 0.9999 - val_loss: 0.0950 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.2359e-04 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 4.0356e-05 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.8980e-05 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 9.6309e-05 - binary_accuracy: 1.0000 - val_loss: 0.0973 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.7690e-05 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.1283e-05 - binary_accuracy: 1.0000 - val_loss: 0.1003 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 5.4377e-05 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 3.8042e-05 - binary_accuracy: 1.0000 - val_loss: 0.0987 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.5200e-05 - binary_accuracy: 1.0000 - val_loss: 0.0920 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.4104e-05 - binary_accuracy: 1.0000 - val_loss: 0.0911 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 5.7375e-05 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.8339e-05 - binary_accuracy: 1.0000 - val_loss: 0.0974 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 7.1248e-06 - binary_accuracy: 1.0000 - val_loss: 0.0965 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 7.0664e-06 - binary_accuracy: 1.0000 - val_loss: 0.0957 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 5.4314e-06 - binary_accuracy: 1.0000 - val_loss: 0.0985 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.8668e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 7.0080e-06 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 5.8145e-06 - binary_accuracy: 1.0000 - val_loss: 0.0974 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 3.5482e-06 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 4.9106e-06 - binary_accuracy: 1.0000 - val_loss: 0.0985 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 3.4030e-06 - binary_accuracy: 1.0000 - val_loss: 0.0946 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.3715e-06 - binary_accuracy: 1.0000 - val_loss: 0.0978 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.5998e-06 - binary_accuracy: 1.0000 - val_loss: 0.0979 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.4758e-06 - binary_accuracy: 1.0000 - val_loss: 0.0988 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.9576e-06 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.9709e-06 - binary_accuracy: 1.0000 - val_loss: 0.1002 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 2.5045e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.7847e-06 - binary_accuracy: 1.0000 - val_loss: 0.0935 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.8011e-06 - binary_accuracy: 1.0000 - val_loss: 0.0977 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 3.6253e-06 - binary_accuracy: 1.0000 - val_loss: 0.0971 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.2543e-06 - binary_accuracy: 1.0000 - val_loss: 0.0982 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.8194e-06 - binary_accuracy: 1.0000 - val_loss: 0.0985 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.4717e-06 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.8355e-06 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.6847e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 5.1777e-06 - binary_accuracy: 1.0000 - val_loss: 0.0995 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.0114e-04 - binary_accuracy: 1.0000 - val_loss: 0.1003 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 4.5957e-05 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 4.7475e-06 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 5.1595e-06 - binary_accuracy: 1.0000 - val_loss: 0.0944 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 2.6661e-06 - binary_accuracy: 1.0000 - val_loss: 0.0976 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.0751e-05 - binary_accuracy: 1.0000 - val_loss: 0.0938 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.1113e-05 - binary_accuracy: 1.0000 - val_loss: 0.0957 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.5918e-06 - binary_accuracy: 1.0000 - val_loss: 0.0975 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.4150e-06 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.8387e-06 - binary_accuracy: 1.0000 - val_loss: 0.1009 - val_binary_accuracy: 0.9868 - 8s/epoch - 135ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 2.2405e-06 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 6.5034e-06 - binary_accuracy: 1.0000 - val_loss: 0.0965 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.5852e-06 - binary_accuracy: 1.0000 - val_loss: 0.0996 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 3.2988e-06 - binary_accuracy: 1.0000 - val_loss: 0.0955 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.8540e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.9090e-06 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.8354e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.5391e-06 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 3.0307e-06 - binary_accuracy: 1.0000 - val_loss: 0.1007 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 3.3425e-06 - binary_accuracy: 1.0000 - val_loss: 0.0976 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 3.1234e-06 - binary_accuracy: 1.0000 - val_loss: 0.0945 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.6776e-06 - binary_accuracy: 1.0000 - val_loss: 0.0965 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.8220e-06 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.3976e-06 - binary_accuracy: 1.0000 - val_loss: 0.0958 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.0469e-06 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.2821e-06 - binary_accuracy: 1.0000 - val_loss: 0.0995 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.0469e-06 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.9086e-06 - binary_accuracy: 1.0000 - val_loss: 0.0995 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 8.8689e-07 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 2.0774e-06 - binary_accuracy: 1.0000 - val_loss: 0.1012 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 9.9960e-07 - binary_accuracy: 1.0000 - val_loss: 0.1024 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.2991e-04 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.5351e-05 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 3.5557e-06 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.8282e-06 - binary_accuracy: 1.0000 - val_loss: 0.1002 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.7904e-06 - binary_accuracy: 1.0000 - val_loss: 0.0959 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 2.8309e-06 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 8.4993e-07 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.7629e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 8.5684e-07 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 5.9726e-07 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.0499e-06 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.1706e-06 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 8.3104e-07 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 6.6284e-07 - binary_accuracy: 1.0000 - val_loss: 0.1022 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 8.4123e-07 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 8.0770e-07 - binary_accuracy: 1.0000 - val_loss: 0.0954 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 6.4135e-07 - binary_accuracy: 1.0000 - val_loss: 0.1012 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 7.3815e-07 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 5.8493e-07 - binary_accuracy: 1.0000 - val_loss: 0.0990 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 7.8002e-07 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 5.7194e-07 - binary_accuracy: 1.0000 - val_loss: 0.1015 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.3241e-06 - binary_accuracy: 1.0000 - val_loss: 0.1047 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 9.3631e-07 - binary_accuracy: 1.0000 - val_loss: 0.1006 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 6.9905e-07 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.2899e-06 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 9.8241e-07 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.8768e-06 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 7.4240e-06 - binary_accuracy: 1.0000 - val_loss: 0.1064 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.7165e-05 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 3.2820e-05 - binary_accuracy: 1.0000 - val_loss: 0.1004 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 3.4624e-04 - binary_accuracy: 0.9999 - val_loss: 0.0995 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.9999027848243713\n",
      "binary_accuracy validation:  0.986111044883728\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04914591\n",
      "train attribution time:  401.9280743598938\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03836813\n",
      "validation attribution time:  40.580400466918945\n",
      "time:  2745.9186766147614\n",
      "----- loop 11 :  [1757]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  65.5417115688324\n",
      "train data delta_a time:  1344.8714559078217\n",
      "train data time:  1410.413167476654\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.290311813354492\n",
      "validation data delta_a time:  121.19362425804138\n",
      "validation data time:  127.48393607139587\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 7.8955e-04 - binary_accuracy: 0.9998 - val_loss: 0.1026 - val_binary_accuracy: 0.9864 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 3.0239e-04 - binary_accuracy: 1.0000 - val_loss: 0.1060 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 9.1678e-05 - binary_accuracy: 1.0000 - val_loss: 0.1035 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.9829e-05 - binary_accuracy: 1.0000 - val_loss: 0.1026 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.8359e-05 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 4.9867e-05 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.7983e-05 - binary_accuracy: 1.0000 - val_loss: 0.0992 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 2.1959e-05 - binary_accuracy: 1.0000 - val_loss: 0.0981 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.3119e-05 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 2.8333e-05 - binary_accuracy: 1.0000 - val_loss: 0.0949 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.3076e-05 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.1787e-05 - binary_accuracy: 1.0000 - val_loss: 0.1027 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 8.5906e-05 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 2.9209e-05 - binary_accuracy: 1.0000 - val_loss: 0.1023 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 4.1510e-05 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.5198e-05 - binary_accuracy: 1.0000 - val_loss: 0.0990 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.2132e-05 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 2.2107e-05 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 8.2079e-05 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.0021e-04 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 6.4759e-05 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 3.7991e-04 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 3.3101e-04 - binary_accuracy: 0.9999 - val_loss: 0.0986 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.5918e-04 - binary_accuracy: 1.0000 - val_loss: 0.0937 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.4379e-05 - binary_accuracy: 1.0000 - val_loss: 0.0949 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.2669e-05 - binary_accuracy: 1.0000 - val_loss: 0.0945 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 7.1102e-06 - binary_accuracy: 1.0000 - val_loss: 0.0992 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 4.3315e-06 - binary_accuracy: 1.0000 - val_loss: 0.0968 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 5.5903e-06 - binary_accuracy: 1.0000 - val_loss: 0.0948 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.1445e-06 - binary_accuracy: 1.0000 - val_loss: 0.0934 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.0109e-05 - binary_accuracy: 1.0000 - val_loss: 0.0993 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 8.0926e-06 - binary_accuracy: 1.0000 - val_loss: 0.0950 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.2155e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 2.0546e-05 - binary_accuracy: 1.0000 - val_loss: 0.1008 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 3.8171e-06 - binary_accuracy: 1.0000 - val_loss: 0.0981 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 5.6032e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 4.7645e-06 - binary_accuracy: 1.0000 - val_loss: 0.0962 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.7603e-06 - binary_accuracy: 1.0000 - val_loss: 0.0981 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 2.6012e-06 - binary_accuracy: 1.0000 - val_loss: 0.0951 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 5.0486e-06 - binary_accuracy: 1.0000 - val_loss: 0.0958 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 3.9040e-06 - binary_accuracy: 1.0000 - val_loss: 0.0930 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 4.2811e-06 - binary_accuracy: 1.0000 - val_loss: 0.0931 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 3.5447e-06 - binary_accuracy: 1.0000 - val_loss: 0.0969 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.8892e-06 - binary_accuracy: 1.0000 - val_loss: 0.0942 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.9745e-06 - binary_accuracy: 1.0000 - val_loss: 0.0932 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 5.5044e-06 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 6.2098e-05 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 6.0789e-06 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.6236e-05 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 8.5139e-06 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 4.4735e-06 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 4.3755e-06 - binary_accuracy: 1.0000 - val_loss: 0.1023 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.6383e-06 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 4.0277e-06 - binary_accuracy: 1.0000 - val_loss: 0.1003 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 4.8222e-06 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.5802e-06 - binary_accuracy: 1.0000 - val_loss: 0.1115 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 3.2228e-06 - binary_accuracy: 1.0000 - val_loss: 0.1031 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.7256e-06 - binary_accuracy: 1.0000 - val_loss: 0.1073 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 3.0076e-06 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.1798e-06 - binary_accuracy: 1.0000 - val_loss: 0.1033 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.1891e-06 - binary_accuracy: 1.0000 - val_loss: 0.1027 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 3.4150e-06 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.9379e-06 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.3229e-06 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.1165e-06 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.8461e-06 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 2.9965e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.6565e-06 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.5175e-06 - binary_accuracy: 1.0000 - val_loss: 0.1012 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.2337e-06 - binary_accuracy: 1.0000 - val_loss: 0.1027 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.0016e-06 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.1280e-06 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.0224e-06 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 3.1264e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.1487e-06 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.5602e-06 - binary_accuracy: 1.0000 - val_loss: 0.1002 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.5135e-06 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 9.1961e-07 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.2688e-06 - binary_accuracy: 1.0000 - val_loss: 0.1004 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 7.7231e-07 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 7.5485e-07 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.4476e-06 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 8.1732e-07 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9863 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 7.3053e-05 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 8.7832e-05 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 4.0289e-04 - binary_accuracy: 0.9999 - val_loss: 0.1025 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.2569e-04 - binary_accuracy: 1.0000 - val_loss: 0.0982 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.1966e-05 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 4.7285e-06 - binary_accuracy: 1.0000 - val_loss: 0.1006 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 4.4734e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 3.4282e-06 - binary_accuracy: 1.0000 - val_loss: 0.0988 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 2.7902e-06 - binary_accuracy: 1.0000 - val_loss: 0.1023 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 3.5374e-06 - binary_accuracy: 1.0000 - val_loss: 0.1002 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 4.2122e-06 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 2.9866e-06 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 4.9981e-06 - binary_accuracy: 1.0000 - val_loss: 0.1004 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 2.3329e-06 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 6.2287e-06 - binary_accuracy: 1.0000 - val_loss: 0.1030 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 2.0668e-06 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9864 - 8s/epoch - 123ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 2.3477e-06 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9869444370269775\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049069937\n",
      "train attribution time:  402.8006331920624\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038035754\n",
      "validation attribution time:  40.29059648513794\n",
      "time:  2754.2167913913727\n",
      "----- loop 12 :  [1752]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.32393431663513\n",
      "train data delta_a time:  1341.9573032855988\n",
      "train data time:  1409.281237602234\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.363625526428223\n",
      "validation data delta_a time:  123.78748989105225\n",
      "validation data time:  130.15111541748047\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0010 - binary_accuracy: 0.9998 - val_loss: 0.0838 - val_binary_accuracy: 0.9868 - 18s/epoch - 284ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 3.1810e-04 - binary_accuracy: 0.9999 - val_loss: 0.0873 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 2.1788e-04 - binary_accuracy: 0.9999 - val_loss: 0.0885 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 8.6955e-05 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 9.0981e-05 - binary_accuracy: 1.0000 - val_loss: 0.0888 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 8.4897e-05 - binary_accuracy: 1.0000 - val_loss: 0.0872 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 7.5132e-05 - binary_accuracy: 1.0000 - val_loss: 0.0894 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.6020e-04 - binary_accuracy: 0.9999 - val_loss: 0.0883 - val_binary_accuracy: 0.9882 - 8s/epoch - 119ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 4.6131e-05 - binary_accuracy: 1.0000 - val_loss: 0.0905 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 2.9721e-05 - binary_accuracy: 1.0000 - val_loss: 0.0917 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.6729e-05 - binary_accuracy: 1.0000 - val_loss: 0.0917 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.3726e-05 - binary_accuracy: 1.0000 - val_loss: 0.0905 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 4.6979e-05 - binary_accuracy: 1.0000 - val_loss: 0.0969 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.2885e-05 - binary_accuracy: 1.0000 - val_loss: 0.0921 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 4.3289e-05 - binary_accuracy: 1.0000 - val_loss: 0.0990 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.9934e-04 - binary_accuracy: 0.9999 - val_loss: 0.0956 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.1384e-04 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 3.6418e-05 - binary_accuracy: 1.0000 - val_loss: 0.0932 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 4.2052e-05 - binary_accuracy: 1.0000 - val_loss: 0.0988 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.4896e-05 - binary_accuracy: 1.0000 - val_loss: 0.1007 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 7.5347e-06 - binary_accuracy: 1.0000 - val_loss: 0.0955 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.8934e-05 - binary_accuracy: 1.0000 - val_loss: 0.0975 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 9.6034e-06 - binary_accuracy: 1.0000 - val_loss: 0.1033 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 7.8252e-06 - binary_accuracy: 1.0000 - val_loss: 0.0969 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 5.2030e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.9787e-05 - binary_accuracy: 1.0000 - val_loss: 0.1002 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.3001e-05 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 9.8244e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 9.1772e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 6.5477e-06 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 5.1603e-06 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 5.1986e-06 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 4.9224e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 9.1126e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 5.5029e-06 - binary_accuracy: 1.0000 - val_loss: 0.1010 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 4.1800e-06 - binary_accuracy: 1.0000 - val_loss: 0.0979 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 4.1749e-06 - binary_accuracy: 1.0000 - val_loss: 0.0981 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 6.5102e-06 - binary_accuracy: 1.0000 - val_loss: 0.0991 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 2.8043e-06 - binary_accuracy: 1.0000 - val_loss: 0.0953 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 4.3108e-06 - binary_accuracy: 1.0000 - val_loss: 0.0982 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 8.9437e-06 - binary_accuracy: 1.0000 - val_loss: 0.1031 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 4.9068e-06 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 6.2881e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.8058e-06 - binary_accuracy: 1.0000 - val_loss: 0.1034 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 5.4838e-06 - binary_accuracy: 1.0000 - val_loss: 0.1089 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 3.1463e-06 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 4.5060e-06 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.8551e-05 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 5.1164e-06 - binary_accuracy: 1.0000 - val_loss: 0.1006 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 4.2713e-06 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 4.5580e-06 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 4.4091e-06 - binary_accuracy: 1.0000 - val_loss: 0.1003 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.0762e-06 - binary_accuracy: 1.0000 - val_loss: 0.1033 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.5194e-06 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 3.8606e-06 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 2.0188e-06 - binary_accuracy: 1.0000 - val_loss: 0.1027 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.6494e-06 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.1204e-06 - binary_accuracy: 1.0000 - val_loss: 0.1057 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 2.0491e-06 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.7081e-06 - binary_accuracy: 1.0000 - val_loss: 0.0981 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.3577e-06 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.7540e-06 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 9.2039e-07 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.8886e-06 - binary_accuracy: 1.0000 - val_loss: 0.1067 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.6271e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.0560e-06 - binary_accuracy: 1.0000 - val_loss: 0.0992 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 8.8875e-07 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 8.2052e-06 - binary_accuracy: 1.0000 - val_loss: 0.1033 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 2.1985e-05 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 6.2058e-06 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.1080e-05 - binary_accuracy: 1.0000 - val_loss: 0.0976 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 3.2673e-06 - binary_accuracy: 1.0000 - val_loss: 0.1008 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.9492e-06 - binary_accuracy: 1.0000 - val_loss: 0.0996 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 4.1602e-06 - binary_accuracy: 1.0000 - val_loss: 0.1030 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 4.8430e-06 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.8326e-06 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.2257e-05 - binary_accuracy: 1.0000 - val_loss: 0.1034 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.1755e-04 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 4.1116e-04 - binary_accuracy: 0.9999 - val_loss: 0.1091 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 2.7565e-05 - binary_accuracy: 1.0000 - val_loss: 0.1015 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 2.1338e-05 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 4.0340e-06 - binary_accuracy: 1.0000 - val_loss: 0.1031 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 7.0648e-06 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 3.8863e-06 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 4.0574e-06 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 4.4750e-06 - binary_accuracy: 1.0000 - val_loss: 0.1068 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 3.7184e-06 - binary_accuracy: 1.0000 - val_loss: 0.1060 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.4185e-06 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 5.1562e-06 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.9921e-06 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 3.7764e-06 - binary_accuracy: 1.0000 - val_loss: 0.1073 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 2.7358e-06 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.6129e-06 - binary_accuracy: 1.0000 - val_loss: 0.1042 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.9230e-06 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.7705e-06 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.8474e-06 - binary_accuracy: 1.0000 - val_loss: 0.1089 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.4675e-06 - binary_accuracy: 1.0000 - val_loss: 0.1077 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.0861e-05 - binary_accuracy: 1.0000 - val_loss: 0.1030 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 2.5506e-06 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 2.9704e-06 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.987083375453949\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049146127\n",
      "train attribution time:  401.74966740608215\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038231485\n",
      "validation attribution time:  41.143717527389526\n",
      "time:  2755.0764062404633\n",
      "----- loop 13 :  [1737]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.75928092002869\n",
      "train data delta_a time:  1338.0555112361908\n",
      "train data time:  1405.8147921562195\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.420472860336304\n",
      "validation data delta_a time:  120.94542837142944\n",
      "validation data time:  127.36590123176575\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0016 - binary_accuracy: 0.9997 - val_loss: 0.1002 - val_binary_accuracy: 0.9881 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.0011 - binary_accuracy: 0.9998 - val_loss: 0.0987 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 5.5182e-04 - binary_accuracy: 0.9999 - val_loss: 0.0922 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 8.8417e-04 - binary_accuracy: 0.9999 - val_loss: 0.0938 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 8.2248e-05 - binary_accuracy: 1.0000 - val_loss: 0.0931 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.5871e-04 - binary_accuracy: 1.0000 - val_loss: 0.0927 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.4532e-04 - binary_accuracy: 0.9999 - val_loss: 0.0932 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.3131e-04 - binary_accuracy: 0.9999 - val_loss: 0.0974 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.0134e-04 - binary_accuracy: 0.9999 - val_loss: 0.0972 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 6.7327e-05 - binary_accuracy: 1.0000 - val_loss: 0.0918 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 2.4971e-05 - binary_accuracy: 1.0000 - val_loss: 0.0963 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.5412e-05 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9887 - 8s/epoch - 119ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 3.6773e-05 - binary_accuracy: 1.0000 - val_loss: 0.0996 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 5.2734e-05 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 2.2814e-05 - binary_accuracy: 1.0000 - val_loss: 0.0987 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.9524e-05 - binary_accuracy: 1.0000 - val_loss: 0.0994 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 2.6196e-05 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.8323e-05 - binary_accuracy: 1.0000 - val_loss: 0.1034 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 3.2179e-05 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.1626e-05 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.6268e-04 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.2582e-05 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9887 - 8s/epoch - 119ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.0671e-05 - binary_accuracy: 1.0000 - val_loss: 0.1027 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.5048e-05 - binary_accuracy: 1.0000 - val_loss: 0.1034 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.3782e-05 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 5.7418e-06 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.1657e-05 - binary_accuracy: 1.0000 - val_loss: 0.1009 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.3453e-05 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 5.5550e-06 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 9.0529e-06 - binary_accuracy: 1.0000 - val_loss: 0.1042 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.0738e-05 - binary_accuracy: 1.0000 - val_loss: 0.1009 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 7.2098e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 4.6936e-06 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 5.3683e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 3.8113e-06 - binary_accuracy: 1.0000 - val_loss: 0.0974 - val_binary_accuracy: 0.9883 - 8s/epoch - 119ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 6.3430e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 8.6389e-06 - binary_accuracy: 1.0000 - val_loss: 0.1010 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 9.9928e-06 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 9.5675e-06 - binary_accuracy: 1.0000 - val_loss: 0.1022 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 5.3537e-06 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 8.4757e-06 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 5.9460e-06 - binary_accuracy: 1.0000 - val_loss: 0.1043 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 4.3474e-06 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.7377e-06 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 3.7544e-06 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 5.2034e-06 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 3.4071e-06 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 3.2124e-06 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.5028e-06 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.2709e-06 - binary_accuracy: 1.0000 - val_loss: 0.1004 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 3.3318e-06 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.2806e-06 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 4.6562e-05 - binary_accuracy: 1.0000 - val_loss: 0.0987 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.0671e-05 - binary_accuracy: 1.0000 - val_loss: 0.0918 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.2153e-05 - binary_accuracy: 1.0000 - val_loss: 0.0974 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.3204e-06 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 4.8743e-06 - binary_accuracy: 1.0000 - val_loss: 0.0963 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 5.2645e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9892 - 8s/epoch - 119ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 4.1610e-04 - binary_accuracy: 0.9999 - val_loss: 0.0994 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 9.2104e-06 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 6.8182e-06 - binary_accuracy: 1.0000 - val_loss: 0.0978 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 2.8531e-06 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.8150e-05 - binary_accuracy: 1.0000 - val_loss: 0.1042 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.0458e-04 - binary_accuracy: 1.0000 - val_loss: 0.1047 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.4405e-05 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 7.1467e-06 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 5.2123e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.3484e-06 - binary_accuracy: 1.0000 - val_loss: 0.0992 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 5.8157e-06 - binary_accuracy: 1.0000 - val_loss: 0.1066 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.5986e-05 - binary_accuracy: 1.0000 - val_loss: 0.0968 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 5.7766e-06 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 3.6335e-06 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.2235e-06 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 2.5186e-05 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 9.0779e-06 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.9798e-06 - binary_accuracy: 1.0000 - val_loss: 0.1006 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.9258e-06 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.4542e-06 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 3.7436e-06 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.6143e-06 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.9447e-06 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.0156e-06 - binary_accuracy: 1.0000 - val_loss: 0.1024 - val_binary_accuracy: 0.9886 - 8s/epoch - 119ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.4877e-06 - binary_accuracy: 1.0000 - val_loss: 0.1064 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 5.0339e-06 - binary_accuracy: 1.0000 - val_loss: 0.1065 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 6.0635e-06 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.1175e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9885 - 8s/epoch - 119ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.1099e-06 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 3.9929e-05 - binary_accuracy: 1.0000 - val_loss: 0.0961 - val_binary_accuracy: 0.9890 - 8s/epoch - 119ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 3.1698e-05 - binary_accuracy: 1.0000 - val_loss: 0.1036 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 7.6585e-06 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.2788e-04 - binary_accuracy: 0.9999 - val_loss: 0.0948 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.9698e-05 - binary_accuracy: 1.0000 - val_loss: 0.0982 - val_binary_accuracy: 0.9883 - 8s/epoch - 119ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.1566e-05 - binary_accuracy: 1.0000 - val_loss: 0.0941 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 5.9666e-06 - binary_accuracy: 1.0000 - val_loss: 0.0951 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 2.9891e-06 - binary_accuracy: 1.0000 - val_loss: 0.0943 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 7.8349e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 4.5494e-06 - binary_accuracy: 1.0000 - val_loss: 0.0973 - val_binary_accuracy: 0.9890 - 8s/epoch - 119ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 9.6621e-06 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 2.5959e-06 - binary_accuracy: 1.0000 - val_loss: 0.0976 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 2.3378e-06 - binary_accuracy: 1.0000 - val_loss: 0.0977 - val_binary_accuracy: 0.9896 - 8s/epoch - 120ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9895832538604736\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04915178\n",
      "train attribution time:  404.66204738616943\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038139917\n",
      "validation attribution time:  40.25785422325134\n",
      "time:  2746.5124683380127\n",
      "----- loop 14 :  [1739]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.57237386703491\n",
      "train data delta_a time:  1344.589416027069\n",
      "train data time:  1412.161789894104\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.300832986831665\n",
      "validation data delta_a time:  119.8888669013977\n",
      "validation data time:  126.18969988822937\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 5.7553e-04 - binary_accuracy: 0.9998 - val_loss: 0.1050 - val_binary_accuracy: 0.9871 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 2.8457e-04 - binary_accuracy: 0.9999 - val_loss: 0.1034 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.6579e-04 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9876 - 8s/epoch - 119ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.0000e-04 - binary_accuracy: 1.0000 - val_loss: 0.1049 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.7606e-05 - binary_accuracy: 1.0000 - val_loss: 0.1031 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 6.7329e-05 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 6.3789e-05 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.7506e-05 - binary_accuracy: 1.0000 - val_loss: 0.1035 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 5.3192e-05 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 5.7584e-05 - binary_accuracy: 1.0000 - val_loss: 0.1042 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 4.7893e-05 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 4.9537e-05 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.2967e-04 - binary_accuracy: 1.0000 - val_loss: 0.1050 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.5528e-05 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 8.9279e-06 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.5313e-05 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 5.3935e-06 - binary_accuracy: 1.0000 - val_loss: 0.1049 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.1441e-06 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 8.4102e-06 - binary_accuracy: 1.0000 - val_loss: 0.1026 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.3808e-06 - binary_accuracy: 1.0000 - val_loss: 0.1054 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.0539e-05 - binary_accuracy: 1.0000 - val_loss: 0.1047 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.9515e-06 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 3.9670e-06 - binary_accuracy: 1.0000 - val_loss: 0.1057 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 9.3078e-06 - binary_accuracy: 1.0000 - val_loss: 0.1039 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 4.5687e-06 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.0645e-05 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.4797e-06 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 3.7796e-06 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 2.7600e-06 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.6783e-06 - binary_accuracy: 1.0000 - val_loss: 0.1061 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.6312e-06 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.5608e-06 - binary_accuracy: 1.0000 - val_loss: 0.1023 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 2.0322e-06 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.5679e-06 - binary_accuracy: 1.0000 - val_loss: 0.1062 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.0569e-06 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.3989e-06 - binary_accuracy: 1.0000 - val_loss: 0.1073 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 4.9192e-06 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.3652e-06 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 2.3621e-06 - binary_accuracy: 1.0000 - val_loss: 0.1081 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.3100e-06 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.8613e-06 - binary_accuracy: 1.0000 - val_loss: 0.1053 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.3490e-06 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 3.4817e-06 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.2743e-06 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 9.5178e-07 - binary_accuracy: 1.0000 - val_loss: 0.1110 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 9.7020e-07 - binary_accuracy: 1.0000 - val_loss: 0.1115 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 6.4310e-06 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.9222e-06 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.6816e-06 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.3312e-06 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 8.0127e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.2235e-06 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.0137e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 8.8323e-07 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.3487e-06 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 7.8625e-07 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 8.7811e-07 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 7.4152e-07 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.1285e-06 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.1265e-06 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 3.6732e-07 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 5.1990e-07 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 6.4502e-07 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.2137e-06 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.6816e-06 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9879 - 8s/epoch - 119ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 4.7701e-07 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 3.6577e-06 - binary_accuracy: 1.0000 - val_loss: 0.1146 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 5.4427e-06 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.8699e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 9.5323e-07 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 2.0442e-06 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.6779e-06 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.1810e-06 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 6.5306e-07 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 6.8505e-07 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.4661e-06 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 4.8005e-07 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 5.6977e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 5.1592e-07 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.1398e-06 - binary_accuracy: 1.0000 - val_loss: 0.1115 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 6.2231e-07 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9882 - 8s/epoch - 119ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.7549e-06 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 4.9212e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 2.6314e-05 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 0.1082 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 2.4690e-05 - binary_accuracy: 1.0000 - val_loss: 0.1063 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 6.3521e-06 - binary_accuracy: 1.0000 - val_loss: 0.1060 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.1353e-05 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 9.3000e-06 - binary_accuracy: 1.0000 - val_loss: 0.1039 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 2.7630e-06 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.3112e-05 - binary_accuracy: 1.0000 - val_loss: 0.1035 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.1903e-05 - binary_accuracy: 1.0000 - val_loss: 0.0979 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 4.2537e-06 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.6960e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9881 - 8s/epoch - 119ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 2.8398e-06 - binary_accuracy: 1.0000 - val_loss: 0.1030 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.0959e-06 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.5399e-06 - binary_accuracy: 1.0000 - val_loss: 0.1049 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 3.1071e-06 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 3.6245e-06 - binary_accuracy: 1.0000 - val_loss: 0.1039 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.9356e-06 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9876389503479004\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049138077\n",
      "train attribution time:  404.539986371994\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03808749\n",
      "validation attribution time:  40.329630613327026\n",
      "time:  2755.880446434021\n",
      "----- loop 15 :  [1691]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.1383798122406\n",
      "train data delta_a time:  1348.0526587963104\n",
      "train data time:  1415.191038608551\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.493972539901733\n",
      "validation data delta_a time:  119.9372615814209\n",
      "validation data time:  126.43123412132263\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 20s - loss: 0.0032 - binary_accuracy: 0.9994 - val_loss: 0.0901 - val_binary_accuracy: 0.9875 - 20s/epoch - 320ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.0012 - binary_accuracy: 0.9998 - val_loss: 0.0904 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 8.8214e-04 - binary_accuracy: 0.9998 - val_loss: 0.0918 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 4.7089e-04 - binary_accuracy: 0.9999 - val_loss: 0.0921 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 4.3131e-04 - binary_accuracy: 0.9999 - val_loss: 0.0901 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 4.2127e-04 - binary_accuracy: 0.9999 - val_loss: 0.0929 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 2.1919e-04 - binary_accuracy: 0.9999 - val_loss: 0.0922 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 2.6624e-04 - binary_accuracy: 0.9999 - val_loss: 0.0896 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.3643e-04 - binary_accuracy: 0.9999 - val_loss: 0.0872 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 2.6107e-04 - binary_accuracy: 0.9999 - val_loss: 0.0868 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 6.7210e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 9.2159e-05 - binary_accuracy: 1.0000 - val_loss: 0.0891 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 9.9734e-05 - binary_accuracy: 1.0000 - val_loss: 0.0867 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.5000e-04 - binary_accuracy: 0.9999 - val_loss: 0.0863 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 8.5373e-05 - binary_accuracy: 1.0000 - val_loss: 0.0917 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 5.0378e-05 - binary_accuracy: 1.0000 - val_loss: 0.0887 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 5.9521e-05 - binary_accuracy: 1.0000 - val_loss: 0.0879 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 2.8421e-05 - binary_accuracy: 1.0000 - val_loss: 0.0882 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 4.8893e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.9651e-05 - binary_accuracy: 1.0000 - val_loss: 0.0890 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 4.0370e-05 - binary_accuracy: 1.0000 - val_loss: 0.0930 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.6455e-05 - binary_accuracy: 1.0000 - val_loss: 0.0920 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 2.1994e-05 - binary_accuracy: 1.0000 - val_loss: 0.0948 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.8735e-05 - binary_accuracy: 1.0000 - val_loss: 0.0927 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.7120e-05 - binary_accuracy: 1.0000 - val_loss: 0.0951 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.3568e-05 - binary_accuracy: 1.0000 - val_loss: 0.0931 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.4613e-05 - binary_accuracy: 1.0000 - val_loss: 0.0897 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 2.5138e-05 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 4.7601e-05 - binary_accuracy: 1.0000 - val_loss: 0.0940 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 5.5516e-05 - binary_accuracy: 1.0000 - val_loss: 0.0973 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.1276e-05 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.3699e-05 - binary_accuracy: 1.0000 - val_loss: 0.0985 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.0391e-05 - binary_accuracy: 1.0000 - val_loss: 0.0922 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.4049e-05 - binary_accuracy: 1.0000 - val_loss: 0.0968 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.4134e-05 - binary_accuracy: 1.0000 - val_loss: 0.0960 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.1671e-05 - binary_accuracy: 1.0000 - val_loss: 0.0977 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.5688e-05 - binary_accuracy: 1.0000 - val_loss: 0.0934 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.2122e-05 - binary_accuracy: 1.0000 - val_loss: 0.0919 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 4.9363e-06 - binary_accuracy: 1.0000 - val_loss: 0.0902 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 9.2966e-06 - binary_accuracy: 1.0000 - val_loss: 0.0930 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 4.8726e-06 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.0951e-05 - binary_accuracy: 1.0000 - val_loss: 0.0984 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 6.1342e-06 - binary_accuracy: 1.0000 - val_loss: 0.0992 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 5.6886e-06 - binary_accuracy: 1.0000 - val_loss: 0.0987 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.2799e-05 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 1.4181e-05 - binary_accuracy: 1.0000 - val_loss: 0.0988 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 7.9912e-06 - binary_accuracy: 1.0000 - val_loss: 0.0976 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 8.2807e-06 - binary_accuracy: 1.0000 - val_loss: 0.1007 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 5.6239e-06 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 3.6527e-06 - binary_accuracy: 1.0000 - val_loss: 0.1043 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.1192e-05 - binary_accuracy: 1.0000 - val_loss: 0.0951 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.4673e-05 - binary_accuracy: 1.0000 - val_loss: 0.1012 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 8.0873e-06 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.6269e-05 - binary_accuracy: 1.0000 - val_loss: 0.0984 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 5.8947e-06 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.7108e-06 - binary_accuracy: 1.0000 - val_loss: 0.0954 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 2.1066e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 7.5029e-06 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 7.4090e-06 - binary_accuracy: 1.0000 - val_loss: 0.1004 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 3.9431e-06 - binary_accuracy: 1.0000 - val_loss: 0.1053 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 6.4869e-06 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 2.3105e-06 - binary_accuracy: 1.0000 - val_loss: 0.1026 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 3.4157e-06 - binary_accuracy: 1.0000 - val_loss: 0.1024 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 4.0707e-06 - binary_accuracy: 1.0000 - val_loss: 0.0959 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.2111e-06 - binary_accuracy: 1.0000 - val_loss: 0.0958 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 2.9656e-06 - binary_accuracy: 1.0000 - val_loss: 0.0988 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 3.7551e-06 - binary_accuracy: 1.0000 - val_loss: 0.1031 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 2.6279e-06 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 2.5735e-06 - binary_accuracy: 1.0000 - val_loss: 0.1009 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 4.5136e-05 - binary_accuracy: 1.0000 - val_loss: 0.0943 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 3.8023e-05 - binary_accuracy: 1.0000 - val_loss: 0.0904 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.1114e-05 - binary_accuracy: 1.0000 - val_loss: 0.0919 - val_binary_accuracy: 0.9889 - 8s/epoch - 123ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 3.7106e-06 - binary_accuracy: 1.0000 - val_loss: 0.0910 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.2843e-05 - binary_accuracy: 1.0000 - val_loss: 0.0952 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 4.8931e-06 - binary_accuracy: 1.0000 - val_loss: 0.0987 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 6.1692e-06 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 8.0615e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.8472e-05 - binary_accuracy: 1.0000 - val_loss: 0.0965 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 5.7696e-06 - binary_accuracy: 1.0000 - val_loss: 0.0911 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 6.5648e-06 - binary_accuracy: 1.0000 - val_loss: 0.0923 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 6.0185e-06 - binary_accuracy: 1.0000 - val_loss: 0.0946 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 8.1748e-06 - binary_accuracy: 1.0000 - val_loss: 0.0976 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 2.1731e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 3.5755e-06 - binary_accuracy: 1.0000 - val_loss: 0.0985 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 3.2798e-06 - binary_accuracy: 1.0000 - val_loss: 0.0981 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 2.5297e-06 - binary_accuracy: 1.0000 - val_loss: 0.0938 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 5.2490e-06 - binary_accuracy: 1.0000 - val_loss: 0.0957 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.4188e-06 - binary_accuracy: 1.0000 - val_loss: 0.0965 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.4278e-06 - binary_accuracy: 1.0000 - val_loss: 0.0971 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.1909e-06 - binary_accuracy: 1.0000 - val_loss: 0.0991 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.3880e-06 - binary_accuracy: 1.0000 - val_loss: 0.1010 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 2.5339e-06 - binary_accuracy: 1.0000 - val_loss: 0.0948 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.3441e-06 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.4865e-06 - binary_accuracy: 1.0000 - val_loss: 0.0994 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.2312e-06 - binary_accuracy: 1.0000 - val_loss: 0.1039 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.2418e-06 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.0727e-06 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 9.5836e-07 - binary_accuracy: 1.0000 - val_loss: 0.1010 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.3175e-06 - binary_accuracy: 1.0000 - val_loss: 0.1008 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 8.9873e-07 - binary_accuracy: 1.0000 - val_loss: 0.1026 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9884722828865051\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049114052\n",
      "train attribution time:  398.5249454975128\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.0381644\n",
      "validation attribution time:  39.28204083442688\n",
      "time:  2757.3315443992615\n",
      "----- loop 16 :  [1759]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.40782928466797\n",
      "train data delta_a time:  1333.0928480625153\n",
      "train data time:  1400.5006773471832\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.077608346939087\n",
      "validation data delta_a time:  121.26350092887878\n",
      "validation data time:  128.34110927581787\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0011 - binary_accuracy: 0.9998 - val_loss: 0.0999 - val_binary_accuracy: 0.9876 - 18s/epoch - 285ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 3.2270e-04 - binary_accuracy: 0.9999 - val_loss: 0.1119 - val_binary_accuracy: 0.9876 - 8s/epoch - 119ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 3.2066e-04 - binary_accuracy: 0.9999 - val_loss: 0.1126 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.9695e-04 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.5278e-04 - binary_accuracy: 0.9999 - val_loss: 0.1123 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 9.3015e-05 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 5.3724e-05 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 7.7769e-05 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.3963e-05 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.3072e-04 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 5.6870e-05 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.3937e-05 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 3.4459e-05 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 3.7860e-05 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 2.6555e-05 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 4.0448e-05 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.6275e-05 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.8931e-05 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.2445e-05 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 7.4448e-06 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 6.8961e-06 - binary_accuracy: 1.0000 - val_loss: 0.1175 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.6531e-05 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.0938e-05 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 3.0266e-05 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.9139e-05 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.2666e-04 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 4.7643e-05 - binary_accuracy: 1.0000 - val_loss: 0.1063 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 9.7440e-06 - binary_accuracy: 1.0000 - val_loss: 0.1091 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 1.1767e-05 - binary_accuracy: 1.0000 - val_loss: 0.1060 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 7.2741e-06 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 8.0735e-06 - binary_accuracy: 1.0000 - val_loss: 0.1099 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 4.2602e-06 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 6.6180e-06 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 7.7810e-06 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 3.7905e-06 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 5.0063e-06 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 6.6377e-06 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.1931e-06 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 3.7107e-06 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 5.9895e-06 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.6242e-06 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 3.3363e-06 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 2.0333e-06 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 4.1506e-06 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.8600e-06 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 3.0053e-06 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.1547e-06 - binary_accuracy: 1.0000 - val_loss: 0.1109 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.5764e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 6.2299e-06 - binary_accuracy: 1.0000 - val_loss: 0.1096 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.0390e-06 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.7491e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.5074e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.5001e-06 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.3687e-06 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.0632e-06 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.7258e-06 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.4858e-06 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.3451e-06 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 4.0526e-06 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 2.2263e-06 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.2454e-06 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 7.2654e-07 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 3.2838e-05 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.1852e-06 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.7185e-06 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 2.0039e-06 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.9770e-06 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.8278e-06 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.2999e-06 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 2.7609e-06 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.3588e-06 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 5.2428e-06 - binary_accuracy: 1.0000 - val_loss: 0.1218 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 4.3472e-06 - binary_accuracy: 1.0000 - val_loss: 0.1204 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.9131e-06 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 2.1694e-06 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.0180e-06 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.2244e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.8425e-06 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 2.1215e-04 - binary_accuracy: 0.9999 - val_loss: 0.1149 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 2.8564e-04 - binary_accuracy: 0.9999 - val_loss: 0.1045 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 4.8107e-05 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 9.7398e-05 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 5.4512e-05 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.1819e-05 - binary_accuracy: 1.0000 - val_loss: 0.1080 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 4.4324e-06 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 5.7261e-06 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.3582e-06 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 4.1417e-06 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.3741e-06 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 2.9693e-06 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 3.0058e-06 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.5010e-06 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.1641e-04 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.2463e-05 - binary_accuracy: 1.0000 - val_loss: 0.0989 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 5.6826e-06 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 4.5640e-06 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.9731e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 3.8143e-06 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.5530e-06 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.4503e-06 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9876389503479004\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04899575\n",
      "train attribution time:  402.57315611839294\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037871934\n",
      "validation attribution time:  40.173338890075684\n",
      "time:  2745.0917003154755\n",
      "----- loop 17 :  [1759]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.26810312271118\n",
      "train data delta_a time:  1330.5585911273956\n",
      "train data time:  1397.8266942501068\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.425846338272095\n",
      "validation data delta_a time:  121.27893948554993\n",
      "validation data time:  127.70478582382202\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0013 - binary_accuracy: 0.9998 - val_loss: 0.0959 - val_binary_accuracy: 0.9897 - 18s/epoch - 284ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 3.0139e-04 - binary_accuracy: 0.9999 - val_loss: 0.0947 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.0084e-04 - binary_accuracy: 1.0000 - val_loss: 0.0900 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 9.0464e-05 - binary_accuracy: 1.0000 - val_loss: 0.0906 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 7.2482e-05 - binary_accuracy: 1.0000 - val_loss: 0.0964 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 6.7447e-05 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 3.3897e-05 - binary_accuracy: 1.0000 - val_loss: 0.0957 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 4.3844e-05 - binary_accuracy: 1.0000 - val_loss: 0.0992 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.7764e-05 - binary_accuracy: 1.0000 - val_loss: 0.0970 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.8279e-05 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 5.1404e-05 - binary_accuracy: 1.0000 - val_loss: 0.0968 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 7.5416e-05 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 4.8836e-05 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 4.3166e-05 - binary_accuracy: 1.0000 - val_loss: 0.0977 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 2.8393e-05 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.8336e-05 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 9.8669e-06 - binary_accuracy: 1.0000 - val_loss: 0.0996 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 2.2114e-05 - binary_accuracy: 1.0000 - val_loss: 0.0993 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.1931e-05 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 9.5333e-06 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 6.7850e-06 - binary_accuracy: 1.0000 - val_loss: 0.1008 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 9.6495e-06 - binary_accuracy: 1.0000 - val_loss: 0.1043 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 4.6902e-06 - binary_accuracy: 1.0000 - val_loss: 0.1031 - val_binary_accuracy: 0.9889 - 8s/epoch - 119ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 4.7079e-06 - binary_accuracy: 1.0000 - val_loss: 0.1053 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 4.5545e-04 - binary_accuracy: 0.9999 - val_loss: 0.1054 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 3.0558e-04 - binary_accuracy: 0.9999 - val_loss: 0.1013 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.3407e-05 - binary_accuracy: 1.0000 - val_loss: 0.1026 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.7316e-05 - binary_accuracy: 1.0000 - val_loss: 0.1039 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 6.8824e-06 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 3.4338e-05 - binary_accuracy: 1.0000 - val_loss: 0.1065 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.0909e-05 - binary_accuracy: 1.0000 - val_loss: 0.1036 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.0353e-05 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.1714e-05 - binary_accuracy: 1.0000 - val_loss: 0.1030 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 5.8795e-05 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.0306e-05 - binary_accuracy: 1.0000 - val_loss: 0.0994 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 4.0723e-05 - binary_accuracy: 1.0000 - val_loss: 0.0948 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.5379e-05 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 4.9225e-06 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 5.5721e-06 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 4.3178e-06 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 2.8321e-06 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 2.0156e-06 - binary_accuracy: 1.0000 - val_loss: 0.0966 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 2.0006e-06 - binary_accuracy: 1.0000 - val_loss: 0.1079 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 8.7972e-06 - binary_accuracy: 1.0000 - val_loss: 0.1012 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 3.0019e-06 - binary_accuracy: 1.0000 - val_loss: 0.1027 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 3.3579e-06 - binary_accuracy: 1.0000 - val_loss: 0.1047 - val_binary_accuracy: 0.9881 - 8s/epoch - 119ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 4.0400e-06 - binary_accuracy: 1.0000 - val_loss: 0.1042 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.5861e-06 - binary_accuracy: 1.0000 - val_loss: 0.1019 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.8285e-06 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 8.6566e-06 - binary_accuracy: 1.0000 - val_loss: 0.0992 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 7.0638e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.0571e-06 - binary_accuracy: 1.0000 - val_loss: 0.1052 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.3331e-06 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 5.6473e-06 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 4.4610e-06 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.8321e-06 - binary_accuracy: 1.0000 - val_loss: 0.1027 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.8749e-06 - binary_accuracy: 1.0000 - val_loss: 0.1077 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.5241e-06 - binary_accuracy: 1.0000 - val_loss: 0.1064 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.7170e-06 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 2.0111e-06 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.1691e-06 - binary_accuracy: 1.0000 - val_loss: 0.1071 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.2350e-06 - binary_accuracy: 1.0000 - val_loss: 0.1059 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.2052e-06 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.2126e-06 - binary_accuracy: 1.0000 - val_loss: 0.1050 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.3361e-06 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.6543e-06 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 7.5241e-07 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.2212e-06 - binary_accuracy: 1.0000 - val_loss: 0.1109 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 9.9395e-07 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.4412e-06 - binary_accuracy: 1.0000 - val_loss: 0.1096 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.2112e-06 - binary_accuracy: 1.0000 - val_loss: 0.1081 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 3.2228e-06 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.3864e-04 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 5.5337e-05 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 7.8948e-05 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 2.7828e-05 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 8.1348e-05 - binary_accuracy: 1.0000 - val_loss: 0.0950 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 4.9671e-05 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 8.3156e-06 - binary_accuracy: 1.0000 - val_loss: 0.1003 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 5.2605e-06 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 3.7637e-06 - binary_accuracy: 1.0000 - val_loss: 0.1039 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.2012e-06 - binary_accuracy: 1.0000 - val_loss: 0.0977 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.5488e-06 - binary_accuracy: 1.0000 - val_loss: 0.1012 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 2.2250e-06 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 1.1874e-06 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.1154e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 3.0936e-06 - binary_accuracy: 1.0000 - val_loss: 0.0995 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.1161e-06 - binary_accuracy: 1.0000 - val_loss: 0.1000 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.1709e-06 - binary_accuracy: 1.0000 - val_loss: 0.0996 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.2511e-06 - binary_accuracy: 1.0000 - val_loss: 0.1007 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 9.4458e-07 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 4.1197e-06 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.4380e-06 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 9.4150e-07 - binary_accuracy: 1.0000 - val_loss: 0.0988 - val_binary_accuracy: 0.9886 - 8s/epoch - 119ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.4221e-06 - binary_accuracy: 1.0000 - val_loss: 0.0969 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.2958e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 2.3749e-06 - binary_accuracy: 1.0000 - val_loss: 0.0988 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 7.0475e-07 - binary_accuracy: 1.0000 - val_loss: 0.0984 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 6.7729e-07 - binary_accuracy: 1.0000 - val_loss: 0.1013 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.3664e-06 - binary_accuracy: 1.0000 - val_loss: 0.0980 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9883333444595337\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049160697\n",
      "train attribution time:  401.492311000824\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038020827\n",
      "validation attribution time:  39.72033667564392\n",
      "time:  2737.932429075241\n",
      "----- loop 18 :  [1762]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.03154301643372\n",
      "train data delta_a time:  1333.8945469856262\n",
      "train data time:  1399.92609000206\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.379637241363525\n",
      "validation data delta_a time:  121.42086005210876\n",
      "validation data time:  127.80049729347229\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 1.7030e-04 - binary_accuracy: 0.9999 - val_loss: 0.1119 - val_binary_accuracy: 0.9875 - 18s/epoch - 284ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 5.2997e-05 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.8030e-05 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 7.9579e-06 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.2144e-05 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.5098e-05 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.3195e-05 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 2.9649e-05 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.1727e-05 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9878 - 8s/epoch - 119ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 4.6143e-05 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 2.7393e-05 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.9612e-06 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 7.6516e-06 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 2.3291e-06 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.4783e-06 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.0236e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.9205e-06 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 8.8855e-07 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 3.9796e-05 - binary_accuracy: 1.0000 - val_loss: 0.1164 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 7.8738e-06 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 2.0214e-06 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 4.2409e-06 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.8853e-06 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.6109e-06 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.6705e-06 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.5387e-06 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.6582e-06 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 2.2319e-06 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 2.5217e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 3.2067e-06 - binary_accuracy: 1.0000 - val_loss: 0.1136 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 6.7434e-07 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.9234e-06 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.7133e-06 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.4884e-06 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.1046e-04 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 6.9284e-06 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 3.4564e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.2115e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 6.8977e-07 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.8677e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 2.0869e-06 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9879 - 8s/epoch - 119ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 4.0366e-06 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.2865e-06 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 7.4338e-07 - binary_accuracy: 1.0000 - val_loss: 0.1175 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 6.6013e-07 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 1.5807e-05 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.9427e-05 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 6.9221e-06 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.9136e-06 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.7861e-06 - binary_accuracy: 1.0000 - val_loss: 0.1109 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 4.5076e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 8.7993e-07 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 6.3254e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 5.8879e-07 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.1528e-06 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.0074e-06 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 5.8594e-07 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 7.7808e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 4.4654e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 7.9421e-07 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 5.0801e-07 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.2578e-06 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 4.3147e-07 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.6954e-06 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.9379e-06 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 6.2245e-04 - binary_accuracy: 0.9999 - val_loss: 0.1143 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 9.2591e-05 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 6.5415e-06 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 4.3838e-06 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 7.7658e-06 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 3.1300e-06 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.1079e-06 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.1981e-06 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 2.3863e-06 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 6.4443e-07 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 4.1454e-06 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 9.5561e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 8.0940e-06 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.7745e-06 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 2.4568e-06 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.6035e-05 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 4.7367e-06 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 2.1397e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.0976e-06 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 3.0517e-06 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 6.6220e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 5.6269e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.1365e-06 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 3.0611e-06 - binary_accuracy: 1.0000 - val_loss: 0.1204 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 7.8170e-07 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 5.9297e-07 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.9526e-06 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 6.3330e-06 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 4.8924e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.5749e-06 - binary_accuracy: 1.0000 - val_loss: 0.1110 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 7.6606e-07 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 2.1320e-06 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9878 - 8s/epoch - 119ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 6.4081e-07 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 7.8417e-07 - binary_accuracy: 1.0000 - val_loss: 0.1164 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 7s - loss: 2.8618e-06 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9872 - 7s/epoch - 119ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9872221946716309\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049093097\n",
      "train attribution time:  402.83319211006165\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037705168\n",
      "validation attribution time:  39.84936785697937\n",
      "time:  2741.0965752601624\n",
      "----- loop 19 :  [1763]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.1823079586029\n",
      "train data delta_a time:  1329.664175271988\n",
      "train data time:  1396.8464832305908\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.832079887390137\n",
      "validation data delta_a time:  121.68328094482422\n",
      "validation data time:  128.51536083221436\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 5.8471e-04 - binary_accuracy: 0.9999 - val_loss: 0.1101 - val_binary_accuracy: 0.9882 - 18s/epoch - 281ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 1.5746e-04 - binary_accuracy: 0.9999 - val_loss: 0.1109 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.0729e-04 - binary_accuracy: 0.9999 - val_loss: 0.1035 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 7s - loss: 6.3535e-05 - binary_accuracy: 1.0000 - val_loss: 0.1063 - val_binary_accuracy: 0.9881 - 7s/epoch - 119ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.0853e-05 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.2868e-05 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.0771e-05 - binary_accuracy: 1.0000 - val_loss: 0.1022 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 4.5293e-06 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 1.4118e-04 - binary_accuracy: 0.9999 - val_loss: 0.1044 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.0386e-05 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.3964e-06 - binary_accuracy: 1.0000 - val_loss: 0.1067 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.0661e-05 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.5588e-05 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 2.2987e-05 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 2.2308e-06 - binary_accuracy: 1.0000 - val_loss: 0.1115 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 3.7534e-06 - binary_accuracy: 1.0000 - val_loss: 0.1066 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 2.0757e-05 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.3696e-05 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 3.2884e-06 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.4317e-06 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 2.8107e-06 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.8723e-06 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.4876e-06 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.7333e-06 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9879 - 8s/epoch - 119ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.6010e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 7.3660e-07 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.0687e-05 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.9347e-06 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 3.6088e-06 - binary_accuracy: 1.0000 - val_loss: 0.1207 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.4559e-06 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 5.4659e-06 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.7174e-06 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 9.5625e-07 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 2.9100e-06 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.2167e-06 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.6641e-05 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 6.4915e-06 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.1102e-06 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 2.8045e-05 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 2.8027e-06 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 2.3068e-06 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 6.7578e-06 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.1646e-06 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 7.2320e-07 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9889 - 8s/epoch - 119ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.7810e-06 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 6.3925e-07 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 3.2224e-06 - binary_accuracy: 1.0000 - val_loss: 0.1164 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 6.2984e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 8.0615e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 5.0945e-07 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 9.4969e-07 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 5.5450e-06 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.1307e-05 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.3821e-06 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.4980e-06 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.0659e-06 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 6.4834e-07 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 2.5393e-06 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 6.4050e-07 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.1804e-06 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.4382e-06 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 2.5867e-06 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 7.7602e-07 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.5121e-06 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 3.9370e-07 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 7.9892e-07 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 4.3253e-07 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9872 - 8s/epoch - 119ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.0322e-06 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 4.0670e-07 - binary_accuracy: 1.0000 - val_loss: 0.1136 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 4.8067e-07 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.1535e-06 - binary_accuracy: 1.0000 - val_loss: 0.1164 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.6981e-05 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 4.0202e-07 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 4.0192e-04 - binary_accuracy: 1.0000 - val_loss: 0.1095 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.9236e-04 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9876 - 8s/epoch - 119ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.1415e-05 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 3.1528e-05 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.3304e-05 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 2.9794e-06 - binary_accuracy: 1.0000 - val_loss: 0.1106 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.9494e-06 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.4595e-06 - binary_accuracy: 1.0000 - val_loss: 0.1099 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.3795e-05 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 3.1305e-06 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.8417e-06 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 6.2875e-05 - binary_accuracy: 1.0000 - val_loss: 0.1086 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 3.1726e-06 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.1923e-06 - binary_accuracy: 1.0000 - val_loss: 0.1071 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 3.8166e-06 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.9060e-06 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.4934e-06 - binary_accuracy: 1.0000 - val_loss: 0.1059 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.0572e-06 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.9967e-06 - binary_accuracy: 1.0000 - val_loss: 0.1063 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.0937e-06 - binary_accuracy: 1.0000 - val_loss: 0.1080 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 8.5661e-07 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 7.1437e-07 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.0003e-06 - binary_accuracy: 1.0000 - val_loss: 0.1086 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 7.0366e-07 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 6.3789e-07 - binary_accuracy: 1.0000 - val_loss: 0.1099 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 7.1207e-07 - binary_accuracy: 1.0000 - val_loss: 0.1080 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 6.4967e-07 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9887501001358032\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04912223\n",
      "train attribution time:  401.8511862754822\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03801148\n",
      "validation attribution time:  39.79938530921936\n",
      "time:  2738.2643971443176\n",
      "----- loop 20 :  [1765]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.24242448806763\n",
      "train data delta_a time:  1332.485805273056\n",
      "train data time:  1399.7282297611237\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.114545106887817\n",
      "validation data delta_a time:  120.99570226669312\n",
      "validation data time:  128.11024737358093\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0023 - binary_accuracy: 0.9997 - val_loss: 0.1046 - val_binary_accuracy: 0.9861 - 18s/epoch - 284ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 4.9342e-04 - binary_accuracy: 0.9998 - val_loss: 0.1021 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 3.6966e-04 - binary_accuracy: 0.9999 - val_loss: 0.1039 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 4.8395e-04 - binary_accuracy: 0.9999 - val_loss: 0.1037 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.0245e-04 - binary_accuracy: 1.0000 - val_loss: 0.1042 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 6.2404e-05 - binary_accuracy: 1.0000 - val_loss: 0.1072 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.6785e-04 - binary_accuracy: 0.9999 - val_loss: 0.1077 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.2104e-04 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 9.7206e-05 - binary_accuracy: 1.0000 - val_loss: 0.1073 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 6.6266e-05 - binary_accuracy: 1.0000 - val_loss: 0.1023 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 4.1007e-05 - binary_accuracy: 1.0000 - val_loss: 0.1066 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.1487e-05 - binary_accuracy: 1.0000 - val_loss: 0.0985 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.1927e-05 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 2.2616e-04 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.7625e-05 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.1348e-05 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 7.0030e-06 - binary_accuracy: 1.0000 - val_loss: 0.1080 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 6.7513e-05 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.7873e-05 - binary_accuracy: 1.0000 - val_loss: 0.1026 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.1412e-05 - binary_accuracy: 1.0000 - val_loss: 0.1047 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 8.1230e-06 - binary_accuracy: 1.0000 - val_loss: 0.1072 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 4.3118e-06 - binary_accuracy: 1.0000 - val_loss: 0.1096 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 4.7281e-06 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 5.4506e-06 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 6.5890e-06 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 3.6865e-06 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 5.9012e-06 - binary_accuracy: 1.0000 - val_loss: 0.1050 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 5.5582e-06 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 6.9192e-06 - binary_accuracy: 1.0000 - val_loss: 0.1099 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.2087e-06 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.3813e-06 - binary_accuracy: 1.0000 - val_loss: 0.1061 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 7.1250e-06 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.9769e-05 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 4.2309e-06 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 4.6897e-06 - binary_accuracy: 1.0000 - val_loss: 0.1065 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 4.1328e-06 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.5076e-06 - binary_accuracy: 1.0000 - val_loss: 0.1073 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.8628e-06 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.9542e-06 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 2.3358e-06 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.5273e-06 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.1026e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 6.5512e-05 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.3776e-04 - binary_accuracy: 0.9999 - val_loss: 0.0999 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 5.9938e-05 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 1.5815e-05 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 6.1371e-06 - binary_accuracy: 1.0000 - val_loss: 0.1086 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 3.8785e-06 - binary_accuracy: 1.0000 - val_loss: 0.1003 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 2.8688e-06 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.0525e-06 - binary_accuracy: 1.0000 - val_loss: 0.1060 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 5.8086e-06 - binary_accuracy: 1.0000 - val_loss: 0.1067 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.5104e-06 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 4.7963e-06 - binary_accuracy: 1.0000 - val_loss: 0.1053 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.3802e-06 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.5252e-06 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.8207e-06 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 4.7394e-06 - binary_accuracy: 1.0000 - val_loss: 0.1065 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 4.3280e-06 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 4.6700e-06 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 8.6799e-07 - binary_accuracy: 1.0000 - val_loss: 0.1075 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.4713e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.3947e-06 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 8.9915e-07 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.0162e-06 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 3.5194e-05 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 6.1489e-06 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 2.1673e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.6762e-06 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 6.3709e-06 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 4.4840e-05 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.0072e-06 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.7746e-06 - binary_accuracy: 1.0000 - val_loss: 0.1054 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.6771e-06 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 8.9644e-07 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 4.2263e-05 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.1959e-05 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 2.3978e-06 - binary_accuracy: 1.0000 - val_loss: 0.1004 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.2466e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 5.7925e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 4.7074e-05 - binary_accuracy: 1.0000 - val_loss: 0.1054 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 5.1921e-05 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 5.6120e-06 - binary_accuracy: 1.0000 - val_loss: 0.0978 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 4.4421e-06 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.8051e-05 - binary_accuracy: 1.0000 - val_loss: 0.0924 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 1.9275e-06 - binary_accuracy: 1.0000 - val_loss: 0.0961 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 2.8586e-06 - binary_accuracy: 1.0000 - val_loss: 0.0962 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.2054e-06 - binary_accuracy: 1.0000 - val_loss: 0.0963 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.2077e-06 - binary_accuracy: 1.0000 - val_loss: 0.0961 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 8.9517e-07 - binary_accuracy: 1.0000 - val_loss: 0.0973 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.3876e-06 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.2632e-06 - binary_accuracy: 1.0000 - val_loss: 0.0961 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.0148e-06 - binary_accuracy: 1.0000 - val_loss: 0.0985 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 9.5139e-07 - binary_accuracy: 1.0000 - val_loss: 0.0987 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.0989e-06 - binary_accuracy: 1.0000 - val_loss: 0.0978 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 8.8035e-07 - binary_accuracy: 1.0000 - val_loss: 0.1003 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 9.2456e-07 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.3401e-06 - binary_accuracy: 1.0000 - val_loss: 0.0962 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 6.3978e-07 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 7.1023e-07 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.5974e-06 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9881945252418518\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049154665\n",
      "train attribution time:  397.2893314361572\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037974555\n",
      "validation attribution time:  41.017823696136475\n",
      "time:  2740.66894698143\n",
      "----- loop 21 :  [1765]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.39157128334045\n",
      "train data delta_a time:  1327.5883464813232\n",
      "train data time:  1393.9799177646637\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.754061937332153\n",
      "validation data delta_a time:  119.73128962516785\n",
      "validation data time:  126.4853515625\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 21s - loss: 1.3002e-04 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9879 - 21s/epoch - 330ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 2.4264e-05 - binary_accuracy: 1.0000 - val_loss: 0.1106 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 6.2097e-06 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.4546e-05 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 8.0345e-06 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.7261e-05 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 3.6006e-06 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.1476e-05 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 3.0653e-06 - binary_accuracy: 1.0000 - val_loss: 0.1096 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.5118e-06 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.1279e-06 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.8374e-06 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.2309e-05 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.2070e-05 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 6.8593e-07 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 5.4025e-07 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.5751e-06 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.8095e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.2028e-06 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 6.7941e-07 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 5.7262e-07 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 8.5108e-07 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 2.7327e-06 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 6.6087e-07 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 4.1051e-07 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 8.3884e-07 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.7244e-07 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 8.9798e-07 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 3.3207e-07 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 5.5966e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 3.5559e-07 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.9037e-07 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 9.5421e-07 - binary_accuracy: 1.0000 - val_loss: 0.1109 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 4.2532e-07 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 5.1470e-07 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.9922e-07 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 8.3535e-07 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 3.4554e-07 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 4.1015e-07 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 3.0485e-07 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 2.7963e-07 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.9744e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 6.8118e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.0716e-06 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 3.2294e-07 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 4.8348e-07 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 3.2368e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 4.1329e-07 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 2.0491e-07 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.9786e-06 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.0277e-06 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 7.5346e-07 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 6.4074e-07 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.7311e-07 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 4.1024e-07 - binary_accuracy: 1.0000 - val_loss: 0.1164 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.5542e-06 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 2.7441e-07 - binary_accuracy: 1.0000 - val_loss: 0.1202 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 2.5368e-07 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.5289e-07 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.7890e-04 - binary_accuracy: 0.9999 - val_loss: 0.1115 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.0008e-05 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 8.2799e-05 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 9.4732e-06 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.8052e-06 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 5.3209e-06 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 2.0697e-06 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.5768e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.2741e-05 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 5.1188e-05 - binary_accuracy: 1.0000 - val_loss: 0.1009 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 3.2808e-05 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 9.9092e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.1556e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 3.6983e-06 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.2091e-06 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.0888e-06 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 3.2836e-07 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 4.4435e-07 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 8.4794e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 2.8688e-07 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 4.7950e-07 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 8.3327e-07 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 4.9741e-07 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 6.2179e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 2.3825e-07 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 4.7610e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 2.6651e-07 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.6729e-07 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.3305e-07 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.4209e-06 - binary_accuracy: 1.0000 - val_loss: 0.1106 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 3.4895e-07 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.9519e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 2.2585e-07 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.7664e-07 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.4401e-07 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 3.1320e-07 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 6.6685e-07 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.6513e-07 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.7555e-06 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 5.6043e-05 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 9.0287e-06 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9873611927032471\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049122192\n",
      "train attribution time:  398.9431645870209\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03793472\n",
      "validation attribution time:  41.30020713806152\n",
      "time:  2737.782274723053\n",
      "----- loop 22 :  [1765]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.33945536613464\n",
      "train data delta_a time:  1332.060030221939\n",
      "train data time:  1399.3994855880737\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.005460739135742\n",
      "validation data delta_a time:  121.32973504066467\n",
      "validation data time:  128.33519577980042\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 8.1422e-05 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9879 - 18s/epoch - 285ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 1.1650e-05 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 3.2486e-06 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 4.1069e-05 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.5745e-06 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 4.6808e-06 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.3562e-06 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.5509e-05 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 1.1554e-04 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 3.5025e-06 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.4213e-06 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.8233e-06 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 6.8005e-06 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 2.5486e-06 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 3.2120e-05 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 2.2860e-05 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 4.6243e-07 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 4.1709e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 6.3958e-07 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 5.9565e-07 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 3.4382e-07 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 4.6524e-07 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 9.3915e-07 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.1579e-06 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.4361e-06 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.8865e-06 - binary_accuracy: 1.0000 - val_loss: 0.1257 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.9789e-07 - binary_accuracy: 1.0000 - val_loss: 0.1272 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.2591e-06 - binary_accuracy: 1.0000 - val_loss: 0.1227 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 1.4956e-06 - binary_accuracy: 1.0000 - val_loss: 0.1234 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 3.8343e-07 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.0698e-06 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 6.9610e-07 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.7573e-07 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 2.4737e-07 - binary_accuracy: 1.0000 - val_loss: 0.1223 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 4.6504e-07 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.2371e-07 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 4.0914e-07 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.4047e-07 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 3.3316e-07 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 4.2367e-07 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.7315e-07 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 8.8524e-07 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 5.7059e-07 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.5582e-07 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 4.8842e-07 - binary_accuracy: 1.0000 - val_loss: 0.1210 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 9.8360e-08 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.2139e-07 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.9818e-07 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.5134e-07 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.2202e-07 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 3.5041e-07 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 3.7231e-07 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 3.0496e-07 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.3932e-07 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.2128e-07 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.3780e-07 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.3650e-07 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.4742e-07 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 2.1916e-07 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 8.4852e-08 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 3.3769e-07 - binary_accuracy: 1.0000 - val_loss: 0.1246 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.8178e-07 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.4310e-07 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.6645e-07 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 0.9882 - 8s/epoch - 123ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 4.4578e-07 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.3204e-07 - binary_accuracy: 1.0000 - val_loss: 0.1196 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 3.4490e-07 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.6240e-07 - binary_accuracy: 1.0000 - val_loss: 0.1272 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.1757e-07 - binary_accuracy: 1.0000 - val_loss: 0.1238 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 3.8263e-06 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.2023e-04 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 9.8309e-05 - binary_accuracy: 0.9999 - val_loss: 0.1193 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.6184e-06 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 2.3683e-06 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.4636e-06 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.0606e-06 - binary_accuracy: 1.0000 - val_loss: 0.1146 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 2.4279e-06 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 5.3682e-07 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 6.1918e-07 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.1885e-06 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 8.5743e-07 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 5.1868e-07 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 5.1965e-07 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.0309e-06 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.1268e-07 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 6.7889e-07 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 3.4444e-07 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.7631e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.4888e-07 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 3.3665e-06 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 6.5880e-07 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 4.7128e-07 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 3.6870e-06 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 4.3746e-07 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 6.1827e-07 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 3.1402e-07 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 3.7118e-07 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 3.0078e-06 - binary_accuracy: 1.0000 - val_loss: 0.1099 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 9.6106e-07 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 5.2213e-07 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9890277981758118\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049120646\n",
      "train attribution time:  401.69612193107605\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03809306\n",
      "validation attribution time:  39.781524896621704\n",
      "time:  2744.3598806858063\n",
      "----- loop 23 :  [1765]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.85384106636047\n",
      "train data delta_a time:  1333.0865800380707\n",
      "train data time:  1401.9404211044312\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.581756114959717\n",
      "validation data delta_a time:  118.59417057037354\n",
      "validation data time:  125.17592668533325\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 3.4819e-04 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9879 - 18s/epoch - 286ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 9.6992e-05 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 4.2446e-06 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 8.0745e-05 - binary_accuracy: 1.0000 - val_loss: 0.1053 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.1004e-05 - binary_accuracy: 1.0000 - val_loss: 0.1059 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.0232e-06 - binary_accuracy: 1.0000 - val_loss: 0.1049 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 2.4309e-06 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 9.0470e-07 - binary_accuracy: 1.0000 - val_loss: 0.1067 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 6.5969e-07 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 2.3518e-06 - binary_accuracy: 1.0000 - val_loss: 0.1073 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.3513e-06 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.6618e-06 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.0219e-06 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 8.0413e-07 - binary_accuracy: 1.0000 - val_loss: 0.1028 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.0022e-06 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 4.5238e-06 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 9.2652e-07 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 3.0307e-07 - binary_accuracy: 1.0000 - val_loss: 0.1064 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 8.7526e-07 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.3232e-06 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.0033e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 5.5977e-07 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 7.3643e-06 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 6.5482e-04 - binary_accuracy: 0.9999 - val_loss: 0.1050 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 4.4307e-05 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 4.1696e-06 - binary_accuracy: 1.0000 - val_loss: 0.1039 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 8.5435e-06 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.4602e-06 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 9.2752e-07 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 5.1779e-07 - binary_accuracy: 1.0000 - val_loss: 0.1036 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 4.4168e-07 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.6122e-06 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.3273e-07 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 7.7335e-07 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 6.4068e-07 - binary_accuracy: 1.0000 - val_loss: 0.1035 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 6.8048e-07 - binary_accuracy: 1.0000 - val_loss: 0.1062 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 3.6599e-07 - binary_accuracy: 1.0000 - val_loss: 0.1049 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 6.6035e-07 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 5.1181e-06 - binary_accuracy: 1.0000 - val_loss: 0.1091 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 4.9075e-07 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 2.7486e-07 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 4.2959e-07 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 4.4226e-07 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.9390e-07 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 2.3887e-07 - binary_accuracy: 1.0000 - val_loss: 0.1080 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 4.6438e-07 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.6133e-07 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.9159e-07 - binary_accuracy: 1.0000 - val_loss: 0.1054 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 6.4776e-07 - binary_accuracy: 1.0000 - val_loss: 0.1075 - val_binary_accuracy: 0.9890 - 8s/epoch - 123ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.9276e-07 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.0148e-07 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 3.7652e-06 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 6.6808e-07 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.8812e-07 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.2888e-07 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.9114e-07 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 8.1079e-07 - binary_accuracy: 1.0000 - val_loss: 0.1075 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 9.2827e-07 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 4.2475e-07 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.5978e-07 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.8261e-07 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 3.9708e-07 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 2.6671e-07 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 3.0581e-07 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.2640e-07 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 3.6486e-07 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 2.9128e-07 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.6965e-07 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 3.0163e-07 - binary_accuracy: 1.0000 - val_loss: 0.1099 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.3620e-07 - binary_accuracy: 1.0000 - val_loss: 0.1064 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 2.4384e-07 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.3464e-07 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.3803e-07 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.9006e-07 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 8.5944e-08 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.6208e-07 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 8.6912e-08 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 8.3275e-08 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.3611e-07 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 6.8001e-08 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 9.7351e-08 - binary_accuracy: 1.0000 - val_loss: 0.1115 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.0609e-07 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 9.2131e-08 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 8.0965e-08 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 7.4868e-08 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9894 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.7300e-07 - binary_accuracy: 1.0000 - val_loss: 0.1110 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.0642e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.8823e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.1151e-07 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 7.3033e-07 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.3183e-05 - binary_accuracy: 1.0000 - val_loss: 0.1380 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 4.0256e-04 - binary_accuracy: 0.9999 - val_loss: 0.1071 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.9404e-06 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.0457e-06 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.4452e-06 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.1990e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 8.0754e-07 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9871 - 8s/epoch - 123ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 8.0850e-07 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.9094e-06 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 5.4542e-07 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9868054986000061\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.0490694\n",
      "train attribution time:  400.7547459602356\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03829571\n",
      "validation attribution time:  40.31587076187134\n",
      "time:  2742.2784447669983\n",
      "----- loop 24 :  [1765]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.14740705490112\n",
      "train data delta_a time:  1333.9465794563293\n",
      "train data time:  1401.0939865112305\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.066997289657593\n",
      "validation data delta_a time:  118.9970874786377\n",
      "validation data time:  126.06408476829529\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 2.5393e-04 - binary_accuracy: 0.9999 - val_loss: 0.1067 - val_binary_accuracy: 0.9872 - 18s/epoch - 283ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 2.7121e-05 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 4.4134e-06 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.4456e-05 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 3.8332e-06 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.2631e-06 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.9572e-06 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 8.3729e-07 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 4.0616e-06 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 9.5948e-07 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.5628e-06 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.1618e-06 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.5069e-06 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 5.3295e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 2.9146e-06 - binary_accuracy: 1.0000 - val_loss: 0.1080 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.2586e-06 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 9.4574e-07 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 3.2471e-07 - binary_accuracy: 1.0000 - val_loss: 0.1136 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 4.4166e-06 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 2.6765e-06 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 8.0953e-07 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 8.4973e-07 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.3056e-06 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 7.7531e-07 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.2343e-06 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 3.2154e-07 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 4.1212e-07 - binary_accuracy: 1.0000 - val_loss: 0.1246 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 2.4836e-07 - binary_accuracy: 1.0000 - val_loss: 0.1257 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 6.9350e-07 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 3.0601e-07 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 9.4587e-07 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 3.6599e-06 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 2.7319e-07 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 4.3602e-06 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.9198e-06 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 3.8126e-07 - binary_accuracy: 1.0000 - val_loss: 0.1210 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 3.4376e-07 - binary_accuracy: 1.0000 - val_loss: 0.1196 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.8258e-07 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 3.0630e-07 - binary_accuracy: 1.0000 - val_loss: 0.1226 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.5313e-07 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.9367e-07 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 4.8178e-07 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 4.3822e-06 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.0085e-07 - binary_accuracy: 1.0000 - val_loss: 0.1220 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.1594e-06 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.6248e-07 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9879 - 8s/epoch - 127ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.0203e-07 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 3.3138e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.5196e-07 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.8883e-07 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.3262e-07 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.0323e-07 - binary_accuracy: 1.0000 - val_loss: 0.1258 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.2428e-05 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 4.1945e-05 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 3.3765e-06 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.1766e-06 - binary_accuracy: 1.0000 - val_loss: 0.1210 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 2.6534e-06 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 2.7195e-04 - binary_accuracy: 0.9999 - val_loss: 0.1211 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.6388e-05 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.7302e-05 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.0087e-06 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.8939e-06 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.4600e-06 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.3165e-06 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.0143e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.3948e-06 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 9.1348e-07 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 6.9208e-07 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 3.5742e-06 - binary_accuracy: 1.0000 - val_loss: 0.1164 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 7.0119e-07 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.4125e-06 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9876 - 8s/epoch - 123ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.3431e-06 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 9.2542e-07 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 7.5030e-07 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.8274e-06 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 6.9768e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 4.7285e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 6.6240e-07 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 4.0113e-07 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 5.5557e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.9979e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.9657e-07 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 6.6714e-07 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 2.6415e-07 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.0230e-07 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 3.8035e-07 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 3.2021e-07 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 3.7790e-07 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 4.9647e-07 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 2.1556e-07 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.4818e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.2202e-07 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.4449e-07 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 3.6643e-07 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.5380e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.2423e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.6788e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 2.2717e-07 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.4359e-07 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 3.4505e-07 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9880554676055908\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049147226\n",
      "train attribution time:  400.66601848602295\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03812571\n",
      "validation attribution time:  40.267380237579346\n",
      "time:  2744.608717918396\n",
      "----- loop 25 :  [1765]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.6416277885437\n",
      "train data delta_a time:  1325.0831818580627\n",
      "train data time:  1392.7248096466064\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.707310914993286\n",
      "validation data delta_a time:  120.15891528129578\n",
      "validation data time:  126.86622619628906\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 6.3836e-04 - binary_accuracy: 0.9999 - val_loss: 0.1162 - val_binary_accuracy: 0.9881 - 18s/epoch - 285ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 5.7407e-05 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.0404e-05 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.4652e-05 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.3126e-06 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 4.1580e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 5.3407e-06 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.0803e-06 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 1.2487e-05 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 5.9343e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.7836e-06 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.5880e-06 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9882 - 8s/epoch - 123ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 9.8853e-07 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.2760e-06 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 5.7822e-07 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 8.2884e-07 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 9.0558e-07 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.3277e-06 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 4.4587e-07 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.4588e-06 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9885 - 8s/epoch - 123ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 4.0400e-07 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.3148e-06 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 6.8298e-07 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 5.4186e-07 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9883 - 8s/epoch - 123ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 4.8345e-07 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.6077e-04 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 2.9874e-06 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 3.5642e-05 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 7.0181e-05 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9874 - 8s/epoch - 123ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 2.3290e-06 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.5623e-05 - binary_accuracy: 1.0000 - val_loss: 0.1218 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.0681e-06 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9876 - 8s/epoch - 123ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.1421e-06 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 4.3552e-07 - binary_accuracy: 1.0000 - val_loss: 0.1196 - val_binary_accuracy: 0.9879 - 8s/epoch - 123ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.7297e-06 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 9.6596e-07 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 6.9914e-07 - binary_accuracy: 1.0000 - val_loss: 0.1211 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 5.0012e-07 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.3976e-06 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 4.8609e-07 - binary_accuracy: 1.0000 - val_loss: 0.1218 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 3.2100e-07 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.0051e-06 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 8.1810e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.7949e-07 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 7.3718e-07 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 3.5221e-07 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.1657e-06 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 5.8075e-06 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.3166e-06 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 7.6128e-07 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.2816e-06 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.2075e-06 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.1951e-06 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.9606e-06 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.1102e-06 - binary_accuracy: 1.0000 - val_loss: 0.1204 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.6037e-06 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 5.7975e-07 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 9.3366e-07 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9876 - 8s/epoch - 123ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 4.1571e-07 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9881 - 8s/epoch - 123ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 2.6176e-07 - binary_accuracy: 1.0000 - val_loss: 0.1245 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 9.2778e-07 - binary_accuracy: 1.0000 - val_loss: 0.1210 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 3.0957e-07 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9879 - 8s/epoch - 123ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 4.7521e-07 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.1732e-07 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.3818e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9878 - 8s/epoch - 123ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 2.0528e-07 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 3.5410e-07 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9879 - 8s/epoch - 123ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 5.3310e-07 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.5990e-07 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.9429e-07 - binary_accuracy: 1.0000 - val_loss: 0.1248 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.5617e-07 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.3490e-07 - binary_accuracy: 1.0000 - val_loss: 0.1211 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 8.9652e-08 - binary_accuracy: 1.0000 - val_loss: 0.1238 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.1694e-07 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.2699e-07 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 0.9881 - 8s/epoch - 123ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 2.5473e-07 - binary_accuracy: 1.0000 - val_loss: 0.1228 - val_binary_accuracy: 0.9883 - 8s/epoch - 123ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.1017e-07 - binary_accuracy: 1.0000 - val_loss: 0.1254 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 9.0387e-08 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 2.6978e-07 - binary_accuracy: 1.0000 - val_loss: 0.1233 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 8.0574e-07 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 3.3853e-07 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.3681e-07 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9882 - 8s/epoch - 123ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 2.2475e-07 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.1137e-07 - binary_accuracy: 1.0000 - val_loss: 0.1265 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.6404e-07 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9885 - 8s/epoch - 123ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 3.6197e-07 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 6.6272e-08 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9878 - 8s/epoch - 135ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 7.8261e-08 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 7.9136e-08 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.1096e-07 - binary_accuracy: 1.0000 - val_loss: 0.1226 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.0959e-07 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 8.5187e-08 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 8.5272e-08 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 8.8463e-08 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.2763e-07 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 7.9928e-08 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.3367e-07 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.3864e-07 - binary_accuracy: 1.0000 - val_loss: 0.1212 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 8.3332e-08 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 5.2161e-08 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9879 - 8s/epoch - 123ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9879167079925537\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04915975\n",
      "train attribution time:  404.0006003379822\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03809771\n",
      "validation attribution time:  40.47397232055664\n",
      "time:  2744.427060365677\n",
      "----- loop 26 :  [1717]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.06478977203369\n",
      "train data delta_a time:  1328.9203445911407\n",
      "train data time:  1396.9851343631744\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.333155155181885\n",
      "validation data delta_a time:  121.28757834434509\n",
      "validation data time:  127.62073349952698\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 3.4702e-04 - binary_accuracy: 0.9999 - val_loss: 0.1117 - val_binary_accuracy: 0.9894 - 18s/epoch - 286ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 1.1839e-04 - binary_accuracy: 0.9999 - val_loss: 0.1075 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.2626e-05 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.9266e-06 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.6619e-05 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 7.9638e-06 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 2.8529e-05 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 5.3003e-06 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 4.0619e-05 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.3011e-04 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 2.7607e-05 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9894 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.6114e-05 - binary_accuracy: 1.0000 - val_loss: 0.1091 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 3.0346e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 5.0843e-06 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 9.3770e-06 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 4.3190e-06 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 6.9895e-06 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 7.1161e-05 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 8.1082e-06 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 2.2219e-06 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 9.0114e-06 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.1805e-06 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.2733e-05 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9896 - 8s/epoch - 123ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 5.2356e-07 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.1780e-06 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 8.9499e-07 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.9795e-07 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.0427e-06 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 4.0869e-07 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.2013e-06 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 3.6319e-07 - binary_accuracy: 1.0000 - val_loss: 0.1207 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 9.3075e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.6472e-06 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.6738e-07 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 3.7829e-07 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9903 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 5.1892e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.0103e-06 - binary_accuracy: 1.0000 - val_loss: 0.1146 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.7588e-07 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 2.2560e-07 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 3.4427e-07 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 8.7345e-07 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.2881e-06 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9903 - 8s/epoch - 122ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 6.5955e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 8.0367e-07 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 3.7618e-07 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 3.0488e-07 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 7.9217e-06 - binary_accuracy: 1.0000 - val_loss: 0.1249 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.2540e-06 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 6.9998e-07 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.1982e-06 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 4.7195e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9901 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.0855e-07 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 3.5811e-07 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.8471e-07 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.0738e-07 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 4.7903e-07 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 2.6532e-07 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.5649e-07 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.5372e-07 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 2.6879e-07 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 9.8866e-08 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.1048e-05 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.2086e-05 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 9.1775e-07 - binary_accuracy: 1.0000 - val_loss: 0.1311 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.0286e-06 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.9718e-06 - binary_accuracy: 1.0000 - val_loss: 0.1256 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 5.6332e-07 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.4411e-07 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.4752e-07 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 4.6892e-07 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.5575e-07 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.3820e-07 - binary_accuracy: 1.0000 - val_loss: 0.1233 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.3571e-07 - binary_accuracy: 1.0000 - val_loss: 0.1255 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.8887e-07 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 2.7600e-07 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.0510e-07 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 3.6157e-07 - binary_accuracy: 1.0000 - val_loss: 0.1249 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.3916e-07 - binary_accuracy: 1.0000 - val_loss: 0.1240 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.4887e-07 - binary_accuracy: 1.0000 - val_loss: 0.1240 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 4.9961e-07 - binary_accuracy: 1.0000 - val_loss: 0.1234 - val_binary_accuracy: 0.9889 - 8s/epoch - 123ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 2.6458e-07 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.3872e-07 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.7422e-07 - binary_accuracy: 1.0000 - val_loss: 0.1234 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 3.2294e-07 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 1.2112e-07 - binary_accuracy: 1.0000 - val_loss: 0.1218 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 7.4351e-08 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 5.7161e-08 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.7772e-07 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 7.2488e-08 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.2229e-07 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 6.4666e-08 - binary_accuracy: 1.0000 - val_loss: 0.1263 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 4.9402e-08 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.2030e-07 - binary_accuracy: 1.0000 - val_loss: 0.1212 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.1404e-07 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 5.0784e-08 - binary_accuracy: 1.0000 - val_loss: 0.1268 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 4.4253e-07 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 3.4375e-07 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.2893e-07 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.1358e-07 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 2.0164e-07 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9888889193534851\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049167506\n",
      "train attribution time:  401.22143030166626\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03829835\n",
      "validation attribution time:  40.266764879226685\n",
      "time:  2743.294227361679\n",
      "----- loop 27 :  [1741]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.71455430984497\n",
      "train data delta_a time:  1328.390596628189\n",
      "train data time:  1396.105150938034\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.177825927734375\n",
      "validation data delta_a time:  120.48364472389221\n",
      "validation data time:  127.66147065162659\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 3.8914e-04 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9893 - 18s/epoch - 282ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 1.1636e-04 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 4.3855e-06 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 3.0124e-06 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 6.8262e-06 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.4590e-06 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 3.4118e-06 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 6.6850e-06 - binary_accuracy: 1.0000 - val_loss: 0.1281 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 8.3078e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9903 - 8s/epoch - 122ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.6260e-06 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9904 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.8821e-06 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9903 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 4.0625e-07 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 3.3029e-06 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 9.6523e-07 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9904 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.3834e-06 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 7.6246e-07 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.6280e-06 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 7.6344e-07 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 2.4059e-06 - binary_accuracy: 1.0000 - val_loss: 0.1220 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 8.1070e-07 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9901 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 5.2558e-07 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.9405e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9907 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 2.8623e-07 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9901 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.0716e-07 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9906 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 3.7596e-07 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9892 - 8s/epoch - 123ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.2993e-07 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 2.1077e-07 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.0406e-07 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9900 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 5.9548e-07 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9899 - 8s/epoch - 125ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 2.0321e-05 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 3.2548e-06 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 3.2443e-07 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 9.5242e-07 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.1996e-06 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 4.2465e-07 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 3.0294e-07 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9893 - 8s/epoch - 123ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 3.7978e-07 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9894 - 8s/epoch - 123ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.9693e-06 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 7.7401e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 9.3517e-07 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 2.8531e-07 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.3335e-07 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 2.3241e-07 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.0497e-06 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 5.8865e-07 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.1830e-07 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 6.2938e-07 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.1011e-07 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.4655e-07 - binary_accuracy: 1.0000 - val_loss: 0.1097 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.5400e-07 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 8.1918e-08 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.6671e-06 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.3616e-07 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.5023e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9904 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.0545e-07 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.0695e-07 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.4913e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.4454e-07 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 4.2017e-08 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 9.1547e-08 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.8157e-07 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9903 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.6066e-07 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 7.8128e-08 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9893 - 8s/epoch - 119ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 9.8560e-08 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.1499e-06 - binary_accuracy: 1.0000 - val_loss: 0.1210 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 8.7361e-07 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 9.7036e-08 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.2694e-07 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.3413e-07 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.9609e-07 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.3758e-07 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 4.9581e-08 - binary_accuracy: 1.0000 - val_loss: 0.1095 - val_binary_accuracy: 0.9901 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.7167e-07 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 3.9384e-08 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 7.2284e-08 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 6.9917e-08 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 4.2992e-08 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9907 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 8.9292e-08 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 3.9133e-08 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 0.9901 - 8s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 3.8953e-08 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 5.2050e-08 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 5.4088e-08 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 4.9679e-08 - binary_accuracy: 1.0000 - val_loss: 0.1204 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 5.4221e-08 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 6.0908e-08 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9899 - 8s/epoch - 123ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 5.9094e-08 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9903 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 4.3483e-08 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 5.2596e-08 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 3.3451e-08 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9901 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 2.4245e-08 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9897 - 8s/epoch - 123ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 4.3494e-08 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9903 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.2408e-08 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9903 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 3.8746e-08 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 6.7172e-07 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9904 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 5.2473e-06 - binary_accuracy: 1.0000 - val_loss: 0.1095 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.5046e-06 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 5.6513e-07 - binary_accuracy: 1.0000 - val_loss: 0.1136 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 4.6001e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 7.9228e-07 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 2.2916e-07 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9894444942474365\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04913129\n",
      "train attribution time:  401.60073351860046\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.04068375\n",
      "validation attribution time:  39.423895597457886\n",
      "time:  2740.4300220012665\n",
      "----- loop 28 :  [1745]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.28735303878784\n",
      "train data delta_a time:  1323.8444156646729\n",
      "train data time:  1392.1317687034607\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.956736326217651\n",
      "validation data delta_a time:  119.34546542167664\n",
      "validation data time:  126.30220174789429\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 22s - loss: 0.0014 - binary_accuracy: 0.9997 - val_loss: 0.1167 - val_binary_accuracy: 0.9885 - 22s/epoch - 341ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 2.5956e-04 - binary_accuracy: 0.9999 - val_loss: 0.1156 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 2.7017e-04 - binary_accuracy: 0.9999 - val_loss: 0.1170 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 5.6609e-05 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 6.9097e-05 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 5.6669e-05 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.8759e-05 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.1322e-05 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9881 - 8s/epoch - 123ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 1.7020e-05 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9882 - 8s/epoch - 123ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.1019e-05 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.8587e-05 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 6.9386e-06 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 5.5722e-06 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 7.6619e-06 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 2.0649e-05 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.2008e-05 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9879 - 8s/epoch - 124ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 8.7888e-06 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 7.1291e-06 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 9.4970e-06 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.3408e-05 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 2.2589e-06 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.5752e-05 - binary_accuracy: 1.0000 - val_loss: 0.1319 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.3833e-05 - binary_accuracy: 1.0000 - val_loss: 0.1298 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.5530e-05 - binary_accuracy: 1.0000 - val_loss: 0.1289 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.0804e-05 - binary_accuracy: 1.0000 - val_loss: 0.1255 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.0527e-06 - binary_accuracy: 1.0000 - val_loss: 0.1270 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.4037e-06 - binary_accuracy: 1.0000 - val_loss: 0.1280 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.5119e-06 - binary_accuracy: 1.0000 - val_loss: 0.1289 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 6.6982e-05 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.0402e-05 - binary_accuracy: 1.0000 - val_loss: 0.1227 - val_binary_accuracy: 0.9882 - 8s/epoch - 123ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.7957e-05 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.9597e-04 - binary_accuracy: 0.9999 - val_loss: 0.1106 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.1038e-04 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.0142e-05 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 4.0596e-06 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 2.6770e-05 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9879 - 8s/epoch - 123ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 9.4604e-06 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 9.1076e-06 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 7.7348e-06 - binary_accuracy: 1.0000 - val_loss: 0.1211 - val_binary_accuracy: 0.9879 - 8s/epoch - 123ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 2.1274e-06 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.9740e-06 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9881 - 8s/epoch - 123ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 5.1225e-06 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.5600e-06 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9886 - 8s/epoch - 123ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.2838e-06 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.9475e-06 - binary_accuracy: 1.0000 - val_loss: 0.1227 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 9.1143e-07 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.5090e-06 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.4492e-06 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 2.2081e-06 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 9.1940e-06 - binary_accuracy: 1.0000 - val_loss: 0.1293 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 5.7000e-06 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.2292e-06 - binary_accuracy: 1.0000 - val_loss: 0.1255 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 3.5147e-06 - binary_accuracy: 1.0000 - val_loss: 0.1240 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.6853e-06 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9885 - 8s/epoch - 123ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.9626e-06 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 7.0580e-06 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9878 - 8s/epoch - 123ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 9.1693e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.7667e-06 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 9.1275e-07 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 7.1305e-07 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 4.4246e-07 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 3.1281e-05 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.5817e-06 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.5486e-05 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.1708e-05 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 3.0106e-06 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.4277e-06 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 2.5128e-06 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 8.0768e-07 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 7.5271e-07 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 5.0520e-07 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.4711e-06 - binary_accuracy: 1.0000 - val_loss: 0.1223 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 7.7533e-07 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 2.2318e-06 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.9634e-06 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.4871e-06 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 5.2118e-07 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 3.3814e-07 - binary_accuracy: 1.0000 - val_loss: 0.1281 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 5.0482e-07 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 2.7321e-07 - binary_accuracy: 1.0000 - val_loss: 0.1267 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 3.5904e-07 - binary_accuracy: 1.0000 - val_loss: 0.1285 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.1507e-06 - binary_accuracy: 1.0000 - val_loss: 0.1275 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 3.3042e-07 - binary_accuracy: 1.0000 - val_loss: 0.1258 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 6.5092e-07 - binary_accuracy: 1.0000 - val_loss: 0.1269 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.2292e-07 - binary_accuracy: 1.0000 - val_loss: 0.1223 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 5.0136e-06 - binary_accuracy: 1.0000 - val_loss: 0.1263 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.8737e-06 - binary_accuracy: 1.0000 - val_loss: 0.1245 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.8800e-06 - binary_accuracy: 1.0000 - val_loss: 0.1282 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.0155e-06 - binary_accuracy: 1.0000 - val_loss: 0.1298 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.1134e-05 - binary_accuracy: 1.0000 - val_loss: 0.1505 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.0056e-06 - binary_accuracy: 1.0000 - val_loss: 0.1384 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.0161e-06 - binary_accuracy: 1.0000 - val_loss: 0.1389 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.3709e-06 - binary_accuracy: 1.0000 - val_loss: 0.1336 - val_binary_accuracy: 0.9885 - 8s/epoch - 123ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.9873e-07 - binary_accuracy: 1.0000 - val_loss: 0.1380 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 9.3731e-07 - binary_accuracy: 1.0000 - val_loss: 0.1364 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.2461e-06 - binary_accuracy: 1.0000 - val_loss: 0.1234 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.2556e-06 - binary_accuracy: 1.0000 - val_loss: 0.1282 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 7.4130e-07 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 4.8346e-07 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 4.0308e-07 - binary_accuracy: 1.0000 - val_loss: 0.1271 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9888888597488403\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049085606\n",
      "train attribution time:  402.8460283279419\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038065586\n",
      "validation attribution time:  39.50137662887573\n",
      "time:  2742.612419128418\n",
      "----- loop 29 :  [1748]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.27250289916992\n",
      "train data delta_a time:  1276.338998556137\n",
      "train data time:  1342.611501455307\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.816786050796509\n",
      "validation data delta_a time:  120.88340497016907\n",
      "validation data time:  127.70019102096558\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0013 - binary_accuracy: 0.9998 - val_loss: 0.1127 - val_binary_accuracy: 0.9883 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 4.1056e-04 - binary_accuracy: 0.9999 - val_loss: 0.1226 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.7083e-04 - binary_accuracy: 0.9999 - val_loss: 0.1195 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.2366e-04 - binary_accuracy: 0.9999 - val_loss: 0.1324 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.7500e-04 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 3.2140e-05 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 8.5002e-05 - binary_accuracy: 0.9999 - val_loss: 0.1250 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 6.9954e-05 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 9.1100e-05 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 3.2001e-05 - binary_accuracy: 1.0000 - val_loss: 0.1287 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.7330e-05 - binary_accuracy: 1.0000 - val_loss: 0.1246 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.0618e-05 - binary_accuracy: 1.0000 - val_loss: 0.1286 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.5621e-05 - binary_accuracy: 1.0000 - val_loss: 0.1223 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.3837e-05 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 9.5394e-06 - binary_accuracy: 1.0000 - val_loss: 0.1207 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 5.6175e-06 - binary_accuracy: 1.0000 - val_loss: 0.1234 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 5.7989e-06 - binary_accuracy: 1.0000 - val_loss: 0.1291 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 2.8344e-06 - binary_accuracy: 1.0000 - val_loss: 0.1262 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 9.3876e-06 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 2.4485e-05 - binary_accuracy: 1.0000 - val_loss: 0.1327 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 6.2295e-06 - binary_accuracy: 1.0000 - val_loss: 0.1276 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.1247e-05 - binary_accuracy: 1.0000 - val_loss: 0.1266 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.0677e-04 - binary_accuracy: 1.0000 - val_loss: 0.1327 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 3.5212e-05 - binary_accuracy: 1.0000 - val_loss: 0.1349 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.3919e-05 - binary_accuracy: 1.0000 - val_loss: 0.1333 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.0606e-05 - binary_accuracy: 1.0000 - val_loss: 0.1196 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 2.1446e-05 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.2359e-05 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 3.4161e-06 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.7071e-05 - binary_accuracy: 1.0000 - val_loss: 0.1220 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.4665e-05 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.3438e-05 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.7140e-06 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.0778e-04 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 3.2970e-05 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 5.1369e-05 - binary_accuracy: 1.0000 - val_loss: 0.1248 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 3.8905e-06 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.4945e-05 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.0641e-05 - binary_accuracy: 1.0000 - val_loss: 0.1249 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 3.1707e-06 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 3.6063e-06 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 5.8818e-06 - binary_accuracy: 1.0000 - val_loss: 0.1211 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 3.1155e-06 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.6642e-06 - binary_accuracy: 1.0000 - val_loss: 0.1258 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.4796e-06 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 1.2028e-06 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.2586e-06 - binary_accuracy: 1.0000 - val_loss: 0.1227 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 6.8692e-06 - binary_accuracy: 1.0000 - val_loss: 0.1278 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 2.8125e-06 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 7.8524e-07 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.4488e-06 - binary_accuracy: 1.0000 - val_loss: 0.1256 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 7.5895e-06 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.4141e-05 - binary_accuracy: 1.0000 - val_loss: 0.1273 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.1773e-05 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.5057e-06 - binary_accuracy: 1.0000 - val_loss: 0.1262 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.4491e-06 - binary_accuracy: 1.0000 - val_loss: 0.1257 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.0444e-06 - binary_accuracy: 1.0000 - val_loss: 0.1257 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.3454e-06 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.1847e-06 - binary_accuracy: 1.0000 - val_loss: 0.1220 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.5984e-06 - binary_accuracy: 1.0000 - val_loss: 0.1254 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.1168e-06 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 8.8337e-07 - binary_accuracy: 1.0000 - val_loss: 0.1284 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.7121e-05 - binary_accuracy: 1.0000 - val_loss: 0.1196 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.4776e-06 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.2485e-06 - binary_accuracy: 1.0000 - val_loss: 0.1246 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.9279e-06 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.1521e-06 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 7.2475e-06 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.9220e-06 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 2.4673e-06 - binary_accuracy: 1.0000 - val_loss: 0.1275 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 2.8877e-06 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 3.1118e-06 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.0127e-06 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 5.9872e-07 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.0675e-06 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.4426e-06 - binary_accuracy: 1.0000 - val_loss: 0.1263 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 6.9823e-07 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.1625e-06 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 3.6151e-07 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 5.6846e-07 - binary_accuracy: 1.0000 - val_loss: 0.1228 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 5.6303e-07 - binary_accuracy: 1.0000 - val_loss: 0.1233 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 5.8232e-05 - binary_accuracy: 1.0000 - val_loss: 0.1348 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 9.4816e-07 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 5.6880e-07 - binary_accuracy: 1.0000 - val_loss: 0.1345 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 9.7603e-05 - binary_accuracy: 1.0000 - val_loss: 0.1372 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 5.6264e-05 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.2823e-04 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9878 - 8s/epoch - 123ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.4988e-05 - binary_accuracy: 1.0000 - val_loss: 0.1286 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 7.0184e-06 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.1669e-06 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.8719e-06 - binary_accuracy: 1.0000 - val_loss: 0.1276 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 8.8622e-07 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 9.5095e-07 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.0548e-06 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 4.2863e-06 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 8.1535e-07 - binary_accuracy: 1.0000 - val_loss: 0.1284 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.0077e-06 - binary_accuracy: 1.0000 - val_loss: 0.1302 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 5.4405e-07 - binary_accuracy: 1.0000 - val_loss: 0.1267 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 3.4334e-07 - binary_accuracy: 1.0000 - val_loss: 0.1276 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 4.7189e-07 - binary_accuracy: 1.0000 - val_loss: 0.1252 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9880555868148804\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049162958\n",
      "train attribution time:  399.29439210891724\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038132746\n",
      "validation attribution time:  39.953646421432495\n",
      "time:  2684.4240374565125\n",
      "----- loop 30 :  [1750]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.98841667175293\n",
      "train data delta_a time:  1335.439189195633\n",
      "train data time:  1403.4276058673859\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.5666985511779785\n",
      "validation data delta_a time:  122.01238656044006\n",
      "validation data time:  128.57908511161804\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 3.2589e-04 - binary_accuracy: 0.9999 - val_loss: 0.1104 - val_binary_accuracy: 0.9890 - 18s/epoch - 284ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 5.8732e-05 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9894 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 7.2311e-06 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.9442e-06 - binary_accuracy: 1.0000 - val_loss: 0.1146 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.1749e-06 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 9.5016e-06 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 5.3915e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 4.3835e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.0021e-06 - binary_accuracy: 1.0000 - val_loss: 0.1057 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.3349e-06 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.7245e-06 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.5289e-06 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.0336e-06 - binary_accuracy: 1.0000 - val_loss: 0.1210 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.2932e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.5406e-06 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 6.3172e-07 - binary_accuracy: 1.0000 - val_loss: 0.1172 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 3.3449e-07 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 2.6922e-06 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 5.0555e-06 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 2.0075e-05 - binary_accuracy: 1.0000 - val_loss: 0.1210 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 2.6293e-06 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 4.6373e-06 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 9.4887e-07 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.2648e-06 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.4682e-06 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.0640e-06 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 5.7724e-07 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 8.0313e-07 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 9.3822e-07 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.2261e-07 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9899 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.0943e-06 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 8.6329e-07 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 9.9076e-07 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.8871e-07 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 6.8756e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 4.1161e-07 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 3.1848e-07 - binary_accuracy: 1.0000 - val_loss: 0.1089 - val_binary_accuracy: 0.9894 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.9931e-06 - binary_accuracy: 1.0000 - val_loss: 0.1064 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.0744e-06 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.0444e-06 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9904 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 7.8958e-07 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 8.6779e-07 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 9.4087e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9901 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 8.3636e-07 - binary_accuracy: 1.0000 - val_loss: 0.1065 - val_binary_accuracy: 0.9903 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 2.9019e-07 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 1.5947e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.6028e-07 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9896 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.7557e-07 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.4297e-07 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9899 - 8s/epoch - 123ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 5.3341e-07 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.4360e-07 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 4.2873e-07 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 7.0410e-07 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.9399e-07 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.9920e-07 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.4647e-07 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.6753e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9901 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 7.5185e-08 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.4052e-07 - binary_accuracy: 1.0000 - val_loss: 0.1091 - val_binary_accuracy: 0.9903 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.6684e-07 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 3.9809e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 8.3796e-08 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.1388e-07 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.0431e-07 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.4094e-07 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 5.3795e-08 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 5.7828e-08 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.0455e-07 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.1412e-07 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.0001e-07 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 2.1011e-07 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.6846e-07 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 7.4328e-08 - binary_accuracy: 1.0000 - val_loss: 0.1106 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.8039e-07 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.0536e-07 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 8.0792e-08 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.1790e-07 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9903 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.4608e-07 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9899 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.4415e-07 - binary_accuracy: 1.0000 - val_loss: 0.1175 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 6.5565e-08 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.0352e-06 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 2.1255e-07 - binary_accuracy: 1.0000 - val_loss: 0.1211 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 2.0072e-07 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.1570e-07 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9899 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.0007e-07 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 8.4037e-08 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 6.1149e-08 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 7.1029e-08 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 9.6496e-08 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.7314e-07 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 7.8065e-08 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 5.7860e-08 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 4.1196e-08 - binary_accuracy: 1.0000 - val_loss: 0.1175 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 5.3733e-08 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 4.0357e-08 - binary_accuracy: 1.0000 - val_loss: 0.1218 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 8.1264e-08 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 5.4456e-08 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 2.7425e-08 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 9.2303e-08 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.5540e-07 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9898611307144165\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.048965972\n",
      "train attribution time:  401.12089562416077\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038322736\n",
      "validation attribution time:  40.20415210723877\n",
      "time:  2748.173860311508\n",
      "----- loop 31 :  [1752]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.22002601623535\n",
      "train data delta_a time:  1333.2240147590637\n",
      "train data time:  1399.444040775299\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.816642999649048\n",
      "validation data delta_a time:  119.70333456993103\n",
      "validation data time:  126.51997756958008\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 9.1561e-04 - binary_accuracy: 0.9998 - val_loss: 0.1193 - val_binary_accuracy: 0.9892 - 18s/epoch - 285ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 3.4520e-04 - binary_accuracy: 0.9999 - val_loss: 0.1235 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.4142e-04 - binary_accuracy: 0.9999 - val_loss: 0.1216 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 7.1052e-05 - binary_accuracy: 0.9999 - val_loss: 0.1208 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 3.8456e-05 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 3.9716e-05 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 8.4861e-05 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.2627e-05 - binary_accuracy: 1.0000 - val_loss: 0.1175 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 1.0060e-05 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 8.3665e-05 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.2976e-05 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.0999e-05 - binary_accuracy: 1.0000 - val_loss: 0.1196 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 6.2142e-05 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 2.0410e-05 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.4809e-04 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 4.9145e-06 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.1810e-05 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.4888e-06 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 9.2359e-06 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.1570e-06 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 6.1043e-05 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.1099e-05 - binary_accuracy: 1.0000 - val_loss: 0.1080 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 4.8478e-06 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.9942e-05 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 3.9849e-06 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.6414e-05 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.9891e-06 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.5094e-05 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 6.1245e-06 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.7696e-06 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 6.6308e-06 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9893 - 8s/epoch - 123ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 9.9105e-06 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 4.8257e-06 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9899 - 8s/epoch - 123ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 2.3594e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 9.0599e-07 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 3.4646e-07 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9894 - 8s/epoch - 123ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 6.7798e-07 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.8322e-06 - binary_accuracy: 1.0000 - val_loss: 0.1061 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 7.6043e-07 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 2.0504e-06 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.6040e-06 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 7.1783e-07 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 6.4062e-07 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 6.5678e-06 - binary_accuracy: 1.0000 - val_loss: 0.1284 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 3.9185e-05 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.8085e-05 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.2436e-06 - binary_accuracy: 1.0000 - val_loss: 0.1196 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 8.2856e-06 - binary_accuracy: 1.0000 - val_loss: 0.1290 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.5990e-06 - binary_accuracy: 1.0000 - val_loss: 0.1263 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.2362e-06 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 3.2803e-06 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 5.9504e-07 - binary_accuracy: 1.0000 - val_loss: 0.1277 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 8.4360e-07 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 5.8467e-07 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 8.3025e-07 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 8.3589e-07 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9890 - 8s/epoch - 123ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 6.3341e-07 - binary_accuracy: 1.0000 - val_loss: 0.1304 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.7672e-06 - binary_accuracy: 1.0000 - val_loss: 0.1306 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.9163e-07 - binary_accuracy: 1.0000 - val_loss: 0.1246 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.0783e-04 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.8397e-05 - binary_accuracy: 1.0000 - val_loss: 0.1401 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 8.0415e-06 - binary_accuracy: 1.0000 - val_loss: 0.1278 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.2467e-05 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.1298e-06 - binary_accuracy: 1.0000 - val_loss: 0.1282 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 5.1759e-06 - binary_accuracy: 1.0000 - val_loss: 0.1313 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 7.5488e-06 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 3.7989e-06 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.5473e-06 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 4.3075e-06 - binary_accuracy: 1.0000 - val_loss: 0.1234 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 8.2209e-06 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.1750e-05 - binary_accuracy: 1.0000 - val_loss: 0.1226 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.4161e-04 - binary_accuracy: 0.9999 - val_loss: 0.1169 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.2187e-04 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 7.8505e-06 - binary_accuracy: 1.0000 - val_loss: 0.1033 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 8.7071e-05 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 4.9254e-06 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 2.4889e-06 - binary_accuracy: 1.0000 - val_loss: 0.1202 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.7856e-05 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 3.8956e-06 - binary_accuracy: 1.0000 - val_loss: 0.1220 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 5.2745e-05 - binary_accuracy: 1.0000 - val_loss: 0.1063 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.4657e-04 - binary_accuracy: 0.9999 - val_loss: 0.1144 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.8282e-06 - binary_accuracy: 1.0000 - val_loss: 0.1081 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 4.0729e-06 - binary_accuracy: 1.0000 - val_loss: 0.1061 - val_binary_accuracy: 0.9897 - 8s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 2.7602e-06 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.7656e-06 - binary_accuracy: 1.0000 - val_loss: 0.1066 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 4.3623e-06 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 9.4404e-07 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.3904e-06 - binary_accuracy: 1.0000 - val_loss: 0.1081 - val_binary_accuracy: 0.9894 - 8s/epoch - 123ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.8337e-06 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.5759e-06 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 4.1613e-07 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.2665e-07 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.0558e-06 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 3.4446e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 4.9205e-07 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 9.1913e-07 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 7.0541e-07 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.4149e-06 - binary_accuracy: 1.0000 - val_loss: 0.1107 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 5.2193e-06 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 4.1565e-07 - binary_accuracy: 1.0000 - val_loss: 0.1245 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.989166796207428\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049057703\n",
      "train attribution time:  402.81277418136597\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03804476\n",
      "validation attribution time:  39.610873222351074\n",
      "time:  2745.1128034591675\n",
      "----- loop 32 :  [1752]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.62381720542908\n",
      "train data delta_a time:  1380.3554019927979\n",
      "train data time:  1447.9948179721832\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.144749879837036\n",
      "validation data delta_a time:  121.70436549186707\n",
      "validation data time:  127.8491153717041\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 19s - loss: 6.5002e-04 - binary_accuracy: 0.9999 - val_loss: 0.1085 - val_binary_accuracy: 0.9890 - 19s/epoch - 299ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 1.6362e-04 - binary_accuracy: 0.9999 - val_loss: 0.1069 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.7204e-05 - binary_accuracy: 1.0000 - val_loss: 0.1071 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.3617e-06 - binary_accuracy: 1.0000 - val_loss: 0.1071 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 6.4578e-06 - binary_accuracy: 1.0000 - val_loss: 0.1043 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.0453e-05 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.0846e-05 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 2.7907e-06 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 7.0099e-06 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.9899e-06 - binary_accuracy: 1.0000 - val_loss: 0.1109 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 4.0363e-06 - binary_accuracy: 1.0000 - val_loss: 0.1034 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.5375e-06 - binary_accuracy: 1.0000 - val_loss: 0.1068 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 4.2014e-07 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 6.4706e-07 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 8.0218e-06 - binary_accuracy: 1.0000 - val_loss: 0.1061 - val_binary_accuracy: 0.9882 - 8s/epoch - 123ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 5.2227e-05 - binary_accuracy: 1.0000 - val_loss: 0.0972 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 8.7223e-06 - binary_accuracy: 1.0000 - val_loss: 0.0958 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 3.0226e-05 - binary_accuracy: 1.0000 - val_loss: 0.0996 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.0350e-04 - binary_accuracy: 1.0000 - val_loss: 0.0983 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.6926e-06 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.0370e-06 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.0131e-06 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.6143e-06 - binary_accuracy: 1.0000 - val_loss: 0.1005 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.0852e-06 - binary_accuracy: 1.0000 - val_loss: 0.1004 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 6.9265e-07 - binary_accuracy: 1.0000 - val_loss: 0.0952 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 8.2353e-07 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 8.0136e-07 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 5.8637e-07 - binary_accuracy: 1.0000 - val_loss: 0.0993 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 5.0555e-07 - binary_accuracy: 1.0000 - val_loss: 0.0999 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.6979e-06 - binary_accuracy: 1.0000 - val_loss: 0.1001 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 3.6527e-07 - binary_accuracy: 1.0000 - val_loss: 0.0939 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 5.6375e-07 - binary_accuracy: 1.0000 - val_loss: 0.0995 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 7.1993e-06 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 3.5956e-05 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 4.2863e-06 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.9320e-05 - binary_accuracy: 1.0000 - val_loss: 0.1034 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 7.6832e-07 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.0675e-06 - binary_accuracy: 1.0000 - val_loss: 0.1066 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 3.1483e-06 - binary_accuracy: 1.0000 - val_loss: 0.1059 - val_binary_accuracy: 0.9900 - 8s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.0874e-06 - binary_accuracy: 1.0000 - val_loss: 0.1062 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 5.6415e-07 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 6.2537e-07 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9903 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.1212e-05 - binary_accuracy: 1.0000 - val_loss: 0.0993 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.6340e-06 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.3155e-06 - binary_accuracy: 1.0000 - val_loss: 0.0995 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 3.5503e-07 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.9994e-06 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 8.1396e-07 - binary_accuracy: 1.0000 - val_loss: 0.1010 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 5.6531e-07 - binary_accuracy: 1.0000 - val_loss: 0.1081 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 3.1097e-07 - binary_accuracy: 1.0000 - val_loss: 0.1004 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 6.1322e-07 - binary_accuracy: 1.0000 - val_loss: 0.1017 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 6.7382e-06 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 3.1727e-07 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.4659e-07 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.8470e-06 - binary_accuracy: 1.0000 - val_loss: 0.0978 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 2.7367e-07 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.7582e-07 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9894 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 9.0261e-07 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 6.9719e-07 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 3.0677e-07 - binary_accuracy: 1.0000 - val_loss: 0.1007 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.6723e-07 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.5005e-07 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 2.5200e-07 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.2926e-07 - binary_accuracy: 1.0000 - val_loss: 0.1072 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 3.5060e-07 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.9111e-07 - binary_accuracy: 1.0000 - val_loss: 0.1011 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 2.2355e-07 - binary_accuracy: 1.0000 - val_loss: 0.1050 - val_binary_accuracy: 0.9894 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.6642e-07 - binary_accuracy: 1.0000 - val_loss: 0.0986 - val_binary_accuracy: 0.9896 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 9.2693e-08 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 2.3112e-07 - binary_accuracy: 1.0000 - val_loss: 0.1045 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 5.8235e-07 - binary_accuracy: 1.0000 - val_loss: 0.1050 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 5.2066e-07 - binary_accuracy: 1.0000 - val_loss: 0.1024 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.1870e-06 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 4.8044e-07 - binary_accuracy: 1.0000 - val_loss: 0.1052 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.5368e-07 - binary_accuracy: 1.0000 - val_loss: 0.1052 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 7.3670e-08 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.1406e-06 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.8952e-06 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 2.9895e-07 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.5229e-07 - binary_accuracy: 1.0000 - val_loss: 0.1047 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 5.4934e-07 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.4526e-07 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 7.3754e-07 - binary_accuracy: 1.0000 - val_loss: 0.0990 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.6310e-07 - binary_accuracy: 1.0000 - val_loss: 0.1014 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.2935e-07 - binary_accuracy: 1.0000 - val_loss: 0.1002 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.9901e-07 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.0012e-07 - binary_accuracy: 1.0000 - val_loss: 0.1044 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.3735e-07 - binary_accuracy: 1.0000 - val_loss: 0.0997 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 4.9564e-07 - binary_accuracy: 1.0000 - val_loss: 0.1057 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 3.2101e-07 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9887 - 8s/epoch - 119ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 9.0259e-08 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.6372e-07 - binary_accuracy: 1.0000 - val_loss: 0.1018 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.5554e-07 - binary_accuracy: 1.0000 - val_loss: 0.1062 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 6.3902e-08 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.5249e-07 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 7.7162e-08 - binary_accuracy: 1.0000 - val_loss: 0.1049 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 6.7821e-08 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.0983e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 8.0299e-08 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.1465e-07 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9898610711097717\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049034018\n",
      "train attribution time:  403.25717210769653\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038212903\n",
      "validation attribution time:  40.78075170516968\n",
      "time:  2793.9227633476257\n",
      "----- loop 33 :  [1661]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.45351958274841\n",
      "train data delta_a time:  1338.5933873653412\n",
      "train data time:  1406.0469069480896\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.520599842071533\n",
      "validation data delta_a time:  122.7764961719513\n",
      "validation data time:  129.29709601402283\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 25s - loss: 0.0016 - binary_accuracy: 0.9997 - val_loss: 0.1231 - val_binary_accuracy: 0.9883 - 25s/epoch - 396ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 7.3791e-04 - binary_accuracy: 0.9999 - val_loss: 0.1237 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 4.4475e-04 - binary_accuracy: 0.9999 - val_loss: 0.1252 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.5369e-04 - binary_accuracy: 0.9999 - val_loss: 0.1179 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.7004e-04 - binary_accuracy: 0.9999 - val_loss: 0.1179 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.7655e-04 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.2823e-05 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.2220e-04 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.6637e-05 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 4.9797e-05 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.2347e-05 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 9.9338e-05 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 2.5897e-05 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.1884e-05 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.3748e-05 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 4.3642e-06 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 6.7326e-06 - binary_accuracy: 1.0000 - val_loss: 0.1252 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 9.2791e-06 - binary_accuracy: 1.0000 - val_loss: 0.1293 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.6560e-06 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.2626e-06 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.5722e-06 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.2950e-06 - binary_accuracy: 1.0000 - val_loss: 0.1245 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 2.0110e-06 - binary_accuracy: 1.0000 - val_loss: 0.1259 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.8340e-06 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 3.3408e-06 - binary_accuracy: 1.0000 - val_loss: 0.1264 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.0321e-06 - binary_accuracy: 1.0000 - val_loss: 0.1302 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 5.4276e-05 - binary_accuracy: 1.0000 - val_loss: 0.1247 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 6.8758e-05 - binary_accuracy: 1.0000 - val_loss: 0.1318 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 9.5295e-05 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.0819e-06 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.5509e-06 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 5.6656e-06 - binary_accuracy: 1.0000 - val_loss: 0.1233 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.1987e-06 - binary_accuracy: 1.0000 - val_loss: 0.1275 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.1240e-06 - binary_accuracy: 1.0000 - val_loss: 0.1277 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 5.0320e-06 - binary_accuracy: 1.0000 - val_loss: 0.1249 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 2.5957e-06 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 2.2471e-05 - binary_accuracy: 1.0000 - val_loss: 0.1308 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.9252e-06 - binary_accuracy: 1.0000 - val_loss: 0.1285 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 5.0671e-07 - binary_accuracy: 1.0000 - val_loss: 0.1302 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 3.3388e-06 - binary_accuracy: 1.0000 - val_loss: 0.1256 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 9.5244e-07 - binary_accuracy: 1.0000 - val_loss: 0.1254 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.8232e-06 - binary_accuracy: 1.0000 - val_loss: 0.1315 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 8.3865e-07 - binary_accuracy: 1.0000 - val_loss: 0.1341 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 9.5424e-07 - binary_accuracy: 1.0000 - val_loss: 0.1307 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 5.5239e-07 - binary_accuracy: 1.0000 - val_loss: 0.1305 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.5959e-06 - binary_accuracy: 1.0000 - val_loss: 0.1283 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.4590e-06 - binary_accuracy: 1.0000 - val_loss: 0.1305 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 8.9715e-07 - binary_accuracy: 1.0000 - val_loss: 0.1309 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.0353e-06 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 5.7919e-06 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 7.6129e-07 - binary_accuracy: 1.0000 - val_loss: 0.1273 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.4341e-06 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 3.5860e-06 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.0533e-04 - binary_accuracy: 1.0000 - val_loss: 0.1099 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.3667e-04 - binary_accuracy: 0.9999 - val_loss: 0.1226 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.3168e-04 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 3.8980e-06 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 2.8176e-06 - binary_accuracy: 1.0000 - val_loss: 0.1146 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 7.9090e-07 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.3653e-06 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 3.2649e-06 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.1018e-06 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 2.1932e-06 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 4.4887e-06 - binary_accuracy: 1.0000 - val_loss: 0.1136 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 3.9571e-07 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 3.4890e-07 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.0942e-06 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 7.3903e-07 - binary_accuracy: 1.0000 - val_loss: 0.1106 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 8.5051e-06 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 8.6703e-07 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 7.6762e-07 - binary_accuracy: 1.0000 - val_loss: 0.1202 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 7.2238e-07 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.1391e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 7.1443e-07 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 3.0471e-07 - binary_accuracy: 1.0000 - val_loss: 0.1248 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 7.5323e-07 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 3.6319e-07 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.8806e-07 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.7054e-07 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 4.3993e-07 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 8.3984e-07 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 2.4017e-07 - binary_accuracy: 1.0000 - val_loss: 0.1218 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 6.6884e-07 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 3.5262e-06 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.0466e-07 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 4.5114e-06 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 4.7959e-06 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 6.5404e-07 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 7.7844e-07 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 5.2855e-06 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.7714e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 2.3535e-07 - binary_accuracy: 1.0000 - val_loss: 0.1279 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.1307e-06 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 3.3918e-07 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.6110e-06 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.4896e-06 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 5.9971e-07 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 6.9705e-07 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 2.7285e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 8.1079e-07 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.987500011920929\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04898279\n",
      "train attribution time:  403.0688099861145\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038349397\n",
      "validation attribution time:  40.60866332054138\n",
      "time:  2757.483251810074\n",
      "----- loop 34 :  [1661]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.06231904029846\n",
      "train data delta_a time:  1342.9698600769043\n",
      "train data time:  1409.0321791172028\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.081716299057007\n",
      "validation data delta_a time:  121.68388247489929\n",
      "validation data time:  128.7655987739563\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 19s - loss: 0.0015 - binary_accuracy: 0.9998 - val_loss: 0.1295 - val_binary_accuracy: 0.9875 - 19s/epoch - 294ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 4.0958e-04 - binary_accuracy: 0.9999 - val_loss: 0.1335 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.9965e-04 - binary_accuracy: 0.9999 - val_loss: 0.1321 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 5.5546e-06 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 6.5708e-05 - binary_accuracy: 1.0000 - val_loss: 0.1371 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.0323e-05 - binary_accuracy: 1.0000 - val_loss: 0.1383 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 2.8610e-05 - binary_accuracy: 1.0000 - val_loss: 0.1467 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 8.8564e-06 - binary_accuracy: 1.0000 - val_loss: 0.1418 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 6.3515e-06 - binary_accuracy: 1.0000 - val_loss: 0.1401 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 8.1026e-06 - binary_accuracy: 1.0000 - val_loss: 0.1350 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.4661e-05 - binary_accuracy: 1.0000 - val_loss: 0.1480 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.0481e-05 - binary_accuracy: 1.0000 - val_loss: 0.1427 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.2495e-06 - binary_accuracy: 1.0000 - val_loss: 0.1381 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 3.5201e-06 - binary_accuracy: 1.0000 - val_loss: 0.1454 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 3.3847e-06 - binary_accuracy: 1.0000 - val_loss: 0.1459 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 5.0042e-05 - binary_accuracy: 1.0000 - val_loss: 0.1476 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 4.9252e-06 - binary_accuracy: 1.0000 - val_loss: 0.1435 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 3.4593e-06 - binary_accuracy: 1.0000 - val_loss: 0.1441 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.6432e-06 - binary_accuracy: 1.0000 - val_loss: 0.1498 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.8151e-06 - binary_accuracy: 1.0000 - val_loss: 0.1434 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 5.5516e-05 - binary_accuracy: 1.0000 - val_loss: 0.1329 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.9276e-06 - binary_accuracy: 1.0000 - val_loss: 0.1372 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 2.0919e-06 - binary_accuracy: 1.0000 - val_loss: 0.1332 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 3.8878e-06 - binary_accuracy: 1.0000 - val_loss: 0.1417 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.6103e-06 - binary_accuracy: 1.0000 - val_loss: 0.1315 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.4552e-06 - binary_accuracy: 1.0000 - val_loss: 0.1359 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.0572e-06 - binary_accuracy: 1.0000 - val_loss: 0.1387 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.1871e-05 - binary_accuracy: 1.0000 - val_loss: 0.1312 - val_binary_accuracy: 0.9867 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 1.1064e-04 - binary_accuracy: 1.0000 - val_loss: 0.1379 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 5.9284e-05 - binary_accuracy: 1.0000 - val_loss: 0.1285 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.9778e-06 - binary_accuracy: 1.0000 - val_loss: 0.1297 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.0176e-06 - binary_accuracy: 1.0000 - val_loss: 0.1256 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.7302e-06 - binary_accuracy: 1.0000 - val_loss: 0.1317 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 6.9268e-07 - binary_accuracy: 1.0000 - val_loss: 0.1258 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 7.4645e-06 - binary_accuracy: 1.0000 - val_loss: 0.1329 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.5276e-06 - binary_accuracy: 1.0000 - val_loss: 0.1344 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.6940e-06 - binary_accuracy: 1.0000 - val_loss: 0.1346 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 5.1667e-05 - binary_accuracy: 1.0000 - val_loss: 0.1349 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 3.1867e-06 - binary_accuracy: 1.0000 - val_loss: 0.1388 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 6.7912e-07 - binary_accuracy: 1.0000 - val_loss: 0.1317 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.2587e-06 - binary_accuracy: 1.0000 - val_loss: 0.1373 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 2.8566e-07 - binary_accuracy: 1.0000 - val_loss: 0.1362 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 2.3939e-06 - binary_accuracy: 1.0000 - val_loss: 0.1302 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 8.0505e-07 - binary_accuracy: 1.0000 - val_loss: 0.1267 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 5.1086e-07 - binary_accuracy: 1.0000 - val_loss: 0.1382 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 9.3586e-07 - binary_accuracy: 1.0000 - val_loss: 0.1352 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.1048e-06 - binary_accuracy: 1.0000 - val_loss: 0.1288 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 6.0245e-07 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.0285e-07 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 6.4687e-07 - binary_accuracy: 1.0000 - val_loss: 0.1300 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.8707e-07 - binary_accuracy: 1.0000 - val_loss: 0.1324 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 5.6107e-07 - binary_accuracy: 1.0000 - val_loss: 0.1305 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 4.0271e-07 - binary_accuracy: 1.0000 - val_loss: 0.1298 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.4325e-07 - binary_accuracy: 1.0000 - val_loss: 0.1336 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.0828e-07 - binary_accuracy: 1.0000 - val_loss: 0.1325 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.5107e-07 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.5290e-07 - binary_accuracy: 1.0000 - val_loss: 0.1312 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 3.1720e-07 - binary_accuracy: 1.0000 - val_loss: 0.1320 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 5.6200e-07 - binary_accuracy: 1.0000 - val_loss: 0.1286 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 3.6238e-07 - binary_accuracy: 1.0000 - val_loss: 0.1307 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.6810e-07 - binary_accuracy: 1.0000 - val_loss: 0.1325 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.8589e-06 - binary_accuracy: 1.0000 - val_loss: 0.1391 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 2.9699e-07 - binary_accuracy: 1.0000 - val_loss: 0.1346 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 9.6076e-08 - binary_accuracy: 1.0000 - val_loss: 0.1376 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.5596e-05 - binary_accuracy: 1.0000 - val_loss: 0.1330 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 8.9499e-06 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 2.9059e-07 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.9561e-07 - binary_accuracy: 1.0000 - val_loss: 0.1258 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.6627e-06 - binary_accuracy: 1.0000 - val_loss: 0.1240 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 5.7536e-07 - binary_accuracy: 1.0000 - val_loss: 0.1282 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 3.7662e-07 - binary_accuracy: 1.0000 - val_loss: 0.1269 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 3.5954e-07 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.7159e-07 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 9.4255e-07 - binary_accuracy: 1.0000 - val_loss: 0.1286 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.1009e-06 - binary_accuracy: 1.0000 - val_loss: 0.1307 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 3.8092e-07 - binary_accuracy: 1.0000 - val_loss: 0.1255 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 8.8068e-07 - binary_accuracy: 1.0000 - val_loss: 0.1281 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.0229e-07 - binary_accuracy: 1.0000 - val_loss: 0.1299 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.7654e-07 - binary_accuracy: 1.0000 - val_loss: 0.1318 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.2015e-07 - binary_accuracy: 1.0000 - val_loss: 0.1289 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 2.8318e-07 - binary_accuracy: 1.0000 - val_loss: 0.1287 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.7191e-07 - binary_accuracy: 1.0000 - val_loss: 0.1252 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 8.5110e-08 - binary_accuracy: 1.0000 - val_loss: 0.1300 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.7336e-07 - binary_accuracy: 1.0000 - val_loss: 0.1323 - val_binary_accuracy: 0.9868 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 1.8618e-07 - binary_accuracy: 1.0000 - val_loss: 0.1299 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.7739e-07 - binary_accuracy: 1.0000 - val_loss: 0.1272 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 9.0772e-07 - binary_accuracy: 1.0000 - val_loss: 0.1320 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 8.3857e-07 - binary_accuracy: 1.0000 - val_loss: 0.1337 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 4.1759e-07 - binary_accuracy: 1.0000 - val_loss: 0.1329 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 3.1799e-07 - binary_accuracy: 1.0000 - val_loss: 0.1310 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 3.5655e-07 - binary_accuracy: 1.0000 - val_loss: 0.1299 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 2.4567e-07 - binary_accuracy: 1.0000 - val_loss: 0.1328 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.0473e-07 - binary_accuracy: 1.0000 - val_loss: 0.1340 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 6.8467e-05 - binary_accuracy: 1.0000 - val_loss: 0.1535 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.5016e-04 - binary_accuracy: 0.9999 - val_loss: 0.1308 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 5.1484e-05 - binary_accuracy: 1.0000 - val_loss: 0.1376 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 5.3535e-06 - binary_accuracy: 1.0000 - val_loss: 0.1421 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 3.5057e-06 - binary_accuracy: 1.0000 - val_loss: 0.1459 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.9753e-06 - binary_accuracy: 1.0000 - val_loss: 0.1427 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 3.2612e-06 - binary_accuracy: 1.0000 - val_loss: 0.1374 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9865278005599976\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049213197\n",
      "train attribution time:  404.95387268066406\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.03803281\n",
      "validation attribution time:  39.07702708244324\n",
      "time:  2755.046831846237\n",
      "----- loop 35 :  [1661]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.37452960014343\n",
      "train data delta_a time:  1336.8137402534485\n",
      "train data time:  1405.188269853592\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.283324956893921\n",
      "validation data delta_a time:  127.43532180786133\n",
      "validation data time:  134.71864676475525\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 19s - loss: 6.0358e-04 - binary_accuracy: 0.9999 - val_loss: 0.1074 - val_binary_accuracy: 0.9882 - 19s/epoch - 294ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 1.6700e-05 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 8.1843e-06 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.2010e-06 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 3.5654e-06 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.2906e-05 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.3207e-05 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.3039e-06 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 5.4785e-07 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.0226e-06 - binary_accuracy: 1.0000 - val_loss: 0.1100 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.6006e-06 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 7.9557e-07 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.2202e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.0069e-06 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 3.8393e-07 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 5.6845e-07 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 3.0019e-07 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 6.4282e-07 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 3.9637e-07 - binary_accuracy: 1.0000 - val_loss: 0.1091 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 3.0429e-07 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.6596e-06 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 5.0014e-07 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 4.0857e-07 - binary_accuracy: 1.0000 - val_loss: 0.1145 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.3022e-07 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 5.5727e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 4.0017e-07 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 4.5224e-07 - binary_accuracy: 1.0000 - val_loss: 0.1091 - val_binary_accuracy: 0.9882 - 8s/epoch - 119ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.9686e-07 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 6.5076e-07 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 5.9449e-07 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.2578e-06 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.2858e-07 - binary_accuracy: 1.0000 - val_loss: 0.1086 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.7456e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.5554e-07 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.9027e-07 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 4.0014e-07 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 8.9614e-08 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.5837e-07 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.0616e-07 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.3684e-07 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 2.3134e-07 - binary_accuracy: 1.0000 - val_loss: 0.1086 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 2.0308e-07 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.3736e-07 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.6217e-07 - binary_accuracy: 1.0000 - val_loss: 0.1135 - val_binary_accuracy: 0.9874 - 8s/epoch - 119ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.3009e-07 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.9468e-06 - binary_accuracy: 1.0000 - val_loss: 0.1066 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 5.8808e-07 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 3.5104e-07 - binary_accuracy: 1.0000 - val_loss: 0.1066 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.2443e-07 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.5721e-07 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9874 - 8s/epoch - 119ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 8.0901e-08 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 9.3848e-08 - binary_accuracy: 1.0000 - val_loss: 0.1089 - val_binary_accuracy: 0.9875 - 8s/epoch - 119ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.9815e-07 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.0310e-07 - binary_accuracy: 1.0000 - val_loss: 0.1042 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.3442e-07 - binary_accuracy: 1.0000 - val_loss: 0.1077 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.2189e-07 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 2.6551e-07 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.4745e-07 - binary_accuracy: 1.0000 - val_loss: 0.1072 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.1609e-07 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.4467e-07 - binary_accuracy: 1.0000 - val_loss: 0.1095 - val_binary_accuracy: 0.9874 - 8s/epoch - 119ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.4564e-07 - binary_accuracy: 1.0000 - val_loss: 0.1095 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.3749e-07 - binary_accuracy: 1.0000 - val_loss: 0.1077 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 6.8044e-08 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.9916e-06 - binary_accuracy: 1.0000 - val_loss: 0.1047 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.0336e-06 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 5.7923e-07 - binary_accuracy: 1.0000 - val_loss: 0.1034 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 4.0250e-07 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.2550e-07 - binary_accuracy: 1.0000 - val_loss: 0.1053 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 3.3069e-07 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 5.4672e-08 - binary_accuracy: 1.0000 - val_loss: 0.1067 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 9.6014e-08 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.4758e-07 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 5.2093e-08 - binary_accuracy: 1.0000 - val_loss: 0.1091 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 4.1869e-07 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.6975e-07 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.7718e-07 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9881 - 8s/epoch - 119ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 7.5026e-08 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.1218e-07 - binary_accuracy: 1.0000 - val_loss: 0.1043 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.4279e-07 - binary_accuracy: 1.0000 - val_loss: 0.1052 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 5.8250e-08 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 8.3434e-08 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 7.7921e-08 - binary_accuracy: 1.0000 - val_loss: 0.1084 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.0752e-07 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 4.0857e-08 - binary_accuracy: 1.0000 - val_loss: 0.1061 - val_binary_accuracy: 0.9885 - 8s/epoch - 119ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 8.0402e-08 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.1577e-07 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 6.1022e-08 - binary_accuracy: 1.0000 - val_loss: 0.1054 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 6.2528e-08 - binary_accuracy: 1.0000 - val_loss: 0.1077 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 4.3625e-08 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 4.3689e-08 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.8912e-08 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.1693e-07 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.8327e-07 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 4.9005e-07 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 4.4694e-07 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.0982e-07 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 2.7621e-07 - binary_accuracy: 1.0000 - val_loss: 0.1115 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 5.0033e-08 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.5295e-07 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9892 - 8s/epoch - 119ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 8.5420e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9883334636688232\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049137756\n",
      "train attribution time:  404.39064288139343\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038694903\n",
      "validation attribution time:  40.84293723106384\n",
      "time:  2756.8449997901917\n",
      "----- loop 36 :  [1655]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.17204427719116\n",
      "train data delta_a time:  1350.991601228714\n",
      "train data time:  1419.1636455059052\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.024272203445435\n",
      "validation data delta_a time:  119.55325698852539\n",
      "validation data time:  126.57752919197083\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 1.8902e-04 - binary_accuracy: 0.9999 - val_loss: 0.1169 - val_binary_accuracy: 0.9882 - 18s/epoch - 289ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 6.4217e-05 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 9.6481e-05 - binary_accuracy: 1.0000 - val_loss: 0.1073 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 8.7062e-06 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 4.7575e-06 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.0179e-06 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.3597e-06 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 7.8763e-07 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 8.8114e-06 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 2.1543e-05 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 2.2428e-06 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.6882e-06 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.8428e-06 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 8.1267e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 3.1310e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9881 - 8s/epoch - 119ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 3.0321e-07 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 7.0484e-07 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.5007e-06 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 3.3151e-06 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.9718e-07 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.9606e-06 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.0163e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 2.4562e-07 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 9.5730e-06 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 9.0090e-07 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.7262e-06 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 4.8747e-06 - binary_accuracy: 1.0000 - val_loss: 0.1215 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 4.1699e-07 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 6.9653e-07 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 7.5980e-07 - binary_accuracy: 1.0000 - val_loss: 0.1249 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 7.2828e-07 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.9922e-07 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.3768e-07 - binary_accuracy: 1.0000 - val_loss: 0.1207 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 3.4081e-07 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.0944e-07 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 2.1551e-07 - binary_accuracy: 1.0000 - val_loss: 0.1223 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.2420e-07 - binary_accuracy: 1.0000 - val_loss: 0.1254 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.6715e-07 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 9.3114e-07 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.1330e-06 - binary_accuracy: 1.0000 - val_loss: 0.1340 - val_binary_accuracy: 0.9862 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 7.4819e-08 - binary_accuracy: 1.0000 - val_loss: 0.1262 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 9.6645e-08 - binary_accuracy: 1.0000 - val_loss: 0.1274 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 7.9381e-08 - binary_accuracy: 1.0000 - val_loss: 0.1233 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.3130e-07 - binary_accuracy: 1.0000 - val_loss: 0.1255 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 7.5557e-08 - binary_accuracy: 1.0000 - val_loss: 0.1226 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.6070e-07 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 6.1650e-08 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 8.9627e-08 - binary_accuracy: 1.0000 - val_loss: 0.1259 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.8867e-07 - binary_accuracy: 1.0000 - val_loss: 0.1289 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 3.5140e-07 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 6.8071e-08 - binary_accuracy: 1.0000 - val_loss: 0.1196 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.6543e-07 - binary_accuracy: 1.0000 - val_loss: 0.1274 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.6071e-07 - binary_accuracy: 1.0000 - val_loss: 0.1277 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 3.0026e-07 - binary_accuracy: 1.0000 - val_loss: 0.1277 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 8.9872e-08 - binary_accuracy: 1.0000 - val_loss: 0.1355 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 9.3643e-08 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 3.1131e-07 - binary_accuracy: 1.0000 - val_loss: 0.1226 - val_binary_accuracy: 0.9878 - 8s/epoch - 119ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 2.7638e-07 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 7.4864e-08 - binary_accuracy: 1.0000 - val_loss: 0.1245 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 8.8637e-08 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 5.8257e-08 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 4.7206e-08 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 3.9130e-08 - binary_accuracy: 1.0000 - val_loss: 0.1220 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.2627e-07 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.6651e-07 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 4.6668e-08 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 5.5086e-08 - binary_accuracy: 1.0000 - val_loss: 0.1212 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 8.0519e-08 - binary_accuracy: 1.0000 - val_loss: 0.1245 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 5.1343e-08 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 3.1287e-08 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 6.3331e-08 - binary_accuracy: 1.0000 - val_loss: 0.1206 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.2672e-07 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 4.8944e-08 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 4.8598e-08 - binary_accuracy: 1.0000 - val_loss: 0.1238 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 5.4948e-08 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 2.9445e-08 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 7.8884e-07 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 3.2097e-08 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 5.8555e-07 - binary_accuracy: 1.0000 - val_loss: 0.1278 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 2.2751e-07 - binary_accuracy: 1.0000 - val_loss: 0.1265 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 4.5874e-08 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.7350e-08 - binary_accuracy: 1.0000 - val_loss: 0.1246 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.1939e-07 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 4.0010e-08 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 5.6775e-08 - binary_accuracy: 1.0000 - val_loss: 0.1253 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 3.5637e-08 - binary_accuracy: 1.0000 - val_loss: 0.1313 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 4.2777e-08 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 2.8334e-08 - binary_accuracy: 1.0000 - val_loss: 0.1249 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.4915e-08 - binary_accuracy: 1.0000 - val_loss: 0.1263 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 8.6306e-08 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9879 - 8s/epoch - 119ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 7.9433e-08 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 5.4559e-08 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 3.6367e-08 - binary_accuracy: 1.0000 - val_loss: 0.1254 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 4.0047e-08 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 2.6776e-08 - binary_accuracy: 1.0000 - val_loss: 0.1301 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 9.4992e-08 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 9.2968e-08 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.7390e-07 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 5.3054e-08 - binary_accuracy: 1.0000 - val_loss: 0.1324 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.5794e-08 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9880555868148804\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049147148\n",
      "train attribution time:  403.5567970275879\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037951753\n",
      "validation attribution time:  40.43124580383301\n",
      "time:  2761.4917542934418\n",
      "----- loop 37 :  [1718]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.03930234909058\n",
      "train data delta_a time:  1343.463790178299\n",
      "train data time:  1411.5030925273895\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.101071834564209\n",
      "validation data delta_a time:  121.11299276351929\n",
      "validation data time:  128.2140645980835\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 19s - loss: 1.0145e-04 - binary_accuracy: 0.9999 - val_loss: 0.1321 - val_binary_accuracy: 0.9883 - 19s/epoch - 294ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 7s - loss: 4.8447e-06 - binary_accuracy: 1.0000 - val_loss: 0.1285 - val_binary_accuracy: 0.9879 - 7s/epoch - 119ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.2571e-05 - binary_accuracy: 1.0000 - val_loss: 0.1273 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.5664e-05 - binary_accuracy: 1.0000 - val_loss: 0.1270 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.1244e-06 - binary_accuracy: 1.0000 - val_loss: 0.1305 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.1232e-06 - binary_accuracy: 1.0000 - val_loss: 0.1279 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 8.3546e-06 - binary_accuracy: 1.0000 - val_loss: 0.1278 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.7235e-05 - binary_accuracy: 1.0000 - val_loss: 0.1238 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 6.0452e-06 - binary_accuracy: 1.0000 - val_loss: 0.1259 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 2.4535e-06 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.0659e-06 - binary_accuracy: 1.0000 - val_loss: 0.1253 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.2175e-06 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.8216e-06 - binary_accuracy: 1.0000 - val_loss: 0.1181 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 6.5081e-07 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 3.6307e-06 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 2.2058e-07 - binary_accuracy: 1.0000 - val_loss: 0.1265 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 2.6172e-07 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.9009e-07 - binary_accuracy: 1.0000 - val_loss: 0.1263 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.1650e-07 - binary_accuracy: 1.0000 - val_loss: 0.1255 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 8.6657e-08 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 7s - loss: 5.1665e-07 - binary_accuracy: 1.0000 - val_loss: 0.1270 - val_binary_accuracy: 0.9879 - 7s/epoch - 119ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.7676e-06 - binary_accuracy: 1.0000 - val_loss: 0.1300 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 8.8306e-07 - binary_accuracy: 1.0000 - val_loss: 0.1279 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.3440e-07 - binary_accuracy: 1.0000 - val_loss: 0.1270 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.5681e-07 - binary_accuracy: 1.0000 - val_loss: 0.1276 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 3.7225e-07 - binary_accuracy: 1.0000 - val_loss: 0.1267 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 5.5343e-08 - binary_accuracy: 1.0000 - val_loss: 0.1263 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 6.0988e-07 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 8.3145e-08 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 2.7792e-07 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 6.2747e-06 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.7226e-04 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.3975e-04 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 6.2188e-06 - binary_accuracy: 1.0000 - val_loss: 0.1304 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.9552e-06 - binary_accuracy: 1.0000 - val_loss: 0.1307 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 3.1145e-06 - binary_accuracy: 1.0000 - val_loss: 0.1316 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 9.0841e-07 - binary_accuracy: 1.0000 - val_loss: 0.1284 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 5.9893e-07 - binary_accuracy: 1.0000 - val_loss: 0.1341 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 8.9708e-08 - binary_accuracy: 1.0000 - val_loss: 0.1279 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.7439e-07 - binary_accuracy: 1.0000 - val_loss: 0.1253 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.1308e-06 - binary_accuracy: 1.0000 - val_loss: 0.1348 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 2.9743e-07 - binary_accuracy: 1.0000 - val_loss: 0.1303 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 2.8560e-07 - binary_accuracy: 1.0000 - val_loss: 0.1277 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.5263e-07 - binary_accuracy: 1.0000 - val_loss: 0.1313 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.5516e-07 - binary_accuracy: 1.0000 - val_loss: 0.1290 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 6.6981e-07 - binary_accuracy: 1.0000 - val_loss: 0.1304 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 2.2874e-07 - binary_accuracy: 1.0000 - val_loss: 0.1298 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.4610e-07 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 4.4396e-05 - binary_accuracy: 1.0000 - val_loss: 0.1136 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 3.6819e-05 - binary_accuracy: 1.0000 - val_loss: 0.1164 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.3849e-05 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 5.6275e-06 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9882 - 8s/epoch - 119ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.1463e-07 - binary_accuracy: 1.0000 - val_loss: 0.1297 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.0952e-06 - binary_accuracy: 1.0000 - val_loss: 0.1274 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.6755e-07 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.0451e-07 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.4063e-06 - binary_accuracy: 1.0000 - val_loss: 0.1267 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.8375e-07 - binary_accuracy: 1.0000 - val_loss: 0.1227 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.3586e-07 - binary_accuracy: 1.0000 - val_loss: 0.1253 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 3.4325e-07 - binary_accuracy: 1.0000 - val_loss: 0.1261 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.8145e-07 - binary_accuracy: 1.0000 - val_loss: 0.1276 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.8382e-07 - binary_accuracy: 1.0000 - val_loss: 0.1309 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 5.8165e-07 - binary_accuracy: 1.0000 - val_loss: 0.1291 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 5.1964e-08 - binary_accuracy: 1.0000 - val_loss: 0.1270 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.2397e-07 - binary_accuracy: 1.0000 - val_loss: 0.1283 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.6627e-07 - binary_accuracy: 1.0000 - val_loss: 0.1276 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 5.7104e-08 - binary_accuracy: 1.0000 - val_loss: 0.1228 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.0304e-05 - binary_accuracy: 1.0000 - val_loss: 0.1273 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 1.8020e-06 - binary_accuracy: 1.0000 - val_loss: 0.1348 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 3.3241e-07 - binary_accuracy: 1.0000 - val_loss: 0.1328 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.3301e-06 - binary_accuracy: 1.0000 - val_loss: 0.1388 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 9.4709e-07 - binary_accuracy: 1.0000 - val_loss: 0.1385 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 8.0415e-07 - binary_accuracy: 1.0000 - val_loss: 0.1347 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 2.4846e-07 - binary_accuracy: 1.0000 - val_loss: 0.1296 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 7.6407e-08 - binary_accuracy: 1.0000 - val_loss: 0.1307 - val_binary_accuracy: 0.9881 - 8s/epoch - 119ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.0048e-07 - binary_accuracy: 1.0000 - val_loss: 0.1316 - val_binary_accuracy: 0.9882 - 8s/epoch - 119ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.1627e-07 - binary_accuracy: 1.0000 - val_loss: 0.1337 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.6655e-07 - binary_accuracy: 1.0000 - val_loss: 0.1329 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 4.2045e-07 - binary_accuracy: 1.0000 - val_loss: 0.1391 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 5.0400e-08 - binary_accuracy: 1.0000 - val_loss: 0.1296 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 2.1994e-06 - binary_accuracy: 1.0000 - val_loss: 0.1360 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.4223e-07 - binary_accuracy: 1.0000 - val_loss: 0.1313 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 2.1901e-07 - binary_accuracy: 1.0000 - val_loss: 0.1386 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 8.4888e-08 - binary_accuracy: 1.0000 - val_loss: 0.1388 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 6.2647e-06 - binary_accuracy: 1.0000 - val_loss: 0.1331 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 4.4687e-06 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.8539e-05 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.1164e-04 - binary_accuracy: 1.0000 - val_loss: 0.1285 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 4.1875e-05 - binary_accuracy: 1.0000 - val_loss: 0.1370 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 8.8603e-06 - binary_accuracy: 1.0000 - val_loss: 0.1286 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 9.1380e-07 - binary_accuracy: 1.0000 - val_loss: 0.1278 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.7360e-06 - binary_accuracy: 1.0000 - val_loss: 0.1228 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.3448e-07 - binary_accuracy: 1.0000 - val_loss: 0.1296 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.7459e-07 - binary_accuracy: 1.0000 - val_loss: 0.1248 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 5.6229e-07 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.0402e-07 - binary_accuracy: 1.0000 - val_loss: 0.1254 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 2.3019e-07 - binary_accuracy: 1.0000 - val_loss: 0.1275 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.9626e-07 - binary_accuracy: 1.0000 - val_loss: 0.1254 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 3.6269e-06 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 1.8635e-07 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9873611330986023\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04906424\n",
      "train attribution time:  403.1143581867218\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.0381916\n",
      "validation attribution time:  40.62771487236023\n",
      "time:  2755.226030111313\n",
      "----- loop 38 :  [1655]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.15551376342773\n",
      "train data delta_a time:  1330.615765094757\n",
      "train data time:  1396.7712788581848\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.115051031112671\n",
      "validation data delta_a time:  121.06170153617859\n",
      "validation data time:  128.17675256729126\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0030 - binary_accuracy: 0.9995 - val_loss: 0.1188 - val_binary_accuracy: 0.9879 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 8.5034e-04 - binary_accuracy: 0.9997 - val_loss: 0.1171 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 2.3942e-04 - binary_accuracy: 0.9999 - val_loss: 0.1240 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 8.1176e-05 - binary_accuracy: 0.9999 - val_loss: 0.1205 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.0199e-04 - binary_accuracy: 0.9999 - val_loss: 0.1211 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.6144e-04 - binary_accuracy: 0.9999 - val_loss: 0.1192 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.6874e-05 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 5.4103e-05 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 4.7546e-05 - binary_accuracy: 1.0000 - val_loss: 0.1302 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 7.7234e-05 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.5370e-05 - binary_accuracy: 1.0000 - val_loss: 0.1274 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.0068e-05 - binary_accuracy: 1.0000 - val_loss: 0.1282 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 6.9660e-05 - binary_accuracy: 1.0000 - val_loss: 0.1291 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.7993e-05 - binary_accuracy: 1.0000 - val_loss: 0.1334 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 7.8277e-05 - binary_accuracy: 1.0000 - val_loss: 0.1243 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 4.0536e-05 - binary_accuracy: 1.0000 - val_loss: 0.1333 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 6.4510e-06 - binary_accuracy: 1.0000 - val_loss: 0.1321 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.1693e-05 - binary_accuracy: 1.0000 - val_loss: 0.1256 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.9589e-05 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 2.6232e-05 - binary_accuracy: 1.0000 - val_loss: 0.1328 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.5179e-04 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 1.6245e-05 - binary_accuracy: 1.0000 - val_loss: 0.1259 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 2.4429e-05 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 2.8138e-05 - binary_accuracy: 1.0000 - val_loss: 0.1199 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.2003e-05 - binary_accuracy: 1.0000 - val_loss: 0.1257 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.4333e-05 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 7.2402e-06 - binary_accuracy: 1.0000 - val_loss: 0.1302 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.3784e-05 - binary_accuracy: 1.0000 - val_loss: 0.1300 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 4.5560e-06 - binary_accuracy: 1.0000 - val_loss: 0.1287 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 5.6844e-06 - binary_accuracy: 1.0000 - val_loss: 0.1338 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 4.3773e-06 - binary_accuracy: 1.0000 - val_loss: 0.1377 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 3.4811e-06 - binary_accuracy: 1.0000 - val_loss: 0.1344 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 6.1476e-06 - binary_accuracy: 1.0000 - val_loss: 0.1308 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 5.8496e-06 - binary_accuracy: 1.0000 - val_loss: 0.1306 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.2577e-06 - binary_accuracy: 1.0000 - val_loss: 0.1345 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.3527e-06 - binary_accuracy: 1.0000 - val_loss: 0.1331 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 8.9649e-06 - binary_accuracy: 1.0000 - val_loss: 0.1327 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.3541e-06 - binary_accuracy: 1.0000 - val_loss: 0.1379 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.4413e-06 - binary_accuracy: 1.0000 - val_loss: 0.1333 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 7.2289e-06 - binary_accuracy: 1.0000 - val_loss: 0.1364 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.8520e-04 - binary_accuracy: 1.0000 - val_loss: 0.1265 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 8.3719e-06 - binary_accuracy: 1.0000 - val_loss: 0.1275 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 4.4373e-06 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 3.9827e-05 - binary_accuracy: 1.0000 - val_loss: 0.1274 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 3.5320e-05 - binary_accuracy: 1.0000 - val_loss: 0.1254 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.8352e-06 - binary_accuracy: 1.0000 - val_loss: 0.1272 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.8391e-06 - binary_accuracy: 1.0000 - val_loss: 0.1275 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.0519e-06 - binary_accuracy: 1.0000 - val_loss: 0.1310 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.4733e-05 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 5.2242e-06 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 7.6846e-06 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 8.7905e-07 - binary_accuracy: 1.0000 - val_loss: 0.1202 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 4.7455e-06 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 7.3442e-06 - binary_accuracy: 1.0000 - val_loss: 0.1276 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.5261e-06 - binary_accuracy: 1.0000 - val_loss: 0.1277 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 5.4231e-06 - binary_accuracy: 1.0000 - val_loss: 0.1257 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.9588e-06 - binary_accuracy: 1.0000 - val_loss: 0.1262 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.3043e-06 - binary_accuracy: 1.0000 - val_loss: 0.1227 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.1048e-06 - binary_accuracy: 1.0000 - val_loss: 0.1265 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 2.3075e-06 - binary_accuracy: 1.0000 - val_loss: 0.1211 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.6099e-06 - binary_accuracy: 1.0000 - val_loss: 0.1264 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.1953e-06 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.4597e-06 - binary_accuracy: 1.0000 - val_loss: 0.1247 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.3861e-06 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 4.7596e-07 - binary_accuracy: 1.0000 - val_loss: 0.1233 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 2.8433e-06 - binary_accuracy: 1.0000 - val_loss: 0.1255 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.1497e-06 - binary_accuracy: 1.0000 - val_loss: 0.1275 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.3918e-06 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 8.8987e-07 - binary_accuracy: 1.0000 - val_loss: 0.1262 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 4.0817e-07 - binary_accuracy: 1.0000 - val_loss: 0.1316 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 4.8556e-07 - binary_accuracy: 1.0000 - val_loss: 0.1267 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 1.3339e-06 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 9.9214e-07 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 4.1663e-07 - binary_accuracy: 1.0000 - val_loss: 0.1219 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 2.8669e-07 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 3.4759e-06 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 4.8497e-07 - binary_accuracy: 1.0000 - val_loss: 0.1258 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.6617e-06 - binary_accuracy: 1.0000 - val_loss: 0.1238 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 7.0619e-07 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 3.3138e-07 - binary_accuracy: 1.0000 - val_loss: 0.1252 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.1264e-06 - binary_accuracy: 1.0000 - val_loss: 0.1314 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 5.7842e-07 - binary_accuracy: 1.0000 - val_loss: 0.1281 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 2.7537e-07 - binary_accuracy: 1.0000 - val_loss: 0.1244 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 3.2917e-07 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 5.5306e-07 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 5.7145e-06 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 5.4464e-07 - binary_accuracy: 1.0000 - val_loss: 0.1321 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.3258e-06 - binary_accuracy: 1.0000 - val_loss: 0.1247 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 4.0364e-07 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 7.7979e-07 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 4.8205e-07 - binary_accuracy: 1.0000 - val_loss: 0.1284 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 2.4379e-07 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.2606e-07 - binary_accuracy: 1.0000 - val_loss: 0.1273 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.8626e-07 - binary_accuracy: 1.0000 - val_loss: 0.1242 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 2.7789e-07 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 5.0563e-07 - binary_accuracy: 1.0000 - val_loss: 0.1259 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.0451e-06 - binary_accuracy: 1.0000 - val_loss: 0.1307 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 2.4424e-07 - binary_accuracy: 1.0000 - val_loss: 0.1340 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 5.7452e-07 - binary_accuracy: 1.0000 - val_loss: 0.1329 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 9.2173e-06 - binary_accuracy: 1.0000 - val_loss: 0.1383 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9876389503479004\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049057614\n",
      "train attribution time:  400.57543420791626\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037949428\n",
      "validation attribution time:  40.703850984573364\n",
      "time:  2740.4003500938416\n",
      "----- loop 39 :  [1742]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.67250370979309\n",
      "train data delta_a time:  1329.4572219848633\n",
      "train data time:  1398.1297256946564\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.410552263259888\n",
      "validation data delta_a time:  126.19947218894958\n",
      "validation data time:  132.61002445220947\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 5.9492e-04 - binary_accuracy: 0.9999 - val_loss: 0.1211 - val_binary_accuracy: 0.9875 - 18s/epoch - 283ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 2.3473e-04 - binary_accuracy: 0.9999 - val_loss: 0.1032 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.8624e-04 - binary_accuracy: 1.0000 - val_loss: 0.1075 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.2143e-05 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.4797e-06 - binary_accuracy: 1.0000 - val_loss: 0.1006 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.1909e-05 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.1394e-05 - binary_accuracy: 1.0000 - val_loss: 0.1111 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.8882e-06 - binary_accuracy: 1.0000 - val_loss: 0.1060 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 6.7299e-06 - binary_accuracy: 1.0000 - val_loss: 0.1085 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 8.7164e-06 - binary_accuracy: 1.0000 - val_loss: 0.1058 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 2.0180e-06 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.6653e-06 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.6622e-06 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 2.6925e-06 - binary_accuracy: 1.0000 - val_loss: 0.1090 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 2.8753e-06 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 4.4198e-06 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 2.5096e-06 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.9859e-07 - binary_accuracy: 1.0000 - val_loss: 0.1075 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 2.6301e-07 - binary_accuracy: 1.0000 - val_loss: 0.1037 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 2.7155e-07 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 7.2201e-07 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 3.0362e-06 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 9.7245e-07 - binary_accuracy: 1.0000 - val_loss: 0.1056 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.7699e-05 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.2681e-04 - binary_accuracy: 0.9999 - val_loss: 0.1036 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 4.6752e-05 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 3.1002e-05 - binary_accuracy: 1.0000 - val_loss: 0.1047 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.3355e-06 - binary_accuracy: 1.0000 - val_loss: 0.1108 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 3.8240e-07 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.8292e-07 - binary_accuracy: 1.0000 - val_loss: 0.1078 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 6.0459e-07 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.1929e-06 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.4727e-06 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 5.1360e-07 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.6653e-07 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.7455e-07 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 5.6067e-07 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 6.1831e-07 - binary_accuracy: 1.0000 - val_loss: 0.1095 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 3.9519e-07 - binary_accuracy: 1.0000 - val_loss: 0.1098 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 2.0159e-07 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 6.1028e-07 - binary_accuracy: 1.0000 - val_loss: 0.1114 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 1.4065e-07 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 8.7988e-08 - binary_accuracy: 1.0000 - val_loss: 0.1115 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.2827e-07 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 5.0492e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.6418e-07 - binary_accuracy: 1.0000 - val_loss: 0.1136 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 7.8076e-07 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 6.0026e-07 - binary_accuracy: 1.0000 - val_loss: 0.1141 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 4.3490e-07 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.6806e-07 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.1362e-07 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 2.6197e-07 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.0316e-07 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.2539e-07 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 3.6508e-07 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.1166e-07 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.3213e-07 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.6449e-07 - binary_accuracy: 1.0000 - val_loss: 0.1125 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 1.8163e-06 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.2826e-07 - binary_accuracy: 1.0000 - val_loss: 0.1096 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.8942e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 4.3465e-07 - binary_accuracy: 1.0000 - val_loss: 0.1155 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 8.6788e-08 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 5.8217e-08 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.8250e-07 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 2.1212e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 9.5484e-08 - binary_accuracy: 1.0000 - val_loss: 0.1156 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.0595e-07 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 5.2568e-07 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 2.8629e-08 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 8.7478e-08 - binary_accuracy: 1.0000 - val_loss: 0.1130 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 5.4112e-08 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 8.7509e-08 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.1625e-07 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.5321e-07 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 3.0186e-07 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.0063e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 9.6158e-08 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 9.4459e-08 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 4.1895e-06 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 6.4226e-06 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 4.3582e-06 - binary_accuracy: 1.0000 - val_loss: 0.1150 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 6.8320e-08 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 7.0823e-08 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 1.1843e-07 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 7.0581e-08 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 6.6566e-08 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.1106e-07 - binary_accuracy: 1.0000 - val_loss: 0.1212 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.6116e-07 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 8.9191e-08 - binary_accuracy: 1.0000 - val_loss: 0.1147 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 7.0471e-08 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.1843e-07 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 3.1047e-07 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 3.3407e-08 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 7s - loss: 5.6439e-08 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9881 - 7s/epoch - 119ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 8.4431e-08 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.2369e-07 - binary_accuracy: 1.0000 - val_loss: 0.1228 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 8.6272e-08 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.0120e-07 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 7.8629e-08 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9886111617088318\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04911458\n",
      "train attribution time:  406.1811406612396\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038344804\n",
      "validation attribution time:  40.97085356712341\n",
      "time:  2748.344931125641\n",
      "----- loop 40 :  [1745]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.5147533416748\n",
      "train data delta_a time:  1311.6586501598358\n",
      "train data time:  1378.1734035015106\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.395488977432251\n",
      "validation data delta_a time:  118.91963243484497\n",
      "validation data time:  125.31512141227722\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0015 - binary_accuracy: 0.9996 - val_loss: 0.1083 - val_binary_accuracy: 0.9897 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 6.9498e-04 - binary_accuracy: 0.9998 - val_loss: 0.1114 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.9111e-04 - binary_accuracy: 0.9999 - val_loss: 0.1062 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.7421e-04 - binary_accuracy: 0.9998 - val_loss: 0.1137 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.4801e-04 - binary_accuracy: 0.9999 - val_loss: 0.1171 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.1924e-04 - binary_accuracy: 0.9999 - val_loss: 0.1189 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 2.4233e-05 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.6561e-05 - binary_accuracy: 1.0000 - val_loss: 0.1110 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.5771e-05 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 4.0031e-05 - binary_accuracy: 1.0000 - val_loss: 0.1134 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 5.6366e-05 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 2.9224e-05 - binary_accuracy: 1.0000 - val_loss: 0.1120 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 3.5952e-05 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.9296e-04 - binary_accuracy: 0.9999 - val_loss: 0.1105 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 4.3235e-05 - binary_accuracy: 1.0000 - val_loss: 0.1052 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.0089e-04 - binary_accuracy: 1.0000 - val_loss: 0.1041 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 5.5993e-06 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 8.6709e-06 - binary_accuracy: 1.0000 - val_loss: 0.1059 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 9.0183e-05 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 4.1198e-06 - binary_accuracy: 1.0000 - val_loss: 0.1062 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.3258e-05 - binary_accuracy: 1.0000 - val_loss: 0.1082 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 6.0133e-06 - binary_accuracy: 1.0000 - val_loss: 0.1054 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 5.1703e-06 - binary_accuracy: 1.0000 - val_loss: 0.1101 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.6427e-05 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 2.1931e-06 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 6.1196e-06 - binary_accuracy: 1.0000 - val_loss: 0.1117 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.8301e-06 - binary_accuracy: 1.0000 - val_loss: 0.1094 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 8.4643e-06 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 3.9191e-06 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.9871e-06 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 3.5390e-06 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 4.0529e-05 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.6835e-05 - binary_accuracy: 1.0000 - val_loss: 0.1133 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.9073e-05 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 9.7665e-06 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9894 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 3.3533e-06 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.0182e-06 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 1.6108e-05 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 5.4439e-06 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 2.7855e-06 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 4.9523e-06 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 7.8208e-07 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9894 - 8s/epoch - 123ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.1201e-05 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.6437e-04 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.0491e-04 - binary_accuracy: 1.0000 - val_loss: 0.1029 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 1.5850e-05 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 7.1739e-06 - binary_accuracy: 1.0000 - val_loss: 0.1106 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 6.0220e-06 - binary_accuracy: 1.0000 - val_loss: 0.1102 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.7058e-05 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 4.6200e-06 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.8869e-06 - binary_accuracy: 1.0000 - val_loss: 0.1091 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.5180e-05 - binary_accuracy: 1.0000 - val_loss: 0.1096 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 4.0836e-05 - binary_accuracy: 1.0000 - val_loss: 0.1008 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.7642e-06 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.6278e-06 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.3548e-06 - binary_accuracy: 1.0000 - val_loss: 0.1068 - val_binary_accuracy: 0.9900 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 8.2058e-07 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 5.8228e-06 - binary_accuracy: 1.0000 - val_loss: 0.1083 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 6.4284e-07 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 5.3966e-06 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.0466e-06 - binary_accuracy: 1.0000 - val_loss: 0.1087 - val_binary_accuracy: 0.9893 - 8s/epoch - 120ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.8616e-06 - binary_accuracy: 1.0000 - val_loss: 0.1053 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.4420e-06 - binary_accuracy: 1.0000 - val_loss: 0.1038 - val_binary_accuracy: 0.9900 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 8.3848e-07 - binary_accuracy: 1.0000 - val_loss: 0.1070 - val_binary_accuracy: 0.9901 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 1.3801e-06 - binary_accuracy: 1.0000 - val_loss: 0.1052 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 5.6717e-07 - binary_accuracy: 1.0000 - val_loss: 0.1104 - val_binary_accuracy: 0.9899 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 5.4423e-06 - binary_accuracy: 1.0000 - val_loss: 0.1080 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 5.7723e-05 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 9.9949e-06 - binary_accuracy: 1.0000 - val_loss: 0.1192 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 2.2657e-06 - binary_accuracy: 1.0000 - val_loss: 0.1148 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 2.8140e-06 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 5.1559e-06 - binary_accuracy: 1.0000 - val_loss: 0.1212 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.3853e-04 - binary_accuracy: 1.0000 - val_loss: 0.1036 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 6.9345e-06 - binary_accuracy: 1.0000 - val_loss: 0.1022 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 2.6212e-06 - binary_accuracy: 1.0000 - val_loss: 0.1077 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 1.1396e-06 - binary_accuracy: 1.0000 - val_loss: 0.1016 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 8.0975e-07 - binary_accuracy: 1.0000 - val_loss: 0.1040 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 3.2434e-06 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 7.5878e-07 - binary_accuracy: 1.0000 - val_loss: 0.1051 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.3149e-06 - binary_accuracy: 1.0000 - val_loss: 0.1024 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.1757e-06 - binary_accuracy: 1.0000 - val_loss: 0.1055 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 6.9456e-07 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.6932e-06 - binary_accuracy: 1.0000 - val_loss: 0.1096 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.7611e-05 - binary_accuracy: 1.0000 - val_loss: 0.1027 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.8089e-05 - binary_accuracy: 1.0000 - val_loss: 0.1124 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 2.9305e-06 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 3.8841e-05 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 3.4372e-06 - binary_accuracy: 1.0000 - val_loss: 0.1046 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 6.0304e-05 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.6248e-05 - binary_accuracy: 1.0000 - val_loss: 0.0923 - val_binary_accuracy: 0.9896 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.9272e-06 - binary_accuracy: 1.0000 - val_loss: 0.0912 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 3.0151e-05 - binary_accuracy: 1.0000 - val_loss: 0.1069 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 7.3508e-06 - binary_accuracy: 1.0000 - val_loss: 0.1021 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 9.1618e-07 - binary_accuracy: 1.0000 - val_loss: 0.1025 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 3.5641e-07 - binary_accuracy: 1.0000 - val_loss: 0.0998 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.7991e-06 - binary_accuracy: 1.0000 - val_loss: 0.1010 - val_binary_accuracy: 0.9896 - 8s/epoch - 120ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 4.1910e-07 - binary_accuracy: 1.0000 - val_loss: 0.1008 - val_binary_accuracy: 0.9897 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 8.0868e-07 - binary_accuracy: 1.0000 - val_loss: 0.1093 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 3.8110e-07 - binary_accuracy: 1.0000 - val_loss: 0.1010 - val_binary_accuracy: 0.9899 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 3.8776e-07 - binary_accuracy: 1.0000 - val_loss: 0.1059 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9893055558204651\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.048976477\n",
      "train attribution time:  399.5368869304657\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037963692\n",
      "validation attribution time:  39.57476758956909\n",
      "time:  2716.437914609909\n",
      "----- loop 41 :  [1748]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.17267394065857\n",
      "train data delta_a time:  1317.1615657806396\n",
      "train data time:  1383.3342397212982\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  7.037373781204224\n",
      "validation data delta_a time:  118.74509358406067\n",
      "validation data time:  125.78246736526489\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 24s - loss: 1.9800e-04 - binary_accuracy: 0.9999 - val_loss: 0.1188 - val_binary_accuracy: 0.9878 - 24s/epoch - 375ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 5.8429e-05 - binary_accuracy: 1.0000 - val_loss: 0.1185 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 2.3313e-05 - binary_accuracy: 1.0000 - val_loss: 0.1253 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 6.6581e-06 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.1738e-06 - binary_accuracy: 1.0000 - val_loss: 0.1221 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 2.7138e-05 - binary_accuracy: 1.0000 - val_loss: 0.1317 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 6.7482e-05 - binary_accuracy: 1.0000 - val_loss: 0.1340 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.6880e-05 - binary_accuracy: 1.0000 - val_loss: 0.1365 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 3.4647e-06 - binary_accuracy: 1.0000 - val_loss: 0.1329 - val_binary_accuracy: 0.9863 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 3.5180e-06 - binary_accuracy: 1.0000 - val_loss: 0.1274 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 7.4914e-07 - binary_accuracy: 1.0000 - val_loss: 0.1348 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.4686e-06 - binary_accuracy: 1.0000 - val_loss: 0.1398 - val_binary_accuracy: 0.9860 - 8s/epoch - 123ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.3449e-06 - binary_accuracy: 1.0000 - val_loss: 0.1321 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.4202e-06 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 9.4029e-06 - binary_accuracy: 1.0000 - val_loss: 0.1342 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.2305e-06 - binary_accuracy: 1.0000 - val_loss: 0.1389 - val_binary_accuracy: 0.9865 - 8s/epoch - 128ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 6.1834e-07 - binary_accuracy: 1.0000 - val_loss: 0.1332 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 9.2390e-05 - binary_accuracy: 1.0000 - val_loss: 0.1584 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 3.9016e-05 - binary_accuracy: 1.0000 - val_loss: 0.1395 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 6.6584e-06 - binary_accuracy: 1.0000 - val_loss: 0.1513 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 5.7575e-06 - binary_accuracy: 1.0000 - val_loss: 0.1406 - val_binary_accuracy: 0.9858 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 8.2352e-06 - binary_accuracy: 1.0000 - val_loss: 0.1504 - val_binary_accuracy: 0.9858 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 8.5151e-07 - binary_accuracy: 1.0000 - val_loss: 0.1422 - val_binary_accuracy: 0.9860 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.4776e-06 - binary_accuracy: 1.0000 - val_loss: 0.1496 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.8576e-06 - binary_accuracy: 1.0000 - val_loss: 0.1439 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 2.3636e-06 - binary_accuracy: 1.0000 - val_loss: 0.1475 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 2.8697e-06 - binary_accuracy: 1.0000 - val_loss: 0.1432 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 3.4468e-06 - binary_accuracy: 1.0000 - val_loss: 0.1446 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 1.2232e-06 - binary_accuracy: 1.0000 - val_loss: 0.1463 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 8.9646e-07 - binary_accuracy: 1.0000 - val_loss: 0.1463 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.1620e-06 - binary_accuracy: 1.0000 - val_loss: 0.1458 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.3043e-06 - binary_accuracy: 1.0000 - val_loss: 0.1440 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.3555e-07 - binary_accuracy: 1.0000 - val_loss: 0.1562 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 3.6480e-07 - binary_accuracy: 1.0000 - val_loss: 0.1405 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.7640e-07 - binary_accuracy: 1.0000 - val_loss: 0.1376 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.2103e-06 - binary_accuracy: 1.0000 - val_loss: 0.1483 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 5.2453e-07 - binary_accuracy: 1.0000 - val_loss: 0.1445 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 6.9632e-07 - binary_accuracy: 1.0000 - val_loss: 0.1485 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.7790e-06 - binary_accuracy: 1.0000 - val_loss: 0.1406 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 4.0723e-07 - binary_accuracy: 1.0000 - val_loss: 0.1376 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.2366e-05 - binary_accuracy: 1.0000 - val_loss: 0.1461 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 5.4124e-05 - binary_accuracy: 1.0000 - val_loss: 0.1523 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 8.9640e-06 - binary_accuracy: 1.0000 - val_loss: 0.1463 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 1.0209e-04 - binary_accuracy: 1.0000 - val_loss: 0.1363 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 2.5345e-06 - binary_accuracy: 1.0000 - val_loss: 0.1395 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 4.3284e-05 - binary_accuracy: 1.0000 - val_loss: 0.1414 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 8.2638e-06 - binary_accuracy: 1.0000 - val_loss: 0.1431 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 3.8488e-06 - binary_accuracy: 1.0000 - val_loss: 0.1350 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.4204e-06 - binary_accuracy: 1.0000 - val_loss: 0.1397 - val_binary_accuracy: 0.9872 - 8s/epoch - 123ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 7.1315e-07 - binary_accuracy: 1.0000 - val_loss: 0.1339 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.2036e-05 - binary_accuracy: 1.0000 - val_loss: 0.1403 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.8031e-06 - binary_accuracy: 1.0000 - val_loss: 0.1266 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 4.3455e-06 - binary_accuracy: 1.0000 - val_loss: 0.1369 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 9.4814e-07 - binary_accuracy: 1.0000 - val_loss: 0.1397 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 3.8330e-07 - binary_accuracy: 1.0000 - val_loss: 0.1364 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 4.7828e-07 - binary_accuracy: 1.0000 - val_loss: 0.1328 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.4799e-06 - binary_accuracy: 1.0000 - val_loss: 0.1371 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 3.4915e-07 - binary_accuracy: 1.0000 - val_loss: 0.1385 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 8.8990e-07 - binary_accuracy: 1.0000 - val_loss: 0.1404 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 3.5268e-07 - binary_accuracy: 1.0000 - val_loss: 0.1383 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.3456e-06 - binary_accuracy: 1.0000 - val_loss: 0.1388 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 1.6814e-06 - binary_accuracy: 1.0000 - val_loss: 0.1328 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 6.7923e-07 - binary_accuracy: 1.0000 - val_loss: 0.1419 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 6.6246e-07 - binary_accuracy: 1.0000 - val_loss: 0.1319 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 4.9856e-07 - binary_accuracy: 1.0000 - val_loss: 0.1379 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.9763e-07 - binary_accuracy: 1.0000 - val_loss: 0.1391 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 2.1472e-07 - binary_accuracy: 1.0000 - val_loss: 0.1403 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.7506e-07 - binary_accuracy: 1.0000 - val_loss: 0.1339 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 2.0020e-07 - binary_accuracy: 1.0000 - val_loss: 0.1360 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 3.6033e-07 - binary_accuracy: 1.0000 - val_loss: 0.1322 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 1.4647e-07 - binary_accuracy: 1.0000 - val_loss: 0.1356 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 2.6063e-07 - binary_accuracy: 1.0000 - val_loss: 0.1344 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 4.0033e-07 - binary_accuracy: 1.0000 - val_loss: 0.1378 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.1414e-07 - binary_accuracy: 1.0000 - val_loss: 0.1389 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 7.8615e-07 - binary_accuracy: 1.0000 - val_loss: 0.1369 - val_binary_accuracy: 0.9874 - 8s/epoch - 123ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 4.3591e-07 - binary_accuracy: 1.0000 - val_loss: 0.1387 - val_binary_accuracy: 0.9871 - 8s/epoch - 123ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 9.7024e-08 - binary_accuracy: 1.0000 - val_loss: 0.1410 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 2.4468e-07 - binary_accuracy: 1.0000 - val_loss: 0.1342 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 3.5965e-07 - binary_accuracy: 1.0000 - val_loss: 0.1395 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.2586e-07 - binary_accuracy: 1.0000 - val_loss: 0.1429 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.5981e-07 - binary_accuracy: 1.0000 - val_loss: 0.1442 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 3.3171e-07 - binary_accuracy: 1.0000 - val_loss: 0.1404 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 9.9116e-08 - binary_accuracy: 1.0000 - val_loss: 0.1361 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.1790e-07 - binary_accuracy: 1.0000 - val_loss: 0.1354 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 3.9927e-07 - binary_accuracy: 1.0000 - val_loss: 0.1402 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.3858e-07 - binary_accuracy: 1.0000 - val_loss: 0.1341 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 8.8985e-08 - binary_accuracy: 1.0000 - val_loss: 0.1353 - val_binary_accuracy: 0.9869 - 8s/epoch - 123ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 9.0692e-08 - binary_accuracy: 1.0000 - val_loss: 0.1391 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.5260e-07 - binary_accuracy: 1.0000 - val_loss: 0.1408 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.0446e-07 - binary_accuracy: 1.0000 - val_loss: 0.1369 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 3.5589e-07 - binary_accuracy: 1.0000 - val_loss: 0.1416 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.7686e-07 - binary_accuracy: 1.0000 - val_loss: 0.1400 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 9.7829e-08 - binary_accuracy: 1.0000 - val_loss: 0.1383 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 7.6420e-08 - binary_accuracy: 1.0000 - val_loss: 0.1385 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.1835e-07 - binary_accuracy: 1.0000 - val_loss: 0.1430 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 6.2973e-08 - binary_accuracy: 1.0000 - val_loss: 0.1436 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 2.5617e-06 - binary_accuracy: 1.0000 - val_loss: 0.1448 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 3.8132e-07 - binary_accuracy: 1.0000 - val_loss: 0.1421 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.3473e-07 - binary_accuracy: 1.0000 - val_loss: 0.1433 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 3.7831e-07 - binary_accuracy: 1.0000 - val_loss: 0.1418 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9873611330986023\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04910674\n",
      "train attribution time:  401.1838982105255\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037887532\n",
      "validation attribution time:  40.56620192527771\n",
      "time:  2734.2095370292664\n",
      "----- loop 42 :  [1748]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.89055585861206\n",
      "train data delta_a time:  1312.790090084076\n",
      "train data time:  1379.680645942688\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.316983461380005\n",
      "validation data delta_a time:  121.21559739112854\n",
      "validation data time:  127.53258085250854\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 3.5474e-04 - binary_accuracy: 0.9999 - val_loss: 0.1329 - val_binary_accuracy: 0.9883 - 18s/epoch - 287ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 1.1444e-05 - binary_accuracy: 1.0000 - val_loss: 0.1225 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 2.4904e-05 - binary_accuracy: 1.0000 - val_loss: 0.1266 - val_binary_accuracy: 0.9883 - 8s/epoch - 120ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.9889e-05 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 3.5587e-06 - binary_accuracy: 1.0000 - val_loss: 0.1340 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.5156e-05 - binary_accuracy: 1.0000 - val_loss: 0.1279 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.2072e-05 - binary_accuracy: 1.0000 - val_loss: 0.1342 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.0814e-06 - binary_accuracy: 1.0000 - val_loss: 0.1355 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 3.5718e-06 - binary_accuracy: 1.0000 - val_loss: 0.1339 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 3.7231e-05 - binary_accuracy: 1.0000 - val_loss: 0.1298 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 3.6424e-05 - binary_accuracy: 1.0000 - val_loss: 0.1321 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 9.1224e-06 - binary_accuracy: 1.0000 - val_loss: 0.1290 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.5806e-05 - binary_accuracy: 1.0000 - val_loss: 0.1314 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 1.5272e-06 - binary_accuracy: 1.0000 - val_loss: 0.1306 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.1103e-06 - binary_accuracy: 1.0000 - val_loss: 0.1316 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.6518e-06 - binary_accuracy: 1.0000 - val_loss: 0.1324 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 5.6652e-07 - binary_accuracy: 1.0000 - val_loss: 0.1317 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 3.6732e-07 - binary_accuracy: 1.0000 - val_loss: 0.1218 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 3.2129e-06 - binary_accuracy: 1.0000 - val_loss: 0.1331 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 7.1188e-06 - binary_accuracy: 1.0000 - val_loss: 0.1353 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 8.6955e-07 - binary_accuracy: 1.0000 - val_loss: 0.1311 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 4.8063e-07 - binary_accuracy: 1.0000 - val_loss: 0.1325 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 6.0814e-07 - binary_accuracy: 1.0000 - val_loss: 0.1321 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 8.4167e-07 - binary_accuracy: 1.0000 - val_loss: 0.1315 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 6.0036e-06 - binary_accuracy: 1.0000 - val_loss: 0.1264 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 7.0133e-06 - binary_accuracy: 1.0000 - val_loss: 0.1300 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 2.3721e-06 - binary_accuracy: 1.0000 - val_loss: 0.1327 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 4.3349e-07 - binary_accuracy: 1.0000 - val_loss: 0.1274 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 4.5462e-07 - binary_accuracy: 1.0000 - val_loss: 0.1287 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.7098e-07 - binary_accuracy: 1.0000 - val_loss: 0.1308 - val_binary_accuracy: 0.9876 - 8s/epoch - 119ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.0478e-06 - binary_accuracy: 1.0000 - val_loss: 0.1307 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 5.3755e-07 - binary_accuracy: 1.0000 - val_loss: 0.1386 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 1.0310e-06 - binary_accuracy: 1.0000 - val_loss: 0.1386 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 5.6054e-07 - binary_accuracy: 1.0000 - val_loss: 0.1365 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.3258e-07 - binary_accuracy: 1.0000 - val_loss: 0.1370 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 2.5004e-07 - binary_accuracy: 1.0000 - val_loss: 0.1309 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.0195e-06 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 3.7298e-07 - binary_accuracy: 1.0000 - val_loss: 0.1322 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 3.6047e-07 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 3.0602e-07 - binary_accuracy: 1.0000 - val_loss: 0.1371 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 2.1979e-07 - binary_accuracy: 1.0000 - val_loss: 0.1277 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 2.3043e-07 - binary_accuracy: 1.0000 - val_loss: 0.1340 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 2.0615e-07 - binary_accuracy: 1.0000 - val_loss: 0.1323 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 4.8947e-07 - binary_accuracy: 1.0000 - val_loss: 0.1294 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 4.4904e-07 - binary_accuracy: 1.0000 - val_loss: 0.1295 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 4.6442e-07 - binary_accuracy: 1.0000 - val_loss: 0.1364 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.0866e-07 - binary_accuracy: 1.0000 - val_loss: 0.1311 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.8596e-07 - binary_accuracy: 1.0000 - val_loss: 0.1383 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 1.3610e-07 - binary_accuracy: 1.0000 - val_loss: 0.1354 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.8033e-06 - binary_accuracy: 1.0000 - val_loss: 0.1364 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.5242e-07 - binary_accuracy: 1.0000 - val_loss: 0.1359 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 4.2134e-08 - binary_accuracy: 1.0000 - val_loss: 0.1365 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.7551e-07 - binary_accuracy: 1.0000 - val_loss: 0.1333 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.1539e-06 - binary_accuracy: 1.0000 - val_loss: 0.1324 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 8.6810e-08 - binary_accuracy: 1.0000 - val_loss: 0.1370 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.1180e-05 - binary_accuracy: 1.0000 - val_loss: 0.1466 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 4.3292e-04 - binary_accuracy: 0.9999 - val_loss: 0.1278 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 8.8763e-05 - binary_accuracy: 0.9999 - val_loss: 0.1276 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 4.9362e-05 - binary_accuracy: 1.0000 - val_loss: 0.1466 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 5.6412e-06 - binary_accuracy: 1.0000 - val_loss: 0.1444 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.0521e-06 - binary_accuracy: 1.0000 - val_loss: 0.1425 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 7.8908e-07 - binary_accuracy: 1.0000 - val_loss: 0.1359 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.0107e-06 - binary_accuracy: 1.0000 - val_loss: 0.1341 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.6605e-06 - binary_accuracy: 1.0000 - val_loss: 0.1411 - val_binary_accuracy: 0.9876 - 8s/epoch - 120ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.4429e-06 - binary_accuracy: 1.0000 - val_loss: 0.1385 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 2.8368e-06 - binary_accuracy: 1.0000 - val_loss: 0.1363 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 3.3720e-07 - binary_accuracy: 1.0000 - val_loss: 0.1395 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 5.2577e-07 - binary_accuracy: 1.0000 - val_loss: 0.1425 - val_binary_accuracy: 0.9875 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 8.6845e-07 - binary_accuracy: 1.0000 - val_loss: 0.1407 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.0422e-06 - binary_accuracy: 1.0000 - val_loss: 0.1420 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 4.8150e-07 - binary_accuracy: 1.0000 - val_loss: 0.1409 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 5.8349e-07 - binary_accuracy: 1.0000 - val_loss: 0.1412 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.6434e-06 - binary_accuracy: 1.0000 - val_loss: 0.1359 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 5.6169e-07 - binary_accuracy: 1.0000 - val_loss: 0.1401 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 3.6015e-07 - binary_accuracy: 1.0000 - val_loss: 0.1416 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 2.2521e-07 - binary_accuracy: 1.0000 - val_loss: 0.1370 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.3258e-07 - binary_accuracy: 1.0000 - val_loss: 0.1413 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.2569e-06 - binary_accuracy: 1.0000 - val_loss: 0.1407 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 3.6031e-07 - binary_accuracy: 1.0000 - val_loss: 0.1403 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.8557e-07 - binary_accuracy: 1.0000 - val_loss: 0.1414 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.4844e-07 - binary_accuracy: 1.0000 - val_loss: 0.1431 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 5.3338e-07 - binary_accuracy: 1.0000 - val_loss: 0.1448 - val_binary_accuracy: 0.9869 - 8s/epoch - 120ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 9.5384e-08 - binary_accuracy: 1.0000 - val_loss: 0.1411 - val_binary_accuracy: 0.9874 - 8s/epoch - 120ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 2.9992e-07 - binary_accuracy: 1.0000 - val_loss: 0.1384 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 2.2367e-06 - binary_accuracy: 1.0000 - val_loss: 0.1373 - val_binary_accuracy: 0.9879 - 8s/epoch - 120ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 4.3650e-07 - binary_accuracy: 1.0000 - val_loss: 0.1396 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 2.9627e-07 - binary_accuracy: 1.0000 - val_loss: 0.1365 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 5.3211e-07 - binary_accuracy: 1.0000 - val_loss: 0.1366 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 3.9456e-07 - binary_accuracy: 1.0000 - val_loss: 0.1352 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.5326e-05 - binary_accuracy: 1.0000 - val_loss: 0.1337 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 7.2212e-07 - binary_accuracy: 1.0000 - val_loss: 0.1372 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 7.5041e-07 - binary_accuracy: 1.0000 - val_loss: 0.1380 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.5772e-07 - binary_accuracy: 1.0000 - val_loss: 0.1360 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.7041e-07 - binary_accuracy: 1.0000 - val_loss: 0.1340 - val_binary_accuracy: 0.9878 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 3.8403e-07 - binary_accuracy: 1.0000 - val_loss: 0.1313 - val_binary_accuracy: 0.9881 - 8s/epoch - 120ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.7331e-07 - binary_accuracy: 1.0000 - val_loss: 0.1402 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 5.8178e-07 - binary_accuracy: 1.0000 - val_loss: 0.1329 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.3089e-07 - binary_accuracy: 1.0000 - val_loss: 0.1355 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.2771e-07 - binary_accuracy: 1.0000 - val_loss: 0.1317 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 2.0816e-07 - binary_accuracy: 1.0000 - val_loss: 0.1350 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9872223138809204\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049134426\n",
      "train attribution time:  401.4303488731384\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037961334\n",
      "validation attribution time:  39.846362590789795\n",
      "time:  2721.7006537914276\n",
      "----- loop 43 :  [1748]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.39104866981506\n",
      "train data delta_a time:  1314.5295343399048\n",
      "train data time:  1381.9205830097198\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.9267258644104\n",
      "validation data delta_a time:  118.43508100509644\n",
      "validation data time:  125.36180686950684\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 1.6469e-04 - binary_accuracy: 0.9999 - val_loss: 0.1194 - val_binary_accuracy: 0.9886 - 18s/epoch - 286ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 3.9186e-05 - binary_accuracy: 1.0000 - val_loss: 0.1216 - val_binary_accuracy: 0.9892 - 8s/epoch - 120ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.9111e-05 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 4.1257e-07 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.3270e-05 - binary_accuracy: 1.0000 - val_loss: 0.1214 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 3.5445e-07 - binary_accuracy: 1.0000 - val_loss: 0.1212 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 4.4487e-07 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 3.7236e-07 - binary_accuracy: 1.0000 - val_loss: 0.1246 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 1.1456e-06 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 4.8919e-07 - binary_accuracy: 1.0000 - val_loss: 0.1252 - val_binary_accuracy: 0.9893 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 5.3615e-07 - binary_accuracy: 1.0000 - val_loss: 0.1229 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.0293e-06 - binary_accuracy: 1.0000 - val_loss: 0.1252 - val_binary_accuracy: 0.9882 - 8s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.5433e-07 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 4.9122e-07 - binary_accuracy: 1.0000 - val_loss: 0.1170 - val_binary_accuracy: 0.9882 - 8s/epoch - 123ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 1.4152e-06 - binary_accuracy: 1.0000 - val_loss: 0.1235 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.8616e-07 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 1.7795e-06 - binary_accuracy: 1.0000 - val_loss: 0.1176 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.1746e-06 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9892 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 2.0189e-06 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9888 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 4.8776e-07 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.8273e-07 - binary_accuracy: 1.0000 - val_loss: 0.1228 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.3817e-07 - binary_accuracy: 1.0000 - val_loss: 0.1253 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 5.2209e-07 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.5187e-07 - binary_accuracy: 1.0000 - val_loss: 0.1233 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.5207e-07 - binary_accuracy: 1.0000 - val_loss: 0.1227 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.9001e-07 - binary_accuracy: 1.0000 - val_loss: 0.1212 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 2.9065e-07 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 1.6188e-07 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 2.6855e-07 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 2.4390e-07 - binary_accuracy: 1.0000 - val_loss: 0.1222 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 6.9038e-08 - binary_accuracy: 1.0000 - val_loss: 0.1186 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.2850e-07 - binary_accuracy: 1.0000 - val_loss: 0.1226 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 2.9931e-07 - binary_accuracy: 1.0000 - val_loss: 0.1202 - val_binary_accuracy: 0.9894 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 2.7300e-07 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9886 - 8s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 1.8278e-07 - binary_accuracy: 1.0000 - val_loss: 0.1232 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 1.8007e-07 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9887 - 8s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 1.2055e-07 - binary_accuracy: 1.0000 - val_loss: 0.1210 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.1066e-07 - binary_accuracy: 1.0000 - val_loss: 0.1157 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 4.8491e-08 - binary_accuracy: 1.0000 - val_loss: 0.1239 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.7118e-07 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 8.4561e-08 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 2.0910e-07 - binary_accuracy: 1.0000 - val_loss: 0.1190 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 6.9853e-08 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 9.1400e-08 - binary_accuracy: 1.0000 - val_loss: 0.1218 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 7.8276e-07 - binary_accuracy: 1.0000 - val_loss: 0.1212 - val_binary_accuracy: 0.9888 - 8s/epoch - 120ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.4358e-07 - binary_accuracy: 1.0000 - val_loss: 0.1213 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.4137e-07 - binary_accuracy: 1.0000 - val_loss: 0.1251 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 8.2489e-08 - binary_accuracy: 1.0000 - val_loss: 0.1240 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 8.8611e-08 - binary_accuracy: 1.0000 - val_loss: 0.1234 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.0290e-07 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 7.1317e-08 - binary_accuracy: 1.0000 - val_loss: 0.1250 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 3.1121e-07 - binary_accuracy: 1.0000 - val_loss: 0.1279 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 7.0902e-08 - binary_accuracy: 1.0000 - val_loss: 0.1217 - val_binary_accuracy: 0.9889 - 8s/epoch - 120ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.2754e-07 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.1460e-06 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 3.5530e-07 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.7406e-07 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.2796e-07 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 2.3287e-07 - binary_accuracy: 1.0000 - val_loss: 0.1119 - val_binary_accuracy: 0.9897 - 8s/epoch - 120ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 4.7896e-08 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 6.3988e-08 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 5.9936e-08 - binary_accuracy: 1.0000 - val_loss: 0.1139 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 3.8321e-07 - binary_accuracy: 1.0000 - val_loss: 0.1168 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.2008e-07 - binary_accuracy: 1.0000 - val_loss: 0.1158 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 3.8238e-08 - binary_accuracy: 1.0000 - val_loss: 0.1173 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.0397e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9892 - 8s/epoch - 122ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 6.4432e-08 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 3.7896e-08 - binary_accuracy: 1.0000 - val_loss: 0.1175 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 2.7681e-07 - binary_accuracy: 1.0000 - val_loss: 0.1144 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 7.0994e-08 - binary_accuracy: 1.0000 - val_loss: 0.1193 - val_binary_accuracy: 0.9889 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 3.4290e-08 - binary_accuracy: 1.0000 - val_loss: 0.1188 - val_binary_accuracy: 0.9890 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 7.7763e-08 - binary_accuracy: 1.0000 - val_loss: 0.1207 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 7.1669e-08 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9890 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 5.4497e-08 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 5.4834e-08 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9890 - 8s/epoch - 120ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 4.8963e-08 - binary_accuracy: 1.0000 - val_loss: 0.1174 - val_binary_accuracy: 0.9887 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 3.8019e-08 - binary_accuracy: 1.0000 - val_loss: 0.1202 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 3.3269e-08 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9893 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 1.2939e-07 - binary_accuracy: 1.0000 - val_loss: 0.1184 - val_binary_accuracy: 0.9889 - 8s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 9.0784e-05 - binary_accuracy: 1.0000 - val_loss: 0.1189 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.9017e-05 - binary_accuracy: 1.0000 - val_loss: 0.1265 - val_binary_accuracy: 0.9888 - 8s/epoch - 121ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 1.9871e-05 - binary_accuracy: 1.0000 - val_loss: 0.1392 - val_binary_accuracy: 0.9886 - 8s/epoch - 123ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.6332e-04 - binary_accuracy: 0.9999 - val_loss: 0.1153 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 7.9968e-06 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 6.3263e-06 - binary_accuracy: 1.0000 - val_loss: 0.1105 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.8123e-06 - binary_accuracy: 1.0000 - val_loss: 0.1131 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.0063e-06 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 7.0645e-07 - binary_accuracy: 1.0000 - val_loss: 0.1096 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 4.6127e-07 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 5.6432e-07 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 4.7591e-07 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 1.2956e-06 - binary_accuracy: 1.0000 - val_loss: 0.1129 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.7582e-07 - binary_accuracy: 1.0000 - val_loss: 0.1103 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.8186e-07 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.5012e-05 - binary_accuracy: 1.0000 - val_loss: 0.1112 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.7959e-05 - binary_accuracy: 1.0000 - val_loss: 0.1194 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 7.0938e-06 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 3.6136e-07 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 3.5314e-07 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 3.0715e-06 - binary_accuracy: 1.0000 - val_loss: 0.1115 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9881944060325623\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049081307\n",
      "train attribution time:  402.14036226272583\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.0381649\n",
      "validation attribution time:  40.423850297927856\n",
      "time:  2725.589140176773\n",
      "----- loop 44 :  [1748]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.85240459442139\n",
      "train data delta_a time:  1338.4976630210876\n",
      "train data time:  1406.350067615509\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.551504373550415\n",
      "validation data delta_a time:  119.32675004005432\n",
      "validation data time:  125.87825441360474\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0028 - binary_accuracy: 0.9996 - val_loss: 0.1246 - val_binary_accuracy: 0.9869 - 18s/epoch - 288ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 0.1194 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 4.8731e-04 - binary_accuracy: 0.9998 - val_loss: 0.1277 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.9762e-04 - binary_accuracy: 0.9999 - val_loss: 0.1321 - val_binary_accuracy: 0.9858 - 8s/epoch - 122ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 2.1273e-04 - binary_accuracy: 0.9999 - val_loss: 0.1282 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.4223e-04 - binary_accuracy: 0.9999 - val_loss: 0.1286 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 8.6102e-05 - binary_accuracy: 1.0000 - val_loss: 0.1316 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 8.9701e-05 - binary_accuracy: 1.0000 - val_loss: 0.1314 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 8.0964e-05 - binary_accuracy: 1.0000 - val_loss: 0.1296 - val_binary_accuracy: 0.9878 - 8s/epoch - 123ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 1.2298e-05 - binary_accuracy: 1.0000 - val_loss: 0.1318 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 4.9586e-05 - binary_accuracy: 1.0000 - val_loss: 0.1314 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.0887e-05 - binary_accuracy: 1.0000 - val_loss: 0.1347 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.1961e-05 - binary_accuracy: 1.0000 - val_loss: 0.1306 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 8.2975e-06 - binary_accuracy: 1.0000 - val_loss: 0.1333 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 3.3710e-05 - binary_accuracy: 1.0000 - val_loss: 0.1317 - val_binary_accuracy: 0.9864 - 8s/epoch - 123ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 1.4999e-05 - binary_accuracy: 1.0000 - val_loss: 0.1327 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 3.7832e-05 - binary_accuracy: 1.0000 - val_loss: 0.1333 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 5.6429e-05 - binary_accuracy: 1.0000 - val_loss: 0.1445 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 2.2056e-05 - binary_accuracy: 1.0000 - val_loss: 0.1386 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.3307e-05 - binary_accuracy: 1.0000 - val_loss: 0.1358 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 5.2007e-06 - binary_accuracy: 1.0000 - val_loss: 0.1428 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 3.2319e-06 - binary_accuracy: 1.0000 - val_loss: 0.1300 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 5.2139e-06 - binary_accuracy: 1.0000 - val_loss: 0.1348 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 5.0058e-06 - binary_accuracy: 1.0000 - val_loss: 0.1369 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.3350e-05 - binary_accuracy: 1.0000 - val_loss: 0.1390 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 1.3497e-05 - binary_accuracy: 1.0000 - val_loss: 0.1405 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 5.2715e-05 - binary_accuracy: 1.0000 - val_loss: 0.1310 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 3.3733e-05 - binary_accuracy: 1.0000 - val_loss: 0.1335 - val_binary_accuracy: 0.9874 - 8s/epoch - 123ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 8.0657e-05 - binary_accuracy: 1.0000 - val_loss: 0.1355 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.5163e-04 - binary_accuracy: 1.0000 - val_loss: 0.1381 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 2.0395e-06 - binary_accuracy: 1.0000 - val_loss: 0.1403 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 1.3829e-04 - binary_accuracy: 1.0000 - val_loss: 0.1330 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 3.6058e-05 - binary_accuracy: 1.0000 - val_loss: 0.1324 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 5.0510e-06 - binary_accuracy: 1.0000 - val_loss: 0.1369 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 2.5366e-06 - binary_accuracy: 1.0000 - val_loss: 0.1262 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 2.2367e-05 - binary_accuracy: 1.0000 - val_loss: 0.1308 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 4.3436e-05 - binary_accuracy: 1.0000 - val_loss: 0.1320 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 2.9919e-05 - binary_accuracy: 1.0000 - val_loss: 0.1483 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 5.9958e-06 - binary_accuracy: 1.0000 - val_loss: 0.1505 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.2248e-06 - binary_accuracy: 1.0000 - val_loss: 0.1469 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 1.0725e-05 - binary_accuracy: 1.0000 - val_loss: 0.1508 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 5.9374e-06 - binary_accuracy: 1.0000 - val_loss: 0.1404 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.9573e-06 - binary_accuracy: 1.0000 - val_loss: 0.1461 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 2.1932e-05 - binary_accuracy: 1.0000 - val_loss: 0.1480 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 2.0003e-06 - binary_accuracy: 1.0000 - val_loss: 0.1454 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 2.0743e-06 - binary_accuracy: 1.0000 - val_loss: 0.1446 - val_binary_accuracy: 0.9865 - 8s/epoch - 123ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 1.2834e-06 - binary_accuracy: 1.0000 - val_loss: 0.1461 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.3782e-06 - binary_accuracy: 1.0000 - val_loss: 0.1387 - val_binary_accuracy: 0.9869 - 8s/epoch - 123ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 3.7374e-06 - binary_accuracy: 1.0000 - val_loss: 0.1458 - val_binary_accuracy: 0.9876 - 8s/epoch - 124ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 2.8977e-06 - binary_accuracy: 1.0000 - val_loss: 0.1451 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 2.7674e-06 - binary_accuracy: 1.0000 - val_loss: 0.1463 - val_binary_accuracy: 0.9868 - 8s/epoch - 123ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 7.4240e-07 - binary_accuracy: 1.0000 - val_loss: 0.1443 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 5.4541e-07 - binary_accuracy: 1.0000 - val_loss: 0.1487 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 5.3815e-07 - binary_accuracy: 1.0000 - val_loss: 0.1425 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 2.6487e-06 - binary_accuracy: 1.0000 - val_loss: 0.1351 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 7.1972e-07 - binary_accuracy: 1.0000 - val_loss: 0.1380 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.6467e-06 - binary_accuracy: 1.0000 - val_loss: 0.1417 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 1.0661e-06 - binary_accuracy: 1.0000 - val_loss: 0.1410 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 5.8221e-07 - binary_accuracy: 1.0000 - val_loss: 0.1450 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.8571e-06 - binary_accuracy: 1.0000 - val_loss: 0.1410 - val_binary_accuracy: 0.9856 - 8s/epoch - 123ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.0460e-06 - binary_accuracy: 1.0000 - val_loss: 0.1435 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 6.0860e-07 - binary_accuracy: 1.0000 - val_loss: 0.1444 - val_binary_accuracy: 0.9868 - 8s/epoch - 123ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 3.8098e-07 - binary_accuracy: 1.0000 - val_loss: 0.1380 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 1.3876e-05 - binary_accuracy: 1.0000 - val_loss: 0.1410 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 6.0592e-05 - binary_accuracy: 1.0000 - val_loss: 0.1404 - val_binary_accuracy: 0.9856 - 8s/epoch - 122ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 1.6135e-04 - binary_accuracy: 1.0000 - val_loss: 0.1340 - val_binary_accuracy: 0.9868 - 8s/epoch - 123ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.1553e-04 - binary_accuracy: 1.0000 - val_loss: 0.1367 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 4.8324e-05 - binary_accuracy: 1.0000 - val_loss: 0.1278 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 8.4053e-06 - binary_accuracy: 1.0000 - val_loss: 0.1258 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.3962e-05 - binary_accuracy: 1.0000 - val_loss: 0.1411 - val_binary_accuracy: 0.9856 - 8s/epoch - 122ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 7.8052e-06 - binary_accuracy: 1.0000 - val_loss: 0.1380 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 4.1571e-06 - binary_accuracy: 1.0000 - val_loss: 0.1450 - val_binary_accuracy: 0.9858 - 8s/epoch - 123ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.1378e-06 - binary_accuracy: 1.0000 - val_loss: 0.1433 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 2.4263e-06 - binary_accuracy: 1.0000 - val_loss: 0.1403 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 5.5418e-06 - binary_accuracy: 1.0000 - val_loss: 0.1413 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 7.6159e-05 - binary_accuracy: 1.0000 - val_loss: 0.1476 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 5.6276e-06 - binary_accuracy: 1.0000 - val_loss: 0.1448 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.8061e-05 - binary_accuracy: 1.0000 - val_loss: 0.1454 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 4.3318e-06 - binary_accuracy: 1.0000 - val_loss: 0.1436 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 1.3855e-05 - binary_accuracy: 1.0000 - val_loss: 0.1406 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 2.6979e-06 - binary_accuracy: 1.0000 - val_loss: 0.1438 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 5.7640e-07 - binary_accuracy: 1.0000 - val_loss: 0.1419 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 2.6202e-06 - binary_accuracy: 1.0000 - val_loss: 0.1362 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.1553e-06 - binary_accuracy: 1.0000 - val_loss: 0.1383 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 7.2793e-07 - binary_accuracy: 1.0000 - val_loss: 0.1433 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.6254e-06 - binary_accuracy: 1.0000 - val_loss: 0.1357 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.2957e-05 - binary_accuracy: 1.0000 - val_loss: 0.1422 - val_binary_accuracy: 0.9868 - 8s/epoch - 123ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 5.3393e-06 - binary_accuracy: 1.0000 - val_loss: 0.1380 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 1.7861e-06 - binary_accuracy: 1.0000 - val_loss: 0.1390 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.3047e-06 - binary_accuracy: 1.0000 - val_loss: 0.1418 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.6706e-06 - binary_accuracy: 1.0000 - val_loss: 0.1421 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 2.7297e-06 - binary_accuracy: 1.0000 - val_loss: 0.1306 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 1.9576e-06 - binary_accuracy: 1.0000 - val_loss: 0.1378 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.5803e-06 - binary_accuracy: 1.0000 - val_loss: 0.1408 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 1.3064e-06 - binary_accuracy: 1.0000 - val_loss: 0.1408 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 2.2814e-06 - binary_accuracy: 1.0000 - val_loss: 0.1385 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.1382e-06 - binary_accuracy: 1.0000 - val_loss: 0.1399 - val_binary_accuracy: 0.9867 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 5.6746e-06 - binary_accuracy: 1.0000 - val_loss: 0.1484 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 1.0747e-06 - binary_accuracy: 1.0000 - val_loss: 0.1492 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 2.0643e-07 - binary_accuracy: 1.0000 - val_loss: 0.1457 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9861111640930176\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04895061\n",
      "train attribution time:  401.77042293548584\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038507722\n",
      "validation attribution time:  40.888872146606445\n",
      "time:  2753.3736670017242\n",
      "----- loop 45 :  [1748]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  68.85494112968445\n",
      "train data delta_a time:  1326.4644606113434\n",
      "train data time:  1395.3194017410278\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.864815950393677\n",
      "validation data delta_a time:  120.93003535270691\n",
      "validation data time:  127.79485130310059\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0011 - binary_accuracy: 0.9999 - val_loss: 0.1230 - val_binary_accuracy: 0.9878 - 18s/epoch - 286ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 4.7486e-04 - binary_accuracy: 0.9999 - val_loss: 0.1199 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 1.9463e-04 - binary_accuracy: 0.9999 - val_loss: 0.1210 - val_binary_accuracy: 0.9886 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 1.5100e-04 - binary_accuracy: 0.9999 - val_loss: 0.1163 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.2839e-04 - binary_accuracy: 0.9999 - val_loss: 0.1153 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.3720e-04 - binary_accuracy: 0.9999 - val_loss: 0.1237 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 1.3930e-04 - binary_accuracy: 1.0000 - val_loss: 0.1146 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 1.5133e-05 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9871 - 8s/epoch - 120ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 2.4065e-05 - binary_accuracy: 1.0000 - val_loss: 0.1121 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 4.5272e-06 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.5855e-05 - binary_accuracy: 1.0000 - val_loss: 0.1180 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 1.5406e-05 - binary_accuracy: 1.0000 - val_loss: 0.1122 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 6.9653e-06 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 2.0244e-05 - binary_accuracy: 1.0000 - val_loss: 0.1128 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 4.2417e-05 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 2.2124e-04 - binary_accuracy: 0.9999 - val_loss: 0.1061 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 3.0173e-05 - binary_accuracy: 1.0000 - val_loss: 0.1116 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 6.3390e-06 - binary_accuracy: 1.0000 - val_loss: 0.1143 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 1.2311e-06 - binary_accuracy: 1.0000 - val_loss: 0.1159 - val_binary_accuracy: 0.9885 - 8s/epoch - 122ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 9.4129e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.7210e-06 - binary_accuracy: 1.0000 - val_loss: 0.1198 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 3.8316e-06 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 1.2077e-05 - binary_accuracy: 1.0000 - val_loss: 0.1113 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.8048e-06 - binary_accuracy: 1.0000 - val_loss: 0.1149 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 1.5031e-06 - binary_accuracy: 1.0000 - val_loss: 0.1151 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 3.7885e-06 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 2.1322e-06 - binary_accuracy: 1.0000 - val_loss: 0.1140 - val_binary_accuracy: 0.9885 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 7.5667e-06 - binary_accuracy: 1.0000 - val_loss: 0.1165 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 1.1219e-06 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 1.8342e-05 - binary_accuracy: 1.0000 - val_loss: 0.1230 - val_binary_accuracy: 0.9875 - 8s/epoch - 122ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 1.0646e-06 - binary_accuracy: 1.0000 - val_loss: 0.1137 - val_binary_accuracy: 0.9881 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 8.4033e-07 - binary_accuracy: 1.0000 - val_loss: 0.1177 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 4.7513e-06 - binary_accuracy: 1.0000 - val_loss: 0.1169 - val_binary_accuracy: 0.9879 - 8s/epoch - 122ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 1.2879e-06 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 5.6064e-07 - binary_accuracy: 1.0000 - val_loss: 0.1204 - val_binary_accuracy: 0.9874 - 8s/epoch - 121ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 9.0181e-06 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 3.2222e-06 - binary_accuracy: 1.0000 - val_loss: 0.1204 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 7.6086e-07 - binary_accuracy: 1.0000 - val_loss: 0.1163 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 1.6463e-06 - binary_accuracy: 1.0000 - val_loss: 0.1234 - val_binary_accuracy: 0.9878 - 8s/epoch - 122ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.8473e-05 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 3.3780e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9887 - 8s/epoch - 122ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 4.9328e-07 - binary_accuracy: 1.0000 - val_loss: 0.1142 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 8.3134e-07 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 8.8633e-07 - binary_accuracy: 1.0000 - val_loss: 0.1203 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 3.0453e-07 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 3.3976e-07 - binary_accuracy: 1.0000 - val_loss: 0.1152 - val_binary_accuracy: 0.9881 - 8s/epoch - 122ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 3.2514e-07 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 1.1963e-07 - binary_accuracy: 1.0000 - val_loss: 0.1277 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 2.3586e-06 - binary_accuracy: 1.0000 - val_loss: 0.1220 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 3.8055e-07 - binary_accuracy: 1.0000 - val_loss: 0.1154 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 4.2395e-07 - binary_accuracy: 1.0000 - val_loss: 0.1200 - val_binary_accuracy: 0.9883 - 8s/epoch - 122ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.7304e-05 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9886 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 1.0523e-04 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 1.4758e-06 - binary_accuracy: 1.0000 - val_loss: 0.1187 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 1.1794e-05 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 1.9078e-06 - binary_accuracy: 1.0000 - val_loss: 0.1183 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 2.0027e-06 - binary_accuracy: 1.0000 - val_loss: 0.1211 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 7.7638e-06 - binary_accuracy: 1.0000 - val_loss: 0.1236 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 6.8344e-07 - binary_accuracy: 1.0000 - val_loss: 0.1237 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 1.0877e-06 - binary_accuracy: 1.0000 - val_loss: 0.1282 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 1.3254e-06 - binary_accuracy: 1.0000 - val_loss: 0.1266 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 4.0965e-07 - binary_accuracy: 1.0000 - val_loss: 0.1283 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 5.0630e-07 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9885 - 8s/epoch - 120ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.5752e-07 - binary_accuracy: 1.0000 - val_loss: 0.1332 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.0968e-07 - binary_accuracy: 1.0000 - val_loss: 0.1279 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 9.1659e-07 - binary_accuracy: 1.0000 - val_loss: 0.1281 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 2.9962e-07 - binary_accuracy: 1.0000 - val_loss: 0.1271 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 1.9076e-07 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9882 - 8s/epoch - 122ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 2.3194e-07 - binary_accuracy: 1.0000 - val_loss: 0.1241 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 2.4110e-06 - binary_accuracy: 1.0000 - val_loss: 0.1329 - val_binary_accuracy: 0.9883 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 7.4047e-05 - binary_accuracy: 1.0000 - val_loss: 0.1179 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 4.6718e-05 - binary_accuracy: 1.0000 - val_loss: 0.1076 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 2.9880e-04 - binary_accuracy: 0.9999 - val_loss: 0.1074 - val_binary_accuracy: 0.9871 - 8s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 1.9773e-04 - binary_accuracy: 0.9999 - val_loss: 0.1161 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 9.1575e-06 - binary_accuracy: 1.0000 - val_loss: 0.1209 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 7.5326e-07 - binary_accuracy: 1.0000 - val_loss: 0.1167 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.9751e-06 - binary_accuracy: 1.0000 - val_loss: 0.1138 - val_binary_accuracy: 0.9879 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 1.2700e-06 - binary_accuracy: 1.0000 - val_loss: 0.1160 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 2.3250e-06 - binary_accuracy: 1.0000 - val_loss: 0.1127 - val_binary_accuracy: 0.9882 - 8s/epoch - 121ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 5.4558e-07 - binary_accuracy: 1.0000 - val_loss: 0.1205 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 1.2577e-06 - binary_accuracy: 1.0000 - val_loss: 0.1178 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 2.1934e-06 - binary_accuracy: 1.0000 - val_loss: 0.1171 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 3.9063e-06 - binary_accuracy: 1.0000 - val_loss: 0.1195 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 3.0935e-06 - binary_accuracy: 1.0000 - val_loss: 0.1126 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 1.3922e-06 - binary_accuracy: 1.0000 - val_loss: 0.1204 - val_binary_accuracy: 0.9876 - 8s/epoch - 122ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 8.4217e-07 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.0501e-06 - binary_accuracy: 1.0000 - val_loss: 0.1191 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 3.5911e-07 - binary_accuracy: 1.0000 - val_loss: 0.1032 - val_binary_accuracy: 0.9875 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 7.9227e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9868 - 8s/epoch - 121ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 1.8605e-06 - binary_accuracy: 1.0000 - val_loss: 0.1153 - val_binary_accuracy: 0.9874 - 8s/epoch - 122ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 1.4052e-06 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 4.7190e-07 - binary_accuracy: 1.0000 - val_loss: 0.1123 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 3.2108e-07 - binary_accuracy: 1.0000 - val_loss: 0.1201 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 2.3760e-07 - binary_accuracy: 1.0000 - val_loss: 0.1197 - val_binary_accuracy: 0.9872 - 8s/epoch - 120ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 2.0638e-07 - binary_accuracy: 1.0000 - val_loss: 0.1161 - val_binary_accuracy: 0.9872 - 8s/epoch - 122ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.3500e-06 - binary_accuracy: 1.0000 - val_loss: 0.1162 - val_binary_accuracy: 0.9876 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 3.1697e-07 - binary_accuracy: 1.0000 - val_loss: 0.1224 - val_binary_accuracy: 0.9869 - 8s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 8.1945e-07 - binary_accuracy: 1.0000 - val_loss: 0.1260 - val_binary_accuracy: 0.9868 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 3.4554e-07 - binary_accuracy: 1.0000 - val_loss: 0.1166 - val_binary_accuracy: 0.9878 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 5.8216e-06 - binary_accuracy: 1.0000 - val_loss: 0.1264 - val_binary_accuracy: 0.9872 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9872223138809204\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.048653387\n",
      "train attribution time:  399.5106861591339\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.038023267\n",
      "validation attribution time:  41.318341970443726\n",
      "time:  2740.4445238113403\n",
      "----- loop 46 :  [1748]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  67.54695725440979\n",
      "train data delta_a time:  1332.494023323059\n",
      "train data time:  1400.0409805774689\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  6.318043947219849\n",
      "validation data delta_a time:  127.61530232429504\n",
      "validation data time:  133.9333462715149\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "63/63 - 18s - loss: 0.0018 - binary_accuracy: 0.9997 - val_loss: 0.1397 - val_binary_accuracy: 0.9854 - 18s/epoch - 285ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 8s - loss: 8.9162e-04 - binary_accuracy: 0.9998 - val_loss: 0.1505 - val_binary_accuracy: 0.9854 - 8s/epoch - 122ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 3.9833e-04 - binary_accuracy: 0.9999 - val_loss: 0.1442 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 2.4611e-04 - binary_accuracy: 0.9999 - val_loss: 0.1412 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 1.6190e-04 - binary_accuracy: 0.9999 - val_loss: 0.1482 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 1.3599e-04 - binary_accuracy: 0.9999 - val_loss: 0.1496 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 8s - loss: 2.2762e-05 - binary_accuracy: 1.0000 - val_loss: 0.1512 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 7.0139e-05 - binary_accuracy: 1.0000 - val_loss: 0.1533 - val_binary_accuracy: 0.9862 - 8s/epoch - 123ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 8s - loss: 3.3622e-05 - binary_accuracy: 1.0000 - val_loss: 0.1537 - val_binary_accuracy: 0.9864 - 8s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 8s - loss: 8.0583e-05 - binary_accuracy: 1.0000 - val_loss: 0.1528 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 8s - loss: 1.0993e-04 - binary_accuracy: 1.0000 - val_loss: 0.1549 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 3.3877e-05 - binary_accuracy: 1.0000 - val_loss: 0.1614 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 8s - loss: 1.2121e-05 - binary_accuracy: 1.0000 - val_loss: 0.1603 - val_binary_accuracy: 0.9851 - 8s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 8s - loss: 3.9160e-05 - binary_accuracy: 1.0000 - val_loss: 0.1473 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 8s - loss: 7.2030e-06 - binary_accuracy: 1.0000 - val_loss: 0.1555 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 8s - loss: 7.4430e-05 - binary_accuracy: 1.0000 - val_loss: 0.1551 - val_binary_accuracy: 0.9856 - 8s/epoch - 121ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 8s - loss: 2.2965e-05 - binary_accuracy: 1.0000 - val_loss: 0.1488 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 8s - loss: 1.0254e-05 - binary_accuracy: 1.0000 - val_loss: 0.1475 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 8s - loss: 4.7493e-06 - binary_accuracy: 1.0000 - val_loss: 0.1496 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 8s - loss: 1.9424e-05 - binary_accuracy: 1.0000 - val_loss: 0.1419 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 8s - loss: 1.5058e-05 - binary_accuracy: 1.0000 - val_loss: 0.1558 - val_binary_accuracy: 0.9854 - 8s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 8s - loss: 2.0739e-05 - binary_accuracy: 1.0000 - val_loss: 0.1527 - val_binary_accuracy: 0.9854 - 8s/epoch - 122ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 8s - loss: 3.1391e-05 - binary_accuracy: 1.0000 - val_loss: 0.1491 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 8s - loss: 1.4818e-05 - binary_accuracy: 1.0000 - val_loss: 0.1498 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 8s - loss: 4.8433e-06 - binary_accuracy: 1.0000 - val_loss: 0.1454 - val_binary_accuracy: 0.9856 - 8s/epoch - 121ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 8s - loss: 3.6120e-06 - binary_accuracy: 1.0000 - val_loss: 0.1436 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 8s - loss: 1.8742e-05 - binary_accuracy: 1.0000 - val_loss: 0.1487 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 8s - loss: 3.0445e-06 - binary_accuracy: 1.0000 - val_loss: 0.1530 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 8s - loss: 3.0886e-05 - binary_accuracy: 1.0000 - val_loss: 0.1393 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 8s - loss: 4.1397e-05 - binary_accuracy: 1.0000 - val_loss: 0.1391 - val_binary_accuracy: 0.9858 - 8s/epoch - 122ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 8s - loss: 6.0906e-06 - binary_accuracy: 1.0000 - val_loss: 0.1308 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 8s - loss: 2.0997e-05 - binary_accuracy: 1.0000 - val_loss: 0.1422 - val_binary_accuracy: 0.9861 - 8s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 8s - loss: 7.3276e-06 - binary_accuracy: 1.0000 - val_loss: 0.1406 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 8s - loss: 7.1629e-06 - binary_accuracy: 1.0000 - val_loss: 0.1399 - val_binary_accuracy: 0.9860 - 8s/epoch - 122ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 8s - loss: 5.6651e-06 - binary_accuracy: 1.0000 - val_loss: 0.1524 - val_binary_accuracy: 0.9854 - 8s/epoch - 120ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 8s - loss: 5.9798e-06 - binary_accuracy: 1.0000 - val_loss: 0.1539 - val_binary_accuracy: 0.9858 - 8s/epoch - 122ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 8s - loss: 2.2225e-06 - binary_accuracy: 1.0000 - val_loss: 0.1426 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 8s - loss: 6.4734e-06 - binary_accuracy: 1.0000 - val_loss: 0.1478 - val_binary_accuracy: 0.9856 - 8s/epoch - 122ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 4.6948e-06 - binary_accuracy: 1.0000 - val_loss: 0.1494 - val_binary_accuracy: 0.9850 - 8s/epoch - 121ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 8s - loss: 1.3305e-06 - binary_accuracy: 1.0000 - val_loss: 0.1435 - val_binary_accuracy: 0.9857 - 8s/epoch - 120ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 8s - loss: 5.5896e-06 - binary_accuracy: 1.0000 - val_loss: 0.1386 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 8s - loss: 5.9178e-06 - binary_accuracy: 1.0000 - val_loss: 0.1453 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 8s - loss: 1.9048e-06 - binary_accuracy: 1.0000 - val_loss: 0.1520 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 8s - loss: 5.5196e-06 - binary_accuracy: 1.0000 - val_loss: 0.1519 - val_binary_accuracy: 0.9851 - 8s/epoch - 122ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 8s - loss: 1.9298e-06 - binary_accuracy: 1.0000 - val_loss: 0.1503 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 8s - loss: 1.0375e-06 - binary_accuracy: 1.0000 - val_loss: 0.1470 - val_binary_accuracy: 0.9865 - 8s/epoch - 122ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 8s - loss: 8.4880e-07 - binary_accuracy: 1.0000 - val_loss: 0.1401 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 8s - loss: 2.1493e-06 - binary_accuracy: 1.0000 - val_loss: 0.1405 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 8s - loss: 8.7351e-07 - binary_accuracy: 1.0000 - val_loss: 0.1537 - val_binary_accuracy: 0.9856 - 8s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 8s - loss: 1.6965e-06 - binary_accuracy: 1.0000 - val_loss: 0.1461 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 8s - loss: 1.3002e-06 - binary_accuracy: 1.0000 - val_loss: 0.1452 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 8s - loss: 1.3866e-06 - binary_accuracy: 1.0000 - val_loss: 0.1466 - val_binary_accuracy: 0.9851 - 8s/epoch - 122ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 8s - loss: 2.8229e-06 - binary_accuracy: 1.0000 - val_loss: 0.1434 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 8s - loss: 2.1405e-06 - binary_accuracy: 1.0000 - val_loss: 0.1553 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 8s - loss: 5.0999e-06 - binary_accuracy: 1.0000 - val_loss: 0.1532 - val_binary_accuracy: 0.9865 - 8s/epoch - 120ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 8s - loss: 8.8828e-07 - binary_accuracy: 1.0000 - val_loss: 0.1471 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 8s - loss: 1.8569e-04 - binary_accuracy: 0.9999 - val_loss: 0.1401 - val_binary_accuracy: 0.9864 - 8s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 8s - loss: 2.0032e-05 - binary_accuracy: 1.0000 - val_loss: 0.1352 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 8s - loss: 2.1778e-05 - binary_accuracy: 1.0000 - val_loss: 0.1359 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 8s - loss: 9.7974e-06 - binary_accuracy: 1.0000 - val_loss: 0.1298 - val_binary_accuracy: 0.9854 - 8s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 8s - loss: 2.4890e-06 - binary_accuracy: 1.0000 - val_loss: 0.1342 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 8s - loss: 9.0142e-06 - binary_accuracy: 1.0000 - val_loss: 0.1401 - val_binary_accuracy: 0.9856 - 8s/epoch - 122ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 8s - loss: 1.2726e-05 - binary_accuracy: 1.0000 - val_loss: 0.1332 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 8s - loss: 2.0502e-06 - binary_accuracy: 1.0000 - val_loss: 0.1350 - val_binary_accuracy: 0.9856 - 8s/epoch - 122ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 8s - loss: 2.5017e-06 - binary_accuracy: 1.0000 - val_loss: 0.1407 - val_binary_accuracy: 0.9856 - 8s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 8s - loss: 4.7137e-06 - binary_accuracy: 1.0000 - val_loss: 0.1344 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 8s - loss: 1.0045e-06 - binary_accuracy: 1.0000 - val_loss: 0.1381 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 8s - loss: 8.1497e-06 - binary_accuracy: 1.0000 - val_loss: 0.1351 - val_binary_accuracy: 0.9871 - 8s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 8s - loss: 2.0986e-06 - binary_accuracy: 1.0000 - val_loss: 0.1345 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 8s - loss: 1.3641e-06 - binary_accuracy: 1.0000 - val_loss: 0.1366 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 8s - loss: 5.4115e-06 - binary_accuracy: 1.0000 - val_loss: 0.1457 - val_binary_accuracy: 0.9858 - 8s/epoch - 122ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 8s - loss: 8.8655e-07 - binary_accuracy: 1.0000 - val_loss: 0.1443 - val_binary_accuracy: 0.9856 - 8s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 8s - loss: 1.2400e-06 - binary_accuracy: 1.0000 - val_loss: 0.1419 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 8s - loss: 7.2896e-07 - binary_accuracy: 1.0000 - val_loss: 0.1403 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 8s - loss: 1.2013e-06 - binary_accuracy: 1.0000 - val_loss: 0.1371 - val_binary_accuracy: 0.9864 - 8s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 8s - loss: 4.6930e-07 - binary_accuracy: 1.0000 - val_loss: 0.1503 - val_binary_accuracy: 0.9862 - 8s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 8s - loss: 1.3042e-06 - binary_accuracy: 1.0000 - val_loss: 0.1458 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 8s - loss: 5.3028e-07 - binary_accuracy: 1.0000 - val_loss: 0.1338 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 8s - loss: 7.6287e-07 - binary_accuracy: 1.0000 - val_loss: 0.1552 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 8s - loss: 3.1839e-07 - binary_accuracy: 1.0000 - val_loss: 0.1443 - val_binary_accuracy: 0.9857 - 8s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 8s - loss: 8.1751e-07 - binary_accuracy: 1.0000 - val_loss: 0.1497 - val_binary_accuracy: 0.9857 - 8s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 8s - loss: 2.6398e-06 - binary_accuracy: 1.0000 - val_loss: 0.1438 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 8s - loss: 1.1796e-06 - binary_accuracy: 1.0000 - val_loss: 0.1448 - val_binary_accuracy: 0.9869 - 8s/epoch - 121ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 8s - loss: 1.3846e-06 - binary_accuracy: 1.0000 - val_loss: 0.1422 - val_binary_accuracy: 0.9860 - 8s/epoch - 121ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 8s - loss: 3.7225e-07 - binary_accuracy: 1.0000 - val_loss: 0.1553 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 8s - loss: 1.0977e-04 - binary_accuracy: 1.0000 - val_loss: 0.1520 - val_binary_accuracy: 0.9860 - 8s/epoch - 120ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 8s - loss: 1.1522e-04 - binary_accuracy: 1.0000 - val_loss: 0.1381 - val_binary_accuracy: 0.9865 - 8s/epoch - 121ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 8s - loss: 1.9062e-05 - binary_accuracy: 1.0000 - val_loss: 0.1436 - val_binary_accuracy: 0.9867 - 8s/epoch - 121ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 8s - loss: 2.2387e-05 - binary_accuracy: 1.0000 - val_loss: 0.1460 - val_binary_accuracy: 0.9854 - 8s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 8s - loss: 4.0115e-05 - binary_accuracy: 1.0000 - val_loss: 0.1517 - val_binary_accuracy: 0.9856 - 8s/epoch - 122ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 8s - loss: 2.2305e-06 - binary_accuracy: 1.0000 - val_loss: 0.1525 - val_binary_accuracy: 0.9851 - 8s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 8s - loss: 4.4840e-06 - binary_accuracy: 1.0000 - val_loss: 0.1556 - val_binary_accuracy: 0.9854 - 8s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 8s - loss: 2.8155e-05 - binary_accuracy: 1.0000 - val_loss: 0.1503 - val_binary_accuracy: 0.9862 - 8s/epoch - 121ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 8s - loss: 1.4228e-04 - binary_accuracy: 1.0000 - val_loss: 0.1527 - val_binary_accuracy: 0.9854 - 8s/epoch - 121ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 8s - loss: 5.1164e-05 - binary_accuracy: 1.0000 - val_loss: 0.1429 - val_binary_accuracy: 0.9850 - 8s/epoch - 121ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 8s - loss: 1.3591e-04 - binary_accuracy: 1.0000 - val_loss: 0.1737 - val_binary_accuracy: 0.9850 - 8s/epoch - 121ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 8s - loss: 1.3654e-05 - binary_accuracy: 1.0000 - val_loss: 0.1462 - val_binary_accuracy: 0.9858 - 8s/epoch - 120ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 8s - loss: 1.0410e-05 - binary_accuracy: 1.0000 - val_loss: 0.1473 - val_binary_accuracy: 0.9861 - 8s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 8s - loss: 6.7379e-06 - binary_accuracy: 1.0000 - val_loss: 0.1558 - val_binary_accuracy: 0.9861 - 8s/epoch - 121ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 8s - loss: 3.1269e-06 - binary_accuracy: 1.0000 - val_loss: 0.1603 - val_binary_accuracy: 0.9858 - 8s/epoch - 121ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  1.0\n",
      "binary_accuracy validation:  0.9858332872390747\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049023286\n",
      "train attribution time:  378.06775069236755\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.037882026\n",
      "validation attribution time:  39.586944341659546\n",
      "time:  2726.616016149521\n",
      "----- loop 47 :  [1649]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  66.83804845809937\n"
     ]
    }
   ],
   "source": [
    "class TestTranslate(unittest.TestCase):\n",
    "\n",
    "    def test_translate(self):\n",
    "\n",
    "        s1 = 100\n",
    "        s2 = 100\n",
    "        s3 = 100\n",
    "        new_model = newmodel(model)\n",
    "        # method = 'riemann_left', 'riemann_right', 'riemann_middle', 'riemann_trapezoid', 'gausslegendre'\n",
    "        n_steps = 6\n",
    "        ig  = IntegratedGradients1(new_model,\n",
    "                    layer=new_model.layers[1],\n",
    "                    n_steps=n_steps,\n",
    "                    method='riemann_trapezoid',\n",
    "                    internal_batch_size=32)\n",
    "        type_weight = 1\n",
    "        learning_rate_value = 0.0001\n",
    "        batch_size_num = 32\n",
    "        epochs_value = 100\n",
    "        losses = {\"classifier_model\": \"binary_crossentropy\"}\n",
    "        lossWeights = {\"classifier_model\": type_weight}\n",
    "        metrics = {\"classifier_model\": \"binary_accuracy\"}\n",
    "        alpha = 0.5\n",
    "        eta = 0.5\n",
    "        print('Start: ', get_gpu_memory())\n",
    "        for i in range(100):\n",
    "            print('----- loop', i, ': ', get_gpu_memory(), ' -----')\n",
    "            start = time.time()\n",
    "        #---產生資料---\n",
    "            # --- train data---\n",
    "            print('########## train data ##########')\n",
    "            start_train = time.time()\n",
    "            start_delta_l = time.time()\n",
    "            for b in range(0,num_train,s1):\n",
    "                e = b + s1\n",
    "                if e>num_train: e = num_train\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('xtrain[b:e] shape: ', xtrain[b:e].shape) #(s,1001,32)\n",
    "                #print('ytrain[b:e] shape: ', ytrain[b:e].shape) #(s,36)\n",
    "\n",
    "                # delta_l = -alpha * grad_loss\n",
    "                with tf.GradientTape() as g:\n",
    "                    x = xtrain[b:e]\n",
    "                    y = ytrain[b:e]\n",
    "                    g.watch(x)\n",
    "                    y_true = y\n",
    "                    y_pred = new_model(x)\n",
    "                    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "                    #print('loss: ', loss)\n",
    "                gt = g.gradient(loss, x)\n",
    "                #print('gt: ', gt)\n",
    "                delta_l = -alpha * gt\n",
    "                #print('delta_l shape: ', delta_l.shape) #(s,1001,32)\n",
    "                newtrain[b:e] = xtrain[b:e] + delta_l\n",
    "            end_delta_l = time.time()\n",
    "            print('train data delta_l time: ', end_delta_l-start_delta_l)\n",
    "\n",
    "            start_delta_a = time.time()\n",
    "            for b in range(0,num_train,s2):\n",
    "                e = b + s2\n",
    "                if e>num_train: e = num_train\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('xtrain[b:e] shape: ', xtrain[b:e].shape) #(s,1001,32)\n",
    "                #print('ytrain[b:e] shape: ', ytrain[b:e].shape) #(s,36)\n",
    "\n",
    "                # delta_a = -eta * ( attrx - attrx_ ) * attrx_gradient\n",
    "                x = np.asarray(xtrain).astype('float32')\n",
    "                predictions = new_model(xtrain[b:e]).numpy()\n",
    "                #print('86: ', get_gpu_memory())\n",
    "                explanation = ig.explain(x[b:e], baselines=None, target=predictions, attribute_to_layer_inputs=False).attributions[0]\n",
    "                #print('88: ', get_gpu_memory())\n",
    "                attrx = explanation\n",
    "                #print('attrx shape: ', attrx.shape) #(s,1001,32)\n",
    "                attrx_ = xtrain_attr[b:e]\n",
    "                #print('attrx_ shape: ', attrx_.shape) #(s,1001,32)\n",
    "                mk = ig._mk()\n",
    "                #attrx_gradient = attrx_grad(xtrain[b:e], attrx, mk, new_model, n_steps)\n",
    "                zk_grad_x = attrx / xtrain[b:e]\n",
    "                zk_grad2_zk = 0\n",
    "                for j in range(n_steps):\n",
    "                    zk = xtrain[b:e] * mk[j]\n",
    "                    with tf.GradientTape() as g:\n",
    "                        x = xtrain[b:e]\n",
    "                        g.watch(x)\n",
    "                        with tf.GradientTape() as gg:\n",
    "                            gg.watch(x)\n",
    "                            loss = new_model(x)\n",
    "                        ggt = gg.gradient(loss, x)\n",
    "                    gt = g.gradient(ggt, x)\n",
    "                    ans = gt * (mk[j] * mk[j])\n",
    "                    zk_grad2_zk += ans\n",
    "                attrx_gradient = zk_grad_x + (xtrain[b:e]/n_steps) + zk_grad2_zk\n",
    "                #print('attrx_gradient shape: ', attrx_gradient.shape) #(s,1001,32)\n",
    "                delta_a = -eta * ( attrx - attrx_ ) * attrx_gradient\n",
    "                #print('delta_a shape: ', delta_a.shape) #(s,1001,32)\n",
    "                newtrain[b:e] = newtrain[b:e] + delta_a\n",
    "            end_delta_a = time.time()\n",
    "            print('train data delta_a time: ', end_delta_a-start_delta_a)\n",
    "            #saveTestTrainData('D:/00/train.npy', newx0)\n",
    "            #print(newx)\n",
    "            end_train = time.time()\n",
    "            print('train data time: ', end_train-start_train)\n",
    "            '''\n",
    "            new_model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "            x = np.asarray(newtrain).astype('float32')\n",
    "            y = np.asarray(ytrain[0:num_train]).astype('float32')\n",
    "            new_model.evaluate(x, y)\n",
    "            '''\n",
    "\n",
    "            # --- validation data ---\n",
    "            print('########## validation data ##########')\n",
    "            start_validation = time.time()\n",
    "            start_delta_l = time.time()\n",
    "            for b in range(0,num_validation,s1):\n",
    "                e = b + s1\n",
    "                if e>num_validation: e = num_validation\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('xvalidation[b:e] shape: ', xvalidation[b:e].shape) #(s,1001,32)\n",
    "                #print('yvalidation[b:e] shape: ', yvalidation[b:e].shape) #(s,36)\n",
    "\n",
    "                # delta_l = -alpha * grad_loss\n",
    "                with tf.GradientTape() as g:\n",
    "                    x = xvalidation[b:e]\n",
    "                    y = yvalidation[b:e]\n",
    "                    g.watch(x)\n",
    "                    y_true = y\n",
    "                    y_pred = new_model(x)\n",
    "                    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "                    #print('loss: ', loss)\n",
    "                #print('149: ', get_gpu_memory())\n",
    "                gt = g.gradient(loss, x)\n",
    "                #print('151: ', get_gpu_memory())\n",
    "                #print('gt: ', gt)\n",
    "                delta_l = -alpha * gt\n",
    "                #print('delta_l shape: ', delta_l.shape) #(s,1001,32)\n",
    "                newvalidation[b:e] = xvalidation[b:e] + delta_l\n",
    "            end_delta_l = time.time()\n",
    "            print('validation data delta_l time: ', end_delta_l-start_delta_l)\n",
    "\n",
    "            start_delta_a = time.time()\n",
    "            for b in range(0,num_validation,s2):\n",
    "                e = b + s2\n",
    "                if e>num_validation: e = num_validation\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('xvalidation[b:e] shape: ', xvalidation[b:e].shape) #(s,1001,32)\n",
    "                #print('yvalidation[b:e] shape: ', yvalidation[b:e].shape) #(s,36)\n",
    "\n",
    "                # delta_a = -eta * ( attrx - attrx_ ) * attrx_gradient\n",
    "                x = np.asarray(xvalidation).astype('float32')\n",
    "                predictions = new_model(xvalidation[b:e]).numpy()\n",
    "                #print('166: ', get_gpu_memory())\n",
    "                explanation = ig.explain(x[b:e], baselines=None, target=predictions, attribute_to_layer_inputs=False).attributions[0]\n",
    "                #print('168: ', get_gpu_memory())\n",
    "                attrx = explanation\n",
    "                #print('attrx shape: ', attrx.shape) #(s,1001,32)\n",
    "                attrx_ = xvalidation_attr[b:e]\n",
    "                #print('attrx_ shape: ', attrx_.shape) #(s,1001,32)\n",
    "                mk = ig._mk()\n",
    "                #attrx_gradient = attrx_grad(xvalidation[b:e], attrx, mk, new_model, n_steps)\n",
    "                zk_grad_x = attrx / xvalidation[b:e]\n",
    "                zk_grad2_zk = 0\n",
    "                for j in range(n_steps):\n",
    "                    zk = xvalidation[b:e] * mk[j]\n",
    "                    with tf.GradientTape() as g:\n",
    "                        x = xvalidation[b:e]\n",
    "                        g.watch(x)\n",
    "                        with tf.GradientTape() as gg:\n",
    "                            gg.watch(x)\n",
    "                            loss = new_model(x)\n",
    "                        ggt = gg.gradient(loss, x)\n",
    "                    gt = g.gradient(ggt, x)\n",
    "                    ans = gt * (mk[j] * mk[j])\n",
    "                    zk_grad2_zk += ans\n",
    "                attrx_gradient = zk_grad_x + (xvalidation[b:e]/n_steps) + zk_grad2_zk\n",
    "                #print('attrx_gradient shape: ', attrx_gradient.shape) #(s,1001,32)\n",
    "                delta_a = -eta * ( attrx - attrx_ ) * attrx_gradient\n",
    "                #print('delta_a shape: ', delta_a.shape) #(s,1001,32)\n",
    "                newvalidation[b:e] = newvalidation[b:e] + delta_a\n",
    "            end_delta_a = time.time()\n",
    "            print('validation data delta_a time: ', end_delta_a-start_delta_a)\n",
    "            #saveTestvalidationData('D:/00/validation.npy', newx0)\n",
    "            #print(newx)\n",
    "            end_validation = time.time()\n",
    "            print('validation data time: ', end_validation-start_validation)\n",
    "            '''\n",
    "            new_model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "            x = np.asarray(newvalidation).astype('float32')\n",
    "            y = np.asarray(yvalidation[0:num_validation]).astype('float32')\n",
    "            new_model.evaluate(x, y)\n",
    "            '''\n",
    "\n",
    "        #----- training new model -----\n",
    "            print('########## training new model ##########')\n",
    "            xtrain0 = xtrain[0:num_train]\n",
    "            ytrain0 = ytrain[0:num_train]\n",
    "            x_train = np.concatenate((xtrain0, newtrain), axis=0)\n",
    "            x_train = np.asarray(x_train).astype('float32')\n",
    "            y_train = np.concatenate((ytrain0, ytrain0), axis=0)\n",
    "            xvalidation0 = xvalidation[0:num_validation]\n",
    "            yvalidation0 = yvalidation[0:num_validation]\n",
    "            x_validation = np.concatenate((xvalidation0, newvalidation), axis=0)\n",
    "            x_validation = np.asarray(x_validation).astype('float32')\n",
    "            y_validation = np.concatenate((yvalidation0, yvalidation0), axis=0)\n",
    "            #print('x_train shape: ', x_train.shape) #(num_train*2,1001,32)\n",
    "            #print('y_train shape: ', y_train.shape) #(num_train*2,36)\n",
    "            #print('x_validation shape: ', x_validation.shape) #(num_validation*2,1001,32)\n",
    "            #print('y_validation shape: ', y_validation.shape) #(num_validation*2,36)\n",
    "            new_model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "\n",
    "            history = new_model.fit(\n",
    "                          x = x_train,\n",
    "                          y = y_train,\n",
    "                          epochs = epochs_value, #100 200 500 3000\n",
    "                          verbose = 2, #set visibility\n",
    "                          #callbacks = [model_checkpoint_callback],\n",
    "                          validation_data = (x_validation, y_validation), #-> has issue \n",
    "                          batch_size = batch_size_num\n",
    "                          )\n",
    "\n",
    "        #----- binary acc & mse -----\n",
    "            print('########## binary acc & mse ##########')\n",
    "\n",
    "            binary_acc_train .append(history.history['binary_accuracy'][epochs_value-1])\n",
    "            binary_acc_validation .append(history.history['val_binary_accuracy'][epochs_value-1])\n",
    "            print('binary_accuracy train: ', history.history['binary_accuracy'][epochs_value-1])\n",
    "            print('binary_accuracy validation: ', history.history['val_binary_accuracy'][epochs_value-1])\n",
    "\n",
    "            # ---- attribution train -----\n",
    "            print('---- attribution train -----')\n",
    "            start_att = time.time()\n",
    "            for b in range(0,num_train*2,s3):\n",
    "                e = b + s3\n",
    "                if e>num_train*2: e = num_train*2\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('x_train[b:e] shape: ', x_train[b:e].shape)\n",
    "                #print('y_train[b:e] shape: ', y_train[b:e].shape)\n",
    "\n",
    "                predictions = y_train[b:e]\n",
    "                #print('254: ', get_gpu_memory())\n",
    "                explanation = ig.explain(x_train[b:e], baselines=None, target=predictions, attribute_to_layer_inputs=False)\n",
    "                #print('256: ', get_gpu_memory())\n",
    "                attr_train[b:e] = explanation.attributions[0]\n",
    "\n",
    "            attr_train_pred = tf.abs(attr_train)\n",
    "            attr_train_pred = tf.reduce_sum(attr_train_pred, axis=2).numpy()/32\n",
    "            #print('attr_train_pred shape: ', attr_train_pred.shape) #(num_train*2,1001)\n",
    "            attr_train_true = xtrain_attr[0:num_train]\n",
    "            attr_train_true = tf.reduce_sum(attr_train_true, axis=2).numpy()/32\n",
    "            attr_train_true = tf.concat([attr_train_true, attr_train_true], 0)\n",
    "            #print('attr_train_true shape: ', attr_train_true.shape) #(num_train*2,1001)\n",
    "            #average = tf.reduce_sum(attrx_pred, axis=1).numpy()/1001\n",
    "            #print('average: ', average)\n",
    "            mse = tf.keras.losses.MeanSquaredError()\n",
    "            attr_mse = mse(attr_train_true, attr_train_pred).numpy()\n",
    "            attr_mse_train.append(attr_mse)\n",
    "            print('attr_mse train: ', attr_mse)\n",
    "            end_att = time.time()\n",
    "            print('train attribution time: ', end_att-start_att)\n",
    "            # ---- attributoin validation -----\n",
    "            print('---- attribution validation -----')\n",
    "            start_att = time.time()\n",
    "            for b in range(0,num_validation*2,s3):\n",
    "                e = b + s3\n",
    "                if e>num_validation*2: e = num_validation*2\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('x_validation[b:e] shape: ', x_validation[b:e].shape)\n",
    "                #print('y_validation[b:e] shape: ', y_validation[b:e].shape)\n",
    "\n",
    "                predictions = y_validation[b:e]\n",
    "                #print('285: ', get_gpu_memory())\n",
    "                explanation = ig.explain(x_validation[b:e], baselines=None, target=predictions, attribute_to_layer_inputs=False)\n",
    "                #print('287: ', get_gpu_memory())\n",
    "                attr_validation[b:e] = explanation.attributions[0]\n",
    "            attr_validation_pred = tf.abs(attr_validation)\n",
    "            attr_validation_pred = tf.reduce_sum(attr_validation_pred, axis=2).numpy()/32\n",
    "            #print('attr_validation_pred shape: ', attr_validation_pred.shape) #(num_validation*2,1001)\n",
    "            attr_validation_true = xvalidation_attr[0:num_validation]\n",
    "            attr_validation_true = tf.reduce_sum(attr_validation_true, axis=2).numpy()/32\n",
    "            attr_validation_true = tf.concat([attr_validation_true, attr_validation_true], 0)\n",
    "            #print('attr_validation_true shape: ', attr_validation_true.shape) #(num_validation*2,1001)\n",
    "            mse = tf.keras.losses.MeanSquaredError()\n",
    "            attr_mse = mse(attr_validation_true, attr_validation_pred).numpy()\n",
    "            attr_mse_validation.append(attr_mse)\n",
    "            print('attr_mse validation: ', attr_mse)\n",
    "            end_att = time.time()\n",
    "            print('validation attribution time: ', end_att-start_att)\n",
    "            end = time.time()\n",
    "            print('time: ', end-start)\n",
    "        plotAttributionAcc(attr_mse_train)\n",
    "        print('----- train acc -----')\n",
    "        print('binary_acc_train: ', binary_acc_train)\n",
    "        print('attr_mse_train: ', attr_mse_train)\n",
    "        print('----- validation acc -----')\n",
    "        print('binary_acc_validation: ', binary_acc_validation)\n",
    "        print('attr_mse_validation: ', attr_mse_validation)\n",
    "            #print(\"Model training completed...\")\n",
    "            #save history\n",
    "            #print(\"Saving history...\")\n",
    "            saveDictionary(history.history, Trained_model_Path + \"/\" + \"model_history\")\n",
    "            #print(\"History saving completed...\")\n",
    "\n",
    "            #save model\n",
    "            #print(\"Saving model...\")\n",
    "            new_model.save(Trained_model_Path + \"/\" + \"test_model1.h5\")\n",
    "            #print(\"Model saving completed...\")\n",
    "\n",
    "x=TestTranslate()\n",
    "x.test_translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "# Data\n",
    "x1 = loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Max-len-1000/x_train[0]_0.npy')\n",
    "x2 = loadTestTrainData('D:/00/train.npy')\n",
    "x1 = np.asarray(x1)\n",
    "x2 = np.asarray(x2).astype('float32')\n",
    "print('x1 shape: ', x1.shape)\n",
    "print('x2 shape: ', x2.shape)\n",
    "y0 = list(loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Max-len-1000/y_train[0]_0.npy'))\n",
    "y0 = np.asarray(y0)\n",
    "print('y0 shape: ', y0.shape)\n",
    "# model\n",
    "new_model = newmodel(model)\n",
    "type_weight = 1\n",
    "learning_rate_value = 0.0001\n",
    "batch_size_num = 32\n",
    "epochs_value = 10\n",
    "losses = {\"classifier_model\": \"binary_crossentropy\"}\n",
    "lossWeights = {\"classifier_model\": type_weight}\n",
    "metrics = {\"classifier_model\": \"binary_accuracy\"}\n",
    "# evaluate\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "new_model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "result1 = model.evaluate(x1, y0)\n",
    "result2 = new_model.evaluate(x2, y0)\n",
    "print('result1: ', result1)\n",
    "print('result2: ', result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1674]\n"
     ]
    }
   ],
   "source": [
    "print(get_gpu_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "achZsSjjc6hw",
    "U4NG1PGqXQkm"
   ],
   "name": "attribution_train_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
