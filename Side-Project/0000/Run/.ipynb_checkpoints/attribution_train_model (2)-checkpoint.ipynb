{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "achZsSjjc6hw"
   },
   "source": [
    "# 安裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62WsE2_OblO2",
    "outputId": "b6780e6d-dbd0-4536-c6ed-1608cd94d5c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-pos-embd in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from keras-pos-embd) (1.21.5)\n",
      "Requirement already satisfied: keras-multi-head in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (0.29.0)\n",
      "Requirement already satisfied: keras-self-attention==0.51.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from keras-multi-head) (0.51.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from keras-self-attention==0.51.0->keras-multi-head) (1.21.5)\n",
      "Requirement already satisfied: keras-layer-normalization in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from keras-layer-normalization) (1.21.5)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from keras-position-wise-feed-forward) (1.21.5)\n",
      "Requirement already satisfied: keras-embed-sim in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from keras-embed-sim) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: alibi in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (1.4.2)\n",
      "Requirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (3.3.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (2.27.1)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.22.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (1.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.7.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (4.20.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (4.64.0)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (0.3.5.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (1.21.5)\n",
      "Requirement already satisfied: Pillow<10.0,>=5.4.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (9.0.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.1.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (1.7.3)\n",
      "Requirement already satisfied: attrs<22.0.0,>=19.2.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (21.4.0)\n",
      "Requirement already satisfied: scikit-image!=0.17.1,<0.20,>=0.14.2 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (0.19.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (4.1.1)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from alibi) (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from pandas<2.0.0,>=0.23.3->alibi) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi) (2021.10.8)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2021.7.2)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (2.7.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from scikit-image!=0.17.1,<0.20,>=0.14.2->alibi) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=0.22.0->alibi) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=0.22.0->alibi) (2.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.0.17)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (61.2.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.11.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.7.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.4.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (0.6.2)\n",
      "Requirement already satisfied: spacy-lookups-data<1.1.0,>=1.0.3 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi) (1.0.3)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy[lookups]<4.0.0,>=2.0.0->alibi) (5.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.28.1->alibi) (0.4.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.7.0->alibi) (0.8.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy[lookups]<4.0.0,>=2.0.0->alibi) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (from jinja2->spacy[lookups]<4.0.0,>=2.0.0->alibi) (2.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-ml-py3 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (7.352.0)\n",
      "Requirement already satisfied: nvidia-ml-py3 in c:\\users\\w.r_chen\\anaconda3\\lib\\site-packages (7.352.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-pos-embd\n",
    "!pip install keras-multi-head\n",
    "!pip install keras-layer-normalization\n",
    "!pip install keras-position-wise-feed-forward\n",
    "!pip install keras-embed-sim\n",
    "!pip install matplotlib\n",
    "!pip install alibi\n",
    "!pip install nvidia-ml-py3\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6T3lB0BWKKEf"
   },
   "source": [
    "# #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKJ7DZipcBw4",
    "outputId": "c585973a-69b6-41a7-c295-41669d4631cd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#drive_path = 'C:/模型 ver. 2/encoder_num=4, decoder_num=4/embed_dim=' + Embed_Dim + '/head_num=' + Head_Num + '/learning_rate=' + Learning_Rate + '/lossWeights_1-' + LossWeights + '/'\n",
    "drive_path = 'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LHUD7liWc434"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_KERAS']= \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "twUnzwRtdBXN"
   },
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "import sys\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/Men-len-1000')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/甲班模型')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/performer')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/performer/keras_position_wise_feed_forward')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/performer/tensorflow_fast_attention')\n",
    "sys.path.append(r'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/performer/keras_performer')\n",
    "from alibi.explainers import IntegratedGradients\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import pynvml\n",
    "from keras_performer import performer_ver_3 as tfr\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ftrZJUOjlJQC"
   },
   "outputs": [],
   "source": [
    "def saveTestTrainData(filename, data): # e.g., 'test.npy'\n",
    "  with open(filename, 'wb') as f:\n",
    "    np.save(f, data)\n",
    "\n",
    "def saveDictionary(dt, file):\n",
    "    import pickle\n",
    "    a_file = open(file, \"wb\")\n",
    "    pickle.dump(dt, a_file)\n",
    "    a_file.close()\n",
    "\n",
    "def loadDictionary(file):\n",
    "    import pickle\n",
    "    a_file = open(file, \"rb\")\n",
    "    dt = pickle.load(a_file)\n",
    "    return dt\n",
    "\n",
    "        \n",
    "def loadMaxLen(filename):     \n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        return lines\n",
    "    \n",
    "def plotTrainingLoss(history):\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right') \n",
    "    plt.show()\n",
    "\n",
    "def plotAttributionAcc(attr_mse_train):\n",
    "    plt.plot(attr_mse_train)\n",
    "    plt.title('model Attribution accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('loop')\n",
    "    plt.legend(['accuracy'], loc='upper left') \n",
    "    plt.show()\n",
    "def plotTrainingAcc(history):\n",
    "    plt.plot(history['sparse_categorical_accuracy'])\n",
    "    plt.plot(history['val_sparse_categorical_accuracy'])\n",
    "    plt.title('model Decoder-Output accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['accuracy', 'val_accuracy'], loc='upper left') \n",
    "    plt.show()\n",
    "    \n",
    "def loadTestTrainData(filename): # e.g., 'test.npy'    \n",
    "    with open(filename, 'rb') as f:\n",
    "        a = np.load(f, allow_pickle=True)\n",
    "        return a    \n",
    "def plotTrainingEFFOLoss(history):\n",
    "    plt.plot(history.history['error_feed_forward_output1_loss'])\n",
    "    plt.plot(history.history['val_error_feed_forward_output1_loss'])\n",
    "    plt.title('model error_feed_forward_output1 loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right') \n",
    "    plt.show()\n",
    "    \n",
    "def plotTrainingDOLoss(history):\n",
    "    plt.plot(history.history['Decoder-Output_loss'])\n",
    "    plt.plot(history.history['val_Decoder-Output_loss'])\n",
    "    plt.title('model Decoder-Output loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'val_loss'], loc='upper right') \n",
    "    plt.show()\n",
    "    \n",
    "def plotTrainingEFFOBinAcc(history):\n",
    "    plt.plot(history.history['error_feed_forward_output1_binary_accuracy'])\n",
    "    plt.plot(history.history['val_error_feed_forward_output1_binary_accuracy'])\n",
    "    plt.title('model error_feed_forward_output1 binary_accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['accuracy', 'val_accuracy'], loc='upper left') \n",
    "    plt.show()\n",
    "    \n",
    "def plotTrainingDOAcc(history):\n",
    "    plt.plot(history.history['Decoder-Output_sparse_categorical_accuracy'])\n",
    "    plt.plot(history.history['val_Decoder-Output_sparse_categorical_accuracy'])\n",
    "    plt.title('model Decoder-Output accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['accuracy', 'val_accuracy'], loc='upper left') \n",
    "    plt.show()\n",
    "    \n",
    "def myAcc(y_true, y_pred):#not necessarily used\n",
    "    global p_msg\n",
    "    tf.config.run_functions_eagerly(True) \n",
    "    #tf.print(\"y_true:\", y_true, output_stream=sys.stderr)\n",
    "    #tf.print(\"y_pred:\", y_pred, output_stream=sys.stderr)\n",
    "    #t_msg = y_true.numpy().tolist()\n",
    "    p_msg = y_pred #.numpy().tolist()\n",
    "    \n",
    "    acc = K.cast(K.equal(K.max(y_true, axis=-1),\n",
    "        K.cast(K.argmax(y_pred, axis=-1), K.floatx())),\n",
    "        K.floatx())\n",
    "    #print(\"metric acc:\" , acc)\n",
    "    return acc\n",
    "\n",
    "def newmodel(model):\n",
    "    inp = model.layers[2].input\n",
    "    opt = model.output\n",
    "    new_model = keras.models.Model(inputs = [inp], outputs = [opt])\n",
    "    return new_model\n",
    "\n",
    "def grad(sample, model):\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(sample)\n",
    "        loss = model(sample)\n",
    "        target = tf.reduce_max(loss, axis=1, keepdims = True)\n",
    "    gt = g.gradient(target, sample)  \n",
    "    return gt\n",
    "\n",
    "def grad2(sample, model):\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(sample)\n",
    "        with tf.GradientTape() as gg:\n",
    "            gg.watch(sample)\n",
    "            loss = model(sample)\n",
    "        ggt = gg.gradient(loss, sample)\n",
    "    gt = g.gradient(ggt, sample)\n",
    "    return gt\n",
    "\n",
    "def attrx_grad(sample, ig, mk, new_model, n_steps):\n",
    "    zk_grad_x = ig / sample\n",
    "    #print('zk_grad_x shape:', zk_grad_x.shape)\n",
    "    \n",
    "    zk_grad2_zk = 0\n",
    "    for i in range(n_steps):\n",
    "        #zk = x * mk\n",
    "        zk = sample * mk[i]\n",
    "        ans = grad2(zk, new_model) * (mk[i] * mk[i])\n",
    "        zk_grad2_zk += ans\n",
    "    #print('zk_grad2_zk shape: ', zk_grad2_zk.shape)\n",
    "    attrx_grad = zk_grad_x + (sample/n_steps) + zk_grad2_zk\n",
    "    return attrx_grad\n",
    "def displayMemory():\n",
    "    import nvidia_smi\n",
    "\n",
    "    nvidia_smi.nvmlInit()\n",
    "\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    # card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "    print(\"Total memory:\", info.total)\n",
    "    print(\"Free memory:\", info.free)\n",
    "    print(\"Used memory:\", info.used)\n",
    "\n",
    "    nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4NG1PGqXQkm"
   },
   "source": [
    "# 讀取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l-X0MKCDRoGz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs:  {'name': 'self_attention_1', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_3', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_5', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_7', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_9', 'trainable': True, 'dtype': 'float32'}\n",
      "kwargs:  {'name': 'self_attention_11', 'trainable': True, 'dtype': 'float32'}\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmax_seq_len=999\\nmodel1 = tfr.get_model(\\n  max_input_len=(max_seq_len, max_seq_len), \\n  token_num=max(len(source_token_dict),len(target_token_dict)),\\n  embed_dim=32,\\n  encoder_num=6,\\n  #decoder_num=6,\\n  head_num=4,\\n  hidden_dim=128,\\n  use_same_embed=False\\n)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load(model_name):\n",
    "\n",
    "  from keras_performer import performer_ver_3\n",
    "  from tensorflow import keras\n",
    "  from keras_embed_sim import EmbeddingRet, EmbeddingSim\n",
    "  from keras_pos_embd import TrigPosEmbedding\n",
    "  from tensorflow_fast_attention.fast_attention_2 import softmax_kernel_transformation,  Attention, SelfAttention\n",
    "  from keras_position_wise_feed_forward.feed_forward import FeedForward  \n",
    "\n",
    "  co = performer_ver_3.get_custom_objects()\n",
    "  co['softmax_kernel_transformation']= softmax_kernel_transformation\n",
    "  path = 'D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000//甲班模型/'\n",
    "  model = keras.models.load_model(path + model_name, custom_objects= co)\n",
    "  s = loadDictionary(path + 'source_token_dict.pickle')\n",
    "  t = loadDictionary(path + 'target_token_dict.pickle')\n",
    "  t_inv = loadDictionary(path + 'target_token_dict_inv.pickle')\n",
    "  return model, s, t, t_inv\n",
    "\n",
    "def loadTestTrainData(filename): # e.g., 'test.npy'    \n",
    "  with open(filename, 'rb') as f:\n",
    "    a = np.load(f, allow_pickle=True)\n",
    "    return a\n",
    "model, source_token_dict, target_token_dict, target_token_dict_inv = load(\"model.h5\")\n",
    "#model.summary()\n",
    "'''\n",
    "max_seq_len=999\n",
    "model1 = tfr.get_model(\n",
    "  max_input_len=(max_seq_len, max_seq_len), \n",
    "  token_num=max(len(source_token_dict),len(target_token_dict)),\n",
    "  embed_dim=32,\n",
    "  encoder_num=6,\n",
    "  #decoder_num=6,\n",
    "  head_num=4,\n",
    "  hidden_dim=128,\n",
    "  use_same_embed=False\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from alibi.api.defaults import DEFAULT_DATA_INTGRAD, DEFAULT_META_INTGRAD\n",
    "from alibi.utils.approximation_methods import approximation_parameters\n",
    "from alibi.api.interfaces import Explainer, Explanation\n",
    "from typing import Callable, Union, List, Tuple, Optional\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "_valid_output_shape_type: List = [tuple, list]\n",
    "\n",
    "\n",
    "def _compute_convergence_delta(model: Union[tf.keras.models.Model],\n",
    "                               input_dtypes: List[tf.DType],\n",
    "                               attributions: List[np.ndarray],\n",
    "                               start_point: Union[List[np.ndarray], np.ndarray],\n",
    "                               end_point: Union[List[np.ndarray], np.ndarray],\n",
    "                               forward_kwargs: Optional[dict],\n",
    "                               target: Optional[List[int]],\n",
    "                               _is_list: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes convergence deltas for each data point. Convergence delta measures how close the sum of all attributions\n",
    "    is to the difference between the model output at the baseline and the model output at the data point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    input_dtypes\n",
    "        List with data types of the inputs.\n",
    "    attributions\n",
    "        Attributions assigned by the integrated gradients method to each feature.\n",
    "    start_point\n",
    "        Baselines.\n",
    "    end_point\n",
    "        Data points.\n",
    "    forward_kwargs\n",
    "        Input keywords args.\n",
    "    target\n",
    "        Target for which the gradients are calculated for classification models.\n",
    "    _is_list\n",
    "        Whether the model's input is a list (multiple inputs) or a np array (single input).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Convergence deltas for each data point.\n",
    "    \"\"\"\n",
    "    if _is_list:\n",
    "        start_point = [tf.convert_to_tensor(start_point[k], dtype=input_dtypes[k]) for k in range(len(input_dtypes))]\n",
    "        end_point = [tf.convert_to_tensor(end_point[k], dtype=input_dtypes[k]) for k in range(len(input_dtypes))]\n",
    "\n",
    "    else:\n",
    "        start_point = tf.convert_to_tensor(start_point)\n",
    "        end_point = tf.convert_to_tensor(end_point)\n",
    "\n",
    "    def _sum_rows(inp):\n",
    "\n",
    "        input_str = string.ascii_lowercase[1: len(inp.shape)]\n",
    "        if isinstance(inp, tf.Tensor):\n",
    "            sums = tf.einsum('a{}->a'.format(input_str), inp).numpy()\n",
    "        elif isinstance(inp, np.ndarray):\n",
    "            sums = np.einsum('a{}->a'.format(input_str), inp)\n",
    "        else:\n",
    "            raise NotImplementedError('input must be a tensorflow tensor or a numpy array')\n",
    "        return sums\n",
    "\n",
    "    start_out = _run_forward(model, start_point, target, forward_kwargs=forward_kwargs)\n",
    "    end_out = _run_forward(model, end_point, target, forward_kwargs=forward_kwargs)\n",
    "\n",
    "    if (len(model.output_shape) == 1 or model.output_shape[-1] == 1) and target is not None:\n",
    "        target_tensor = tf.cast(target, dtype=start_out.dtype)\n",
    "        target_tensor = tf.reshape(1 - target_tensor, [len(target), 1])\n",
    "        sign = 2 * target_tensor - 1\n",
    "\n",
    "        start_out = target_tensor + sign * start_out\n",
    "        end_out = target_tensor + sign * end_out\n",
    "\n",
    "    start_out_sum = _sum_rows(start_out)\n",
    "    end_out_sum = _sum_rows(end_out)\n",
    "\n",
    "    attr_sum = np.zeros(start_out_sum.shape)\n",
    "    for j in range(len(attributions)):\n",
    "        attrs_sum_j = _sum_rows(attributions[j])\n",
    "        attr_sum += attrs_sum_j\n",
    "\n",
    "    _deltas = attr_sum - (end_out_sum - start_out_sum)\n",
    "\n",
    "    return _deltas\n",
    "\n",
    "\n",
    "def _select_target(preds: tf.Tensor,\n",
    "                   targets: Union[None, tf.Tensor, np.ndarray, list]) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Select the predictions corresponding to the targets if targets is not None.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    preds\n",
    "        Predictions before selection.\n",
    "    targets\n",
    "        Targets to select.\n",
    "    Returns\n",
    "    -------\n",
    "        Selected predictions\n",
    "\n",
    "    \"\"\"\n",
    "    if targets is not None:\n",
    "        if isinstance(preds, tf.Tensor):\n",
    "            preds = tf.linalg.diag_part(tf.gather(preds, targets, axis=1))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    else:\n",
    "        raise ValueError(\"target cannot be `None` if `model` output dimensions > 1\")\n",
    "    return preds\n",
    "\n",
    "\n",
    "def _run_forward(model: Union[tf.keras.models.Model],\n",
    "                 x: Union[List[tf.Tensor], List[np.ndarray]],\n",
    "                 target: Union[None, tf.Tensor, np.ndarray, list],\n",
    "                 forward_kwargs: Optional[dict] = None) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Returns the output of the model. If the target is not `None`, only the output for the selected target is returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    x\n",
    "        Input data point.\n",
    "    target\n",
    "        Target for which the gradients are calculated for classification models.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    Returns\n",
    "    -------\n",
    "        Model output or model output after target selection for classification models.\n",
    "\n",
    "    \"\"\"\n",
    "    if forward_kwargs is None:\n",
    "        preds = model(x)\n",
    "    else:\n",
    "        preds = model(x, **forward_kwargs)\n",
    "\n",
    "    if len(model.output_shape) > 1 and model.output_shape[-1] > 1:\n",
    "        preds = _select_target(preds, target)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def _run_forward_from_layer(model: tf.keras.models.Model,\n",
    "                            layer: tf.keras.layers.Layer,\n",
    "                            orig_call: Callable,\n",
    "                            orig_dummy_input: Union[list, np.ndarray],\n",
    "                            x: tf.Tensor,\n",
    "                            target: Union[None, tf.Tensor, np.ndarray, list],\n",
    "                            forward_kwargs: Optional[dict] = None,\n",
    "                            run_from_layer_inputs: bool = False,\n",
    "                            select_target: bool = True) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Function currently unused.\n",
    "    Executes a forward call from an internal layer of the model to the model output.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    layer\n",
    "        Starting layer for the forward call.\n",
    "    orig_call\n",
    "        Original `call` method of the layer.\n",
    "    orig_dummy_input\n",
    "        Dummy input needed to initiate the model forward call. The number of instances in the dummy input must\n",
    "        be the same as the number of instances in x. The dummy input values play no role in the evaluation\n",
    "        as the  layer's status is overwritten during the forward call.\n",
    "    x\n",
    "        Layer's inputs. The layer's status is overwritten with `x` during the forward call.\n",
    "    target\n",
    "        Target for the output position to be returned.\n",
    "    forward_kwargs\n",
    "        Input keyword args. It must be a dict with numpy arrays as values. If it's not None,\n",
    "        the first dimension of the arrays must correspond to the number of instances in x and orig_dummy_input.\n",
    "    run_from_layer_inputs\n",
    "        If True, the forward pass starts from the layer's inputs, if False it starts from the layer's outputs.\n",
    "    select_target\n",
    "        Whether to return predictions for selected targets or return predictions for all targets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Model's predictions for the given target.\n",
    "\n",
    "    \"\"\"\n",
    "    def feed_layer(layer):\n",
    "        \"\"\"\n",
    "        Overwrites the intermediate layer status with the precomputed values `x`.\n",
    "\n",
    "        \"\"\"\n",
    "        def decorator(func):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                # Store the result and inputs of `layer.call` internally.\n",
    "                if run_from_layer_inputs:\n",
    "                    layer.inp = x\n",
    "                    layer.result = func(*x, **kwargs)\n",
    "                else:\n",
    "                    layer.inp = args\n",
    "                    layer.result = x\n",
    "                # Return the result to continue with the forward pass.\n",
    "                return layer.result\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        layer.call = decorator(layer.call)\n",
    "\n",
    "    feed_layer(layer)\n",
    "    if forward_kwargs is None:\n",
    "        preds = model(orig_dummy_input)\n",
    "    else:\n",
    "        preds = model(orig_dummy_input, **forward_kwargs)\n",
    "\n",
    "    delattr(layer, 'inp')\n",
    "    delattr(layer, 'result')\n",
    "    layer.call = orig_call\n",
    "\n",
    "    if select_target and len(model.output_shape) > 1 and model.output_shape[-1] > 1:\n",
    "        preds = _select_target(preds, target)\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "def _run_forward_to_layer(model: tf.keras.models.Model,\n",
    "                          layer: tf.keras.layers.Layer,\n",
    "                          orig_call: Callable,\n",
    "                          x: Union[List[np.ndarray], np.ndarray],\n",
    "                          forward_kwargs: Optional[dict] = None,\n",
    "                          run_to_layer_inputs: bool = False) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Executes a forward call from the model input to an internal layer output.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    layer\n",
    "        Starting layer for the forward call.\n",
    "    orig_call\n",
    "        Original `call` method of the layer.\n",
    "    x\n",
    "        Model's inputs.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    run_to_layer_inputs\n",
    "        If True, the layer's inputs are returned. If False, the layer's output's are returned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Output of the given layer.\n",
    "\n",
    "    \"\"\"\n",
    "    def take_layer(layer):\n",
    "        \"\"\"\n",
    "        Stores the layer's outputs internally to the layer's object.\n",
    "\n",
    "        \"\"\"\n",
    "        def decorator(func):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                # Store the result of `layer.call` internally.\n",
    "                layer.inp = args\n",
    "                layer.result = func(*args, **kwargs)\n",
    "                # Return the result to continue with the forward pass.\n",
    "                return layer.result\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        layer.call = decorator(layer.call)\n",
    "\n",
    "    # inp = tf.zeros((x.shape[0], ) + model.input_shape[1:])\n",
    "    take_layer(layer)\n",
    "    if forward_kwargs is None:\n",
    "        _ = model(x)\n",
    "    else:\n",
    "        _ = model(x, **forward_kwargs)\n",
    "    layer_inp = layer.inp\n",
    "    layer_out = layer.result\n",
    "\n",
    "    delattr(layer, 'inp')\n",
    "    delattr(layer, 'result')\n",
    "    layer.call = orig_call\n",
    "\n",
    "    if run_to_layer_inputs:\n",
    "        return layer_inp\n",
    "    else:\n",
    "        return layer_out\n",
    "\n",
    "from tensorflow.python.training.tracking.data_structures import ListWrapper\n",
    "def _forward_input_baseline(X: Union[List[np.ndarray], np.ndarray],\n",
    "                            bls: Union[List[np.ndarray], np.ndarray],\n",
    "                            model: tf.keras.Model,\n",
    "                            layer: tf.keras.layers.Layer,\n",
    "                            orig_call: Callable,\n",
    "                            forward_kwargs: Optional[dict] = None,\n",
    "                            forward_to_inputs: bool = False) -> Tuple[Union[list, tf.Tensor], Union[list, tf.Tensor]]:\n",
    "    \"\"\"\n",
    "    Forwards inputs and baselines to the layer's inputs or outputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Input data points.\n",
    "    bls\n",
    "        Baselines.\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    layer\n",
    "        Desired layer output.\n",
    "    orig_call\n",
    "        Original `call` method of layer.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    forward_to_inputs\n",
    "        If True, X and bls are forwarded to the layer's input. If False, they are forwarded to the layer's outputs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Forwarded inputs and  baselines as a numpy arrays.\n",
    "\n",
    "    \"\"\"\n",
    "    #print(\"layer: \", layer)\n",
    "    if layer is not None:\n",
    "        X_layer = _run_forward_to_layer(model,\n",
    "                                        layer,\n",
    "                                        orig_call,\n",
    "                                        X,\n",
    "                                        forward_kwargs=forward_kwargs,\n",
    "                                        run_to_layer_inputs=forward_to_inputs)\n",
    "        bls_layer = _run_forward_to_layer(model,\n",
    "                                          layer,\n",
    "                                          orig_call,\n",
    "                                          bls,\n",
    "                                          forward_kwargs=forward_kwargs,\n",
    "                                          run_to_layer_inputs=forward_to_inputs)\n",
    "\n",
    "        #print(\"bls_layer type: \", type(bls_layer))\n",
    "        #print(\"X_layer type: \", type(X_layer))\n",
    "        if isinstance(X_layer, tuple):\n",
    "            X_layer = list(X_layer)\n",
    "\n",
    "        if isinstance(bls_layer, tuple):\n",
    "            bls_layer = list(bls_layer)\n",
    "\n",
    "        return X_layer, bls_layer\n",
    "\n",
    "    else:\n",
    "        return X, bls\n",
    "\n",
    "\n",
    "def _gradients_input(model: Union[tf.keras.models.Model],\n",
    "                     x: List[tf.Tensor],\n",
    "                     target: Union[None, tf.Tensor],\n",
    "                     forward_kwargs: Optional[dict] = None) -> List[tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Calculates the gradients of the target class output (or the output if the output dimension is equal to 1)\n",
    "    with respect to each input feature.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    x\n",
    "        Input data point.\n",
    "    target\n",
    "        Target for which the gradients are calculated if the output dimension is higher than 1.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    Returns\n",
    "    -------\n",
    "        Gradients for each input feature.\n",
    "\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        preds = _run_forward(model, x, target, forward_kwargs=forward_kwargs)\n",
    "\n",
    "    grads = tape.gradient(preds, x)\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def _gradients_layer(model: Union[tf.keras.models.Model],\n",
    "                     layer: Union[tf.keras.layers.Layer],\n",
    "                     orig_call: Callable,\n",
    "                     orig_dummy_input: Union[list, np.ndarray],\n",
    "                     x: Union[List[tf.Tensor], tf.Tensor],\n",
    "                     target: Union[None, tf.Tensor],\n",
    "                     forward_kwargs: Optional[dict] = None,\n",
    "                     compute_layer_inputs_gradients: bool = False) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Calculates the gradients of the target class output (or the output if the output dimension is equal to 1)\n",
    "    with respect to each element of `layer`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Tensorflow or keras model.\n",
    "    layer\n",
    "        Layer of the model with respect to which the gradients are calculated.\n",
    "    orig_call\n",
    "        Original `call` method of the layer. This is necessary since the call method is modified by the function\n",
    "        in order to make the layer output visible to the GradientTape.\n",
    "    x\n",
    "        Input data point.\n",
    "    target\n",
    "        Target for which the gradients are calculated if the output dimension is higher than 1.\n",
    "    forward_kwargs\n",
    "        Input keyword args.\n",
    "    compute_layer_inputs_gradients\n",
    "        If True, gradients are computed with respect to the layer's inputs.\n",
    "        If False, they are computed with respect to the layer's outputs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Gradients for each element of layer.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def watch_layer(layer, tape):\n",
    "        \"\"\"\n",
    "        Make an intermediate hidden `layer` watchable by the `tape`.\n",
    "        After calling this function, you can obtain the gradient with\n",
    "        respect to the output of the `layer` by calling:\n",
    "\n",
    "            grads = tape.gradient(..., layer.result)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def decorator(func):\n",
    "            def wrapper(*args, **kwargs):\n",
    "                # Store the result and the input of `layer.call` internally.\n",
    "                if compute_layer_inputs_gradients:\n",
    "                    layer.inp = x\n",
    "                    layer.result = func(*x, **kwargs)\n",
    "                    # From this point onwards, watch this tensor.\n",
    "                    tape.watch(layer.inp)\n",
    "                else:\n",
    "                    layer.inp = args\n",
    "                    layer.result = x\n",
    "                    # From this point onwards, watch this tensor.\n",
    "                    tape.watch(layer.result)\n",
    "                # Return the result to continue with the forward pass.\n",
    "                return layer.result\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        layer.call = decorator(layer.call)\n",
    "\n",
    "    #  Repeating the dummy input needed to initiate the model's forward call in order to ensure that\n",
    "    #  the number of dummy instances is the same as the number of real instances.\n",
    "    #  This is necessary in case `forward_kwargs` is not None. In that case, the model forward call  would crash\n",
    "    #  if the number of instances in `orig_dummy_input` is different from the number of instances in `forward_kwargs`.\n",
    "    #  The number of instances in `forward_kwargs` is the same as the number of instances in `x` by construction.\n",
    "    if isinstance(orig_dummy_input, list):\n",
    "        if isinstance(x, list):\n",
    "            orig_dummy_input = [np.repeat(inp, x[0].shape[0], axis=0) for inp in orig_dummy_input]\n",
    "        else:\n",
    "            orig_dummy_input = [np.repeat(inp, x.shape[0], axis=0) for inp in orig_dummy_input]\n",
    "    else:\n",
    "        if isinstance(x, list):\n",
    "            orig_dummy_input = np.repeat(orig_dummy_input, x[0].shape[0], axis=0)\n",
    "        else:\n",
    "            orig_dummy_input = np.repeat(orig_dummy_input, x.shape[0], axis=0)\n",
    "\n",
    "    #  Calculating the gradients with respect to the layer.\n",
    "    with tf.GradientTape() as tape:\n",
    "        watch_layer(layer, tape)\n",
    "        preds = _run_forward(model, orig_dummy_input, target, forward_kwargs=forward_kwargs)\n",
    "\n",
    "    if compute_layer_inputs_gradients:\n",
    "        grads = tape.gradient(preds, layer.inp)\n",
    "    else:\n",
    "        grads = tape.gradient(preds, layer.result)\n",
    "\n",
    "    delattr(layer, 'inp')\n",
    "    delattr(layer, 'result')\n",
    "    layer.call = orig_call\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def _format_baseline(X: np.ndarray,\n",
    "                     baselines: Union[None, int, float, np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Formats baselines to return a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Input data points.\n",
    "    baselines\n",
    "        Baselines.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Formatted inputs and  baselines as a numpy arrays.\n",
    "\n",
    "    \"\"\"\n",
    "    #print(\"X.shape: \", X.shape)\n",
    "    if baselines is None:\n",
    "        bls = np.zeros(X.shape).astype(X.dtype)\n",
    "    elif isinstance(baselines, int) or isinstance(baselines, float):\n",
    "        bls = np.full(X.shape, baselines).astype(X.dtype)\n",
    "    elif isinstance(baselines, np.ndarray):\n",
    "        bls = baselines.astype(X.dtype)\n",
    "    else:\n",
    "        raise ValueError(f\"baselines must be `int`, `float`, `np.ndarray` or `None`. Found {type(baselines)}\")\n",
    "    #print(\"bls.shape: \", bls.shape)\n",
    "    return bls\n",
    "\n",
    "\n",
    "def _format_target(target: Union[None, int, list, np.ndarray],\n",
    "                   nb_samples: int) -> Union[None, List[int]]:\n",
    "    \"\"\"\n",
    "    Formats target to return a list.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target\n",
    "        Original target.\n",
    "    nb_samples\n",
    "        Number of samples in the batch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Formatted target as a list.\n",
    "\n",
    "    \"\"\"\n",
    "    if target is not None:\n",
    "        if isinstance(target, int):\n",
    "            target = [target for _ in range(nb_samples)]\n",
    "        elif isinstance(target, list) or isinstance(target, np.ndarray):\n",
    "            target = [t.astype(int) for t in target]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "def _sum_integral_terms(step_sizes: list,\n",
    "                        grads: Union[tf.Tensor, np.ndarray]) -> Union[tf.Tensor, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Sums the terms in the path integral with weights `step_sizes`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    step_sizes\n",
    "        Weights in the path integral sum.\n",
    "    grads\n",
    "        Gradients to sum for each feature.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Sums of the gradients along the chosen path.\n",
    "\n",
    "    \"\"\"\n",
    "    input_str = string.ascii_lowercase[1: len(grads.shape)]\n",
    "    if isinstance(grads, tf.Tensor):\n",
    "        step_sizes = tf.convert_to_tensor(step_sizes)\n",
    "        einstr = 'a,a{}->{}'.format(input_str, input_str)\n",
    "        sums = tf.einsum(einstr, step_sizes, grads).numpy()\n",
    "    elif isinstance(grads, np.ndarray):\n",
    "        einstr = 'a,a{}->{}'.format(input_str, input_str)\n",
    "        sums = np.einsum(einstr, step_sizes, grads)\n",
    "    else:\n",
    "        raise NotImplementedError('input must be a tensorflow tensor or a numpy array')\n",
    "    return sums\n",
    "\n",
    "\n",
    "def _calculate_sum_int(batches: List[List[tf.Tensor]],\n",
    "                       model: Union[tf.keras.Model],\n",
    "                       target: Union[None, List[int]],\n",
    "                       target_paths: np.ndarray,\n",
    "                       n_steps: int,\n",
    "                       nb_samples: int,\n",
    "                       step_sizes: List[float],\n",
    "                       j: int) -> Union[tf.Tensor, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculates the sum of all the terms in the integral from a list of batch gradients.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batches\n",
    "        List of batch gradients.\n",
    "    model\n",
    "        tf.keras or keras model.\n",
    "    target\n",
    "        List of targets.\n",
    "    target_paths\n",
    "        Targets for each path in the integral.\n",
    "    n_steps\n",
    "        Number of steps in the integral.\n",
    "    nb_samples\n",
    "        Total number of samples.\n",
    "    step_sizes\n",
    "        Step sizes used to calculate the integral.\n",
    "    j\n",
    "        Iterates through list of inputs or list of layers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    grads = tf.concat(batches[j], 0)\n",
    "    shape = grads.shape[1:]\n",
    "    if isinstance(shape, tf.TensorShape):\n",
    "        shape = tuple(shape.as_list())\n",
    "\n",
    "    # invert sign of gradients for target 0 examples if classifier returns only positive class probability\n",
    "    if (len(model.output_shape) == 1 or model.output_shape[-1] == 1) and target is not None:\n",
    "        sign = 2 * target_paths - 1\n",
    "        grads = np.asarray([s * g for s, g in zip(sign, grads)])\n",
    "\n",
    "    grads = tf.reshape(grads, (n_steps, nb_samples) + shape)\n",
    "    # sum integral terms and scale attributions\n",
    "    sum_int = _sum_integral_terms(step_sizes, grads.numpy())\n",
    "\n",
    "    return sum_int\n",
    "\n",
    "\n",
    "def _validate_output(model: tf.keras.Model,\n",
    "                     target: Optional[List[int]]) -> None:\n",
    "    \"\"\"\n",
    "    Validates the model's output type and raises an error if the output type is not supported.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model\n",
    "        Keras model for which the output is validated.\n",
    "    target\n",
    "        Targets for which gradients are calculated\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    if not model.output_shape or not any(isinstance(model.output_shape, t) for t in _valid_output_shape_type):\n",
    "        raise NotImplementedError(f\"The model output_shape attribute must be in {_valid_output_shape_type}. \"\n",
    "                                  f\"Found model.output_shape: {model.output_shape}\")\n",
    "\n",
    "    if (len(model.output_shape) == 1\n",
    "        or model.output_shape[-1] == 1) \\\n",
    "            and target is None:\n",
    "        logger.warning(\"It looks like you are passing a model with a scalar output and target is set to `None`.\"\n",
    "                       \"If your model is a regression model this will produce correct attributions. If your model \"\n",
    "                       \"is a classification model, targets for each datapoint must be defined. \"\n",
    "                       \"Not defining the target may lead to incorrect values for the attributions.\"\n",
    "                       \"Targets can be either the true classes or the classes predicted by the model.\")\n",
    "\n",
    "\n",
    "class IntegratedGradients1(Explainer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: tf.keras.Model,\n",
    "                 layer: Optional[tf.keras.layers.Layer] = None,\n",
    "                 method: str = \"gausslegendre\",\n",
    "                 n_steps: int = 10,\n",
    "                 internal_batch_size: int = 100\n",
    "                 ) -> None:\n",
    "        \"\"\"\n",
    "        An implementation of the integrated gradients method for Tensorflow and Keras models.\n",
    "\n",
    "        For details of the method see the original paper:\n",
    "        https://arxiv.org/abs/1703.01365 .\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model\n",
    "            Tensorflow or Keras model.\n",
    "        layer\n",
    "            Layer with respect to which the gradients are calculated.\n",
    "            If not provided, the gradients are calculated with respect to the input.\n",
    "        method\n",
    "            Method for the integral approximation. Methods available:\n",
    "            \"riemann_left\", \"riemann_right\", \"riemann_middle\", \"riemann_trapezoid\", \"gausslegendre\".\n",
    "        n_steps\n",
    "            Number of step in the path integral approximation from the baseline to the input instance.\n",
    "        internal_batch_size\n",
    "            Batch size for the internal batching.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(meta=copy.deepcopy(DEFAULT_META_INTGRAD))\n",
    "        params = locals()\n",
    "        remove = ['self', 'model', '__class__', 'layer']\n",
    "        params = {k: v for k, v in params.items() if k not in remove}\n",
    "        self.model = model\n",
    "\n",
    "        if self.model.inputs is None:\n",
    "            self._has_inputs = False\n",
    "        else:\n",
    "            self._has_inputs = True\n",
    "\n",
    "        if layer is None:\n",
    "            self.orig_call = None\n",
    "            layer_num = 0\n",
    "        else:\n",
    "            self.orig_call = layer.call\n",
    "            try:\n",
    "                layer_num = model.layers.index(layer)\n",
    "            except ValueError:\n",
    "                logger.info(\"Layer not in the list of model.layers\")\n",
    "                layer_num = None\n",
    "\n",
    "        params['layer'] = layer_num\n",
    "        self.meta['params'].update(params)\n",
    "        self.layer = layer\n",
    "        self.n_steps = n_steps\n",
    "        self.method = method\n",
    "        self.internal_batch_size = internal_batch_size\n",
    "\n",
    "        self._is_list: Optional[bool] = None\n",
    "        self._is_np: Optional[bool] = None\n",
    "        self.orig_dummy_input: Optional[Union[list, np.ndarray]] = None\n",
    "\n",
    "\n",
    "    def explain(self,\n",
    "                X: Union[np.ndarray, List[np.ndarray]],\n",
    "                forward_kwargs: Optional[dict] = None,\n",
    "                baselines: Union[int, float, np.ndarray, List[int], List[float], List[np.ndarray]] = None,\n",
    "                target: Union[int, list, np.ndarray] = None,\n",
    "                attribute_to_layer_inputs: bool = False) -> Explanation:\n",
    "        \"\"\"Calculates the attributions for each input feature or element of layer and\n",
    "        returns an Explanation object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X\n",
    "            Instance for which integrated gradients attribution are computed.\n",
    "        forward_kwargs\n",
    "            Input keyword args. If it's not None, it must be a dict with numpy arrays as values.\n",
    "            The first dimension of the arrays must correspond to the number of examples.\n",
    "            It will be repeated for each of n_steps along the integrated path.\n",
    "            The attributions are not computed with respect to these arguments.\n",
    "        baselines\n",
    "            Baselines (starting point of the path integral) for each instance.\n",
    "            If the passed value is an `np.ndarray` must have the same shape as X.\n",
    "            If not provided, all features values for the baselines are set to 0.\n",
    "        target\n",
    "            Defines which element of the model output is considered to compute the gradients.\n",
    "            It can be a list of integers or a numeric value. If a numeric value is passed, the gradients are calculated\n",
    "            for the same element of the output for all data points.\n",
    "            It must be provided if the model output dimension is higher than 1.\n",
    "            For regression models whose output is a scalar, target should not be provided.\n",
    "            For classification models `target` can be either the true classes or the classes predicted by the model.\n",
    "        attribute_to_layer_inputs\n",
    "            In case of layers gradients, controls whether the gradients are computed for the layer's inputs or\n",
    "            outputs. If True, gradients are computed for the layer's inputs, if False for the layer's outputs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            `Explanation` object including `meta` and `data` attributes with integrated gradients attributions\n",
    "            for each feature.\n",
    "\n",
    "        \"\"\"\n",
    "        self._is_list = isinstance(X, list)\n",
    "        self._is_np = isinstance(X, np.ndarray)\n",
    "        #print('self._is_list: ', self._is_list)\n",
    "        #print('self._is_np: ', self._is_np)\n",
    "        if self._is_list:\n",
    "            self.orig_dummy_input = [np.zeros((1,) + xx.shape[1:], dtype=xx.dtype) for xx in X]  # type: ignore\n",
    "            nb_samples = len(X[0])\n",
    "            input_dtypes = [xx.dtype for xx in X]\n",
    "            # Formatting baselines in case of models with multiple inputs\n",
    "            if baselines is None:\n",
    "                baselines = [None for _ in range(len(X))]\n",
    "            else:\n",
    "                if not isinstance(baselines, list):\n",
    "                    raise ValueError(f\"If the input X is a list, baseline can only be `None` or \"\n",
    "                                     f\"a list of the same length of X. Found baselines type {type(baselines)}\")\n",
    "                else:\n",
    "                    if len(X) != len(baselines):\n",
    "                        raise ValueError(f\"Length of 'X' must match length of 'baselines'. \"\n",
    "                                         f\"Found len(X): {len(X)}, len(baselines): {len(baselines)}\")\n",
    "\n",
    "            if max([len(x) for x in X]) != min([len(x) for x in X]):\n",
    "                raise ValueError(\"First dimension must be egual for all inputs\")\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                x, baseline = X[i], baselines[i]  # type: ignore\n",
    "                # format and check baselines\n",
    "                baseline = _format_baseline(x, baseline)\n",
    "                baselines[i] = baseline  # type: ignore\n",
    "\n",
    "        elif self._is_np:\n",
    "            #X = cast(np.ndarray, X)  # help mypy out\n",
    "            #print('in is np : X shape:', X.shape)\n",
    "            self.orig_dummy_input = np.zeros((1,) + X.shape[1:], dtype=X.dtype)  # type: ignore\n",
    "            nb_samples = len(X)\n",
    "            input_dtypes = [X.dtype]  # type: ignore\n",
    "            # Formatting baselines for models with a single input\n",
    "            baselines = _format_baseline(X, baselines)\n",
    "            #print(\"baselines.shape1: \", baselines.shape)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Input must be a np.ndarray or a list of np.ndarray\")\n",
    "\n",
    "        # defining integral method\n",
    "        step_sizes_func, alphas_func = approximation_parameters(self.method)\n",
    "        step_sizes, alphas = step_sizes_func(self.n_steps), alphas_func(self.n_steps)\n",
    "        #print('alphas: ', alphas)\n",
    "        target = _format_target(target, nb_samples)\n",
    "        #print('target:', target)\n",
    "        #print('target type:', type(target))\n",
    "        if self._is_list:\n",
    "            # Attributions calculation in case of multiple inputs\n",
    "            if not self._has_inputs:\n",
    "                # Inferring model's inputs from data points for models with no explicit inputs\n",
    "                # (typically subclassed models)\n",
    "                inputs = [tf.keras.Input(shape=xx.shape[1:], dtype=xx.dtype) for xx in X]\n",
    "                self.model(inputs)\n",
    "\n",
    "            _validate_output(self.model, target)\n",
    "\n",
    "            if self.layer is None:\n",
    "                # No layer passed, attributions computed with respect to the inputs\n",
    "                attributions = self._compute_attributions_list_input(X,\n",
    "                                                                     baselines,\n",
    "                                                                     target,\n",
    "                                                                     step_sizes,\n",
    "                                                                     alphas,\n",
    "                                                                     nb_samples,\n",
    "                                                                     forward_kwargs,\n",
    "                                                                     attribute_to_layer_inputs)\n",
    "\n",
    "            else:\n",
    "                # forwad inputs and  baselines\n",
    "                X_layer, baselines_layer = _forward_input_baseline(X,\n",
    "                                                                   baselines,\n",
    "                                                                   self.model,\n",
    "                                                                   self.layer,\n",
    "                                                                   self.orig_call,\n",
    "                                                                   forward_kwargs=forward_kwargs,\n",
    "                                                                   forward_to_inputs=attribute_to_layer_inputs)\n",
    "\n",
    "                if isinstance(X_layer, list) and isinstance(baselines_layer, list):\n",
    "                    attributions = self._compute_attributions_list_input(X_layer,\n",
    "                                                                         baselines_layer,\n",
    "                                                                         target,\n",
    "                                                                         step_sizes,\n",
    "                                                                         alphas,\n",
    "                                                                         nb_samples,\n",
    "                                                                         forward_kwargs,\n",
    "                                                                         attribute_to_layer_inputs)\n",
    "                else:\n",
    "                    attributions = self._compute_attributions_tensor_input(X_layer,\n",
    "                                                                           baselines_layer,\n",
    "                                                                           target,\n",
    "                                                                           step_sizes,\n",
    "                                                                           alphas,\n",
    "                                                                           nb_samples,\n",
    "                                                                           forward_kwargs,\n",
    "                                                                           attribute_to_layer_inputs)\n",
    "\n",
    "        else:\n",
    "            # Attributions calculation in case of single input\n",
    "            if not self._has_inputs:\n",
    "                inputs = tf.keras.Input(shape=X.shape[1:], dtype=X.dtype)  # type: ignore\n",
    "                self.model(inputs)\n",
    "\n",
    "            _validate_output(self.model, target)\n",
    "\n",
    "            if self.layer is None:\n",
    "                attributions = self._compute_attributions_tensor_input(X,\n",
    "                                                                       baselines,\n",
    "                                                                       target,\n",
    "                                                                       step_sizes,\n",
    "                                                                       alphas,\n",
    "                                                                       nb_samples,\n",
    "                                                                       forward_kwargs,\n",
    "                                                                       attribute_to_layer_inputs)\n",
    "\n",
    "            else:\n",
    "                #print(\"--------else self.layer is None:\")\n",
    "                # forwad inputs and  baselines\n",
    "                X_layer, baselines_layer = _forward_input_baseline(X,\n",
    "                                            baselines,\n",
    "                                            self.model,\n",
    "                                            self.layer,\n",
    "                                            self.orig_call,\n",
    "                                            forward_kwargs=forward_kwargs,\n",
    "                                            forward_to_inputs=attribute_to_layer_inputs)\n",
    "\n",
    "                #print(\"-----baselines_layer[0].shape: \", baselines_layer[0].shape)\n",
    "                if isinstance(X_layer, list) and isinstance(baselines_layer, list):\n",
    "                    attributions = self._compute_attributions_list_input(X_layer,\n",
    "                                                baselines_layer,\n",
    "                                                target,\n",
    "                                                step_sizes,\n",
    "                                                alphas,\n",
    "                                                nb_samples,\n",
    "                                                forward_kwargs,\n",
    "                                                attribute_to_layer_inputs)\n",
    "                    #print(\"------baselines.shape\", baselines.shape)\n",
    "                else:\n",
    "                    attributions = self._compute_attributions_tensor_input(X_layer,\n",
    "                                                                           baselines_layer,\n",
    "                                                                           target,\n",
    "                                                                           step_sizes,\n",
    "                                                                           alphas,\n",
    "                                                                           nb_samples,\n",
    "                                                                           forward_kwargs,\n",
    "                                                                           attribute_to_layer_inputs)\n",
    "        # calculate convergence deltas\n",
    "        deltas = _compute_convergence_delta(self.model,\n",
    "                                            input_dtypes,\n",
    "                                            attributions,\n",
    "                                            baselines,\n",
    "                                            X,\n",
    "                                            forward_kwargs,\n",
    "                                            target,\n",
    "                                            self._is_list)\n",
    "\n",
    "        return self.build_explanation(\n",
    "            X=X,\n",
    "            forward_kwargs=forward_kwargs,\n",
    "            baselines=baselines,\n",
    "            target=target,\n",
    "            attributions=attributions,\n",
    "            deltas=deltas\n",
    "        )\n",
    "\n",
    "\n",
    "    def build_explanation(self,\n",
    "                          X: List[np.ndarray],\n",
    "                          forward_kwargs: Optional[dict],\n",
    "                          baselines: List[np.ndarray],\n",
    "                          target: Optional[List[int]],\n",
    "                          attributions: Union[List[np.ndarray], List[tf.Tensor]],\n",
    "                          deltas: np.ndarray) -> Explanation:\n",
    "\n",
    "        data = copy.deepcopy(DEFAULT_DATA_INTGRAD)\n",
    "        predictions = self.model(X).numpy()\n",
    "        if isinstance(attributions[0], tf.Tensor):\n",
    "            attributions = [attr.numpy() for attr in attributions]\n",
    "        data.update(X=X,\n",
    "                    forward_kwargs=forward_kwargs,\n",
    "                    baselines=baselines,\n",
    "                    target=target,\n",
    "                    attributions=attributions,\n",
    "                    deltas=deltas,\n",
    "                    predictions=predictions)\n",
    "\n",
    "        return Explanation(meta=copy.deepcopy(self.meta), data=data)\n",
    "\n",
    "\n",
    "    def reset_predictor(self, predictor: Union[tf.keras.Model]) -> None:\n",
    "        # TODO: check what else should be done (e.g. validate dtypes again?)\n",
    "        self.model = predictor\n",
    "\n",
    "\n",
    "    def _compute_attributions_list_input(self,\n",
    "                       X: List[np.ndarray],\n",
    "                       baselines: Union[List[int], List[float], List[np.ndarray]],\n",
    "                       target: Optional[List[int]],\n",
    "                       step_sizes: List[float],\n",
    "                       alphas: List[float],\n",
    "                       nb_samples: int,\n",
    "                       forward_kwargs: Optional[dict],\n",
    "                       compute_layer_inputs_gradients: bool) -> List:\n",
    "        \"\"\"For each tensor in a list of input tensors,\n",
    "        calculates the attributions for each feature or element of layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X\n",
    "        Instance for which integrated gradients attribution are computed.\n",
    "        baselines\n",
    "            Baselines (starting point of the path integral) for each instance.\n",
    "        target\n",
    "            Defines which element of the model output is considered to compute the gradients.\n",
    "        step_sizes\n",
    "            Weights in the path integral sum.\n",
    "        alphas\n",
    "            Interpolation parameter defining the points of the interal path.\n",
    "        nb_samples\n",
    "            Total number of samples.\n",
    "        forward_kwargs\n",
    "            Input keywords args.\n",
    "        compute_layer_inputs_gradients\n",
    "            In case of layers gradients, controls whether the gradients are computed for the layer's inputs or\n",
    "            outputs. If True, gradients are computed for the layer's inputs, if False for the layer's outputs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tuple with integrated gradients attributions, deltas and predictions\n",
    "\n",
    "        \"\"\"\n",
    "        #print(\"X type: \", type(X))\n",
    "        #print(\"X len: \", len(X))\n",
    "        #print('X[0] shape: ', X[0].shape)\n",
    "        #print('X[1] shape: ', X[1].shape)\n",
    "        attrs_dtypes = [ [xx.dtype for xx in X][0] ] # [# of outputs]\n",
    "        #print(\"attrs_dtypes type: \", type(attrs_dtypes))\n",
    "        #print(\"attrs_dtypes len: \", len(attrs_dtypes))\n",
    "        #print(\"attrs_dtypes[0] type: \", type(attrs_dtypes[0]))\n",
    "\n",
    "        # define paths in features' space\n",
    "        paths = []\n",
    "        #print(\"type(baselines): \", type(baselines))\n",
    "        #print(\"baselines[0].shape: \", baselines[0].shape)\n",
    "        for i in range(len(X)): #ListWrapper of length 2\n",
    "            x, baseline = X[i], baselines[i]  # type: ignore\n",
    "            # construct paths (279 X 802 X 32)\n",
    "            blist =[]\n",
    "            for j in range(self.n_steps): \n",
    "              tmp = baseline + alphas[j] * (x-baseline) \n",
    "              #print('alphas[j] shape: ', alphas[j].shape)\n",
    "              #print('alphas[j]: ', alphas[j])\n",
    "              #print(\"tmp shape:\", tmp.shape)            \n",
    "              blist.append(tmp)\n",
    "            path = np.concatenate(blist, axis=0)\n",
    "            #print(\"path shape\", path.shape)\n",
    "            paths.append(path)\n",
    "\n",
    "        if forward_kwargs is not None:\n",
    "            paths_kwargs = {k: np.concatenate([forward_kwargs[k] for _ in range(self.n_steps)], axis=0)\n",
    "                            for k in forward_kwargs.keys()}\n",
    "        else:\n",
    "            paths_kwargs = None\n",
    "\n",
    "        # define target paths\n",
    "        if target is not None:\n",
    "            target_paths = np.concatenate([target \n",
    "                    for _ in range(self.n_steps)],\n",
    "                    axis=0)\n",
    "        else:\n",
    "            target_paths = None\n",
    "        if forward_kwargs is not None:\n",
    "            if target_paths is not None:\n",
    "                #print(\"PATH1....\")\n",
    "                ds_args = tuple(p for p in paths) + (paths_kwargs, target_paths)\n",
    "            else:\n",
    "                #print(\"PATH2....\")\n",
    "                ds_args = tuple(p for p in paths) + (paths_kwargs,)\n",
    "\n",
    "        else:\n",
    "            if target_paths is not None:\n",
    "                #print(\"PATH3....\")\n",
    "                #print(\"len(target_paths): \", len(target_paths))\n",
    "                #print(\"target_paths[0].shape: \", target_paths[0].shape)\n",
    "                #print(\"target_paths[0]: \", target_paths[0])\n",
    "                #print(\"len(paths): \", len(paths))\n",
    "                #print(\"type(paths): \", type(paths))\n",
    "                #print(\"paths[0].shape: \", paths[0].shape)\n",
    "                #print(\"paths[1].shape: \", paths[1].shape)\n",
    "                #print(\"paths: \", paths)\n",
    "                #ds_args = tuple(p for p in paths) + (target_paths,)\n",
    "                ds_args = tuple([paths[0]]) + (target_paths,)\n",
    "            else:\n",
    "                #print(\"PATH4....\")\n",
    "                ds_args = tuple(p for p in paths)\n",
    "        #print('len(ds_args): ', len(ds_args))\n",
    "        #print('ds_args[0].shape: ', ds_args[0].shape)\n",
    "        #print('ds_args[1].shape: ', ds_args[1].shape)\n",
    "        paths_ds = tf.data.Dataset.from_tensor_slices(ds_args).batch(self.internal_batch_size)\n",
    "        paths_ds.as_numpy_iterator()\n",
    "        paths_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        #print(\"paths_ds len: \", len(paths_ds))\n",
    "\n",
    "        # calculate gradients for batches\n",
    "        batches = []\n",
    "        for path in paths_ds:\n",
    "            #print(\"path type: \", type(path))\n",
    "            #print(\"path len: \", len(path))\n",
    "            if forward_kwargs is not None:\n",
    "                if target is not None:\n",
    "                    paths_b, kwargs_b, target_b = path[:-2], path[-2], path[-1]\n",
    "                else:\n",
    "                    paths_b, kwargs_b = path\n",
    "                    target_b = None\n",
    "            else:\n",
    "                if target is not None:\n",
    "                    paths_b, target_b = path[:-1], path[-1]\n",
    "                    kwargs_b = None\n",
    "                else:\n",
    "                    paths_b, kwargs_b, target_b = path, None, None\n",
    "\n",
    "            paths_b = [tf.dtypes.cast(paths_b[i], attrs_dtypes[i]) for i in range(len(paths_b))]\n",
    "\n",
    "            #print(\"self.layer: \", self.layer)\n",
    "            if self.layer is None:\n",
    "                grads_b = _gradients_input(self.model, paths_b, target_b, forward_kwargs=kwargs_b)\n",
    "            else:\n",
    "                grads_b = _gradients_layer(self.model,\n",
    "                                           self.layer,\n",
    "                                           self.orig_call,\n",
    "                                           self.orig_dummy_input,\n",
    "                                           paths_b,\n",
    "                                           target_b,\n",
    "                                           forward_kwargs=kwargs_b,\n",
    "                                           compute_layer_inputs_gradients=compute_layer_inputs_gradients)\n",
    "            #print(\"grads_b type: \", type(grads_b))\n",
    "            #print(\"grads_b shape: \", grads_b.shape)\n",
    "\n",
    "            batches.append(grads_b)\n",
    "\n",
    "        # multi-input\n",
    "        #print(\"batches type: \", type(batches))\n",
    "        #print(\"len(batches): \", len(batches))\n",
    "        #print(\"batches[0] len\",len(batches[0]) )\n",
    "        #print(\"attrs_dtypes type: \", type(attrs_dtypes))\n",
    "        #print(\"len(attrs_dtypes): \", len(attrs_dtypes))\n",
    "        #print(\"batches[0]: \", batches[0])\n",
    "\n",
    "        batches = [[batches[i][j] for i in range(len(batches))] for j in range(len(attrs_dtypes))]\n",
    "\n",
    "        # calculate attributions from gradients batches\n",
    "        attributions = []\n",
    "        for j in range(len(attrs_dtypes)):\n",
    "            sum_int = _calculate_sum_int(batches, self.model,\n",
    "                                         target, target_paths,\n",
    "                                         self.n_steps, nb_samples,\n",
    "                                         step_sizes, j)\n",
    "            norm = X[j] - baselines[j]  # type: ignore\n",
    "            attribution = norm * sum_int\n",
    "            attributions.append(attribution)\n",
    "        return attributions\n",
    "\n",
    "    def _compute_attributions_tensor_input(self,\n",
    "                                           X: Union[np.ndarray, tf.Tensor],\n",
    "                                           baselines: Union[np.ndarray, tf.Tensor],\n",
    "                                           target: Optional[List[int]],\n",
    "                                           step_sizes: List[float],\n",
    "                                           alphas: List[float],\n",
    "                                           nb_samples: int,\n",
    "                                           forward_kwargs: Optional[dict],\n",
    "                                           compute_layer_inputs_gradients: bool) -> List:\n",
    "        \"\"\"For a single input tensor, calculates the attributions for each input feature or element of layer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X\n",
    "            Instance for which integrated gradients attribution are computed.\n",
    "        baselines\n",
    "            Baselines (starting point of the path integral) for each instance.\n",
    "        target\n",
    "            Defines which element of the model output is considered to compute the gradients.\n",
    "        step_sizes\n",
    "            Weights in the path integral sum.\n",
    "        alphas\n",
    "            Interpolation parameter defining the points of the interal path.\n",
    "        nb_samples\n",
    "            Total number of samples.\n",
    "        forward_kwargs\n",
    "            Inputs keywords args.\n",
    "        compute_layer_inputs_gradients\n",
    "            In case of layers gradients, controls whether the gradients are computed for the layer's inputs or\n",
    "            outputs. If True, gradients are computed for the layer's inputs, if False for the layer's outputs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tuple with integrated gradients attributions, deltas and predictions\n",
    "        \"\"\"\n",
    "        # define paths in features's or layers' space\n",
    "        paths = np.concatenate([baselines + alphas[i] * (X - baselines) for i in range(self.n_steps)], axis=0)\n",
    "\n",
    "        if forward_kwargs is not None:\n",
    "            paths_kwargs = {k: np.concatenate([forward_kwargs[k] for _ in range(self.n_steps)], axis=0)\n",
    "                            for k in forward_kwargs.keys()}\n",
    "        else:\n",
    "            paths_kwargs = None\n",
    "\n",
    "        # define target paths\n",
    "        if target is not None:\n",
    "            target_paths = np.concatenate([target for _ in range(self.n_steps)], axis=0)\n",
    "        else:\n",
    "            target_paths = None\n",
    "\n",
    "        if forward_kwargs is not None:\n",
    "            if target_paths is not None:\n",
    "                ds_args = (paths, paths_kwargs, target_paths)\n",
    "            else:\n",
    "                ds_args = (paths, paths_kwargs)  # type: ignore\n",
    "        else:\n",
    "            if target_paths is not None:\n",
    "                ds_args = (paths, target_paths)  # type: ignore\n",
    "            else:\n",
    "                ds_args = paths\n",
    "\n",
    "        paths_ds = tf.data.Dataset.from_tensor_slices(ds_args).batch(self.internal_batch_size)\n",
    "        paths_ds.as_numpy_iterator()\n",
    "        paths_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        # calculate gradients for batches\n",
    "        batches = []\n",
    "        for path in paths_ds:\n",
    "            if forward_kwargs is not None:\n",
    "                if target is not None:\n",
    "                    paths_b, kwargs_b, target_b = path\n",
    "                else:\n",
    "                    paths_b, kwargs_b = path\n",
    "                    target_b = None\n",
    "            else:\n",
    "                kwargs_b = None\n",
    "                if target is not None:\n",
    "                    paths_b, target_b = path\n",
    "                else:\n",
    "                    paths_b, target_b = path, None\n",
    "\n",
    "            if self.layer is None:\n",
    "                grads_b = _gradients_input(self.model, paths_b, target_b, forward_kwargs=kwargs_b)\n",
    "\n",
    "            else:\n",
    "                grads_b = _gradients_layer(self.model,\n",
    "                                           self.layer,\n",
    "                                           self.orig_call,\n",
    "                                           self.orig_dummy_input,\n",
    "                                           paths_b,\n",
    "                                           target_b,\n",
    "                                           forward_kwargs=kwargs_b,\n",
    "                                           compute_layer_inputs_gradients=compute_layer_inputs_gradients)\n",
    "\n",
    "            batches.append(grads_b)\n",
    "\n",
    "        # calculate attributions from gradients batches\n",
    "        attributions = []\n",
    "        sum_int = _calculate_sum_int([batches], self.model,\n",
    "                                     target, target_paths,\n",
    "                                     self.n_steps, nb_samples,\n",
    "                                     step_sizes, 0)\n",
    "        #print('sum_int shape: ', sum_int.shape)\n",
    "        norm = X - baselines\n",
    "\n",
    "        attribution = norm * sum_int\n",
    "        attributions.append(attribution)\n",
    "\n",
    "        return attributions\n",
    "    def _mk(self) -> List:\n",
    "        step_sizes_func, mk_func = approximation_parameters(self.method)\n",
    "        step_sizes, mk = step_sizes_func(self.n_steps), mk_func(self.n_steps)\n",
    "        return mk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1J8DFouqmVQ"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain shape:  (13081, 1001, 32)\n",
      "xtrain_attr shape:  (13081, 1001, 32)\n",
      "ytrain shape:  (13081, 36)\n",
      "xvalidation shape:  (1454, 1001, 32)\n",
      "xvalidation_attr shape:  (1454, 1001, 32)\n",
      "yvalidation shape:  (1454, 36)\n",
      "newtrain shape:  (13081, 1001, 32)\n",
      "newvalidation shape:  (1454, 1001, 32)\n",
      "attr_train shape:  (26162, 1001, 32)\n",
      "attr_validation shape:  (2908, 1001, 32)\n"
     ]
    }
   ],
   "source": [
    "xtrain = loadTestTrainData('D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/Max-len-1000/x_train[0]_0.npy')\n",
    "xtrain_attr = loadTestTrainData('D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/Attribution_all/x_newtrain_attribution_code.npy')\n",
    "ytrain = loadTestTrainData('D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/Max-len-1000/y_train[0]_0.npy')\n",
    "xvalidation = loadTestTrainData('D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/Max-len-1000/x_validation[0]_0.npy')\n",
    "xvalidation_attr = loadTestTrainData('D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/Attribution_all/x_newvalidation_attribution_code.npy')\n",
    "yvalidation = loadTestTrainData('D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000/Max-len-1000/y_validation[0]_0.npy')\n",
    "xtrain = model.layers[1](xtrain)[0]\n",
    "xvalidation = model.layers[1](xvalidation)[0]\n",
    "print('xtrain shape: ', xtrain.shape)\n",
    "print('xtrain_attr shape: ', xtrain_attr.shape)\n",
    "print('ytrain shape: ', ytrain.shape)\n",
    "print('xvalidation shape: ', xvalidation.shape)\n",
    "print('xvalidation_attr shape: ', xvalidation_attr.shape)\n",
    "print('yvalidation shape: ', yvalidation.shape)\n",
    "num_train = len(xtrain) #215 len(xtrain)\n",
    "num_validation = len(xvalidation) # 215 len(xvalidation)\n",
    "newtrain = np.zeros( (num_train, 1001, 32) )\n",
    "newtrain = np.asarray(newtrain).astype('float32')\n",
    "print('newtrain shape: ', newtrain.shape)\n",
    "newvalidation = np.zeros( (num_validation, 1001, 32) )\n",
    "newvalidation = np.asarray(newvalidation).astype('float32')\n",
    "print('newvalidation shape: ', newvalidation.shape)\n",
    "attr_train = np.zeros( (num_train*2, 1001, 32) )\n",
    "attr_train = np.asarray(attr_train).astype('float32')\n",
    "print('attr_train shape: ', attr_train.shape)\n",
    "attr_validation = np.zeros( (num_validation*2, 1001, 32) )\n",
    "attr_validation = np.asarray(attr_validation).astype('float32')\n",
    "print('attr_validation shape: ', attr_validation.shape)\n",
    "binary_acc_train = []\n",
    "binary_acc_validation = []\n",
    "attr_mse_train = []\n",
    "attr_mse_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  [771]\n",
      "----- loop 0 :  [771]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  21.814963579177856\n",
      "train data delta_a time:  783.212010383606\n",
      "train data time:  805.0269739627838\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  2.294084310531616\n",
      "validation data delta_a time:  81.74081802368164\n",
      "validation data time:  84.03490233421326\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "818/818 - 64s - loss: 0.3009 - binary_accuracy: 0.9385 - val_loss: 0.1618 - val_binary_accuracy: 0.9526 - 64s/epoch - 79ms/step\n",
      "Epoch 2/100\n",
      "818/818 - 57s - loss: 0.1530 - binary_accuracy: 0.9536 - val_loss: 0.1316 - val_binary_accuracy: 0.9577 - 57s/epoch - 69ms/step\n",
      "Epoch 3/100\n",
      "818/818 - 57s - loss: 0.1294 - binary_accuracy: 0.9579 - val_loss: 0.1123 - val_binary_accuracy: 0.9609 - 57s/epoch - 69ms/step\n",
      "Epoch 4/100\n",
      "818/818 - 57s - loss: 0.1089 - binary_accuracy: 0.9624 - val_loss: 0.0943 - val_binary_accuracy: 0.9660 - 57s/epoch - 69ms/step\n",
      "Epoch 5/100\n",
      "818/818 - 57s - loss: 0.0904 - binary_accuracy: 0.9676 - val_loss: 0.0786 - val_binary_accuracy: 0.9718 - 57s/epoch - 69ms/step\n",
      "Epoch 6/100\n",
      "818/818 - 57s - loss: 0.0723 - binary_accuracy: 0.9738 - val_loss: 0.0613 - val_binary_accuracy: 0.9777 - 57s/epoch - 69ms/step\n",
      "Epoch 7/100\n",
      "818/818 - 57s - loss: 0.0573 - binary_accuracy: 0.9790 - val_loss: 0.0485 - val_binary_accuracy: 0.9825 - 57s/epoch - 69ms/step\n",
      "Epoch 8/100\n",
      "818/818 - 57s - loss: 0.0458 - binary_accuracy: 0.9834 - val_loss: 0.0388 - val_binary_accuracy: 0.9858 - 57s/epoch - 69ms/step\n",
      "Epoch 9/100\n",
      "818/818 - 57s - loss: 0.0363 - binary_accuracy: 0.9868 - val_loss: 0.0314 - val_binary_accuracy: 0.9884 - 57s/epoch - 69ms/step\n",
      "Epoch 10/100\n",
      "818/818 - 57s - loss: 0.0288 - binary_accuracy: 0.9895 - val_loss: 0.0255 - val_binary_accuracy: 0.9911 - 57s/epoch - 69ms/step\n",
      "Epoch 11/100\n",
      "818/818 - 57s - loss: 0.0235 - binary_accuracy: 0.9916 - val_loss: 0.0223 - val_binary_accuracy: 0.9921 - 57s/epoch - 69ms/step\n",
      "Epoch 12/100\n",
      "818/818 - 57s - loss: 0.0192 - binary_accuracy: 0.9931 - val_loss: 0.0198 - val_binary_accuracy: 0.9931 - 57s/epoch - 69ms/step\n",
      "Epoch 13/100\n",
      "818/818 - 57s - loss: 0.0162 - binary_accuracy: 0.9943 - val_loss: 0.0165 - val_binary_accuracy: 0.9944 - 57s/epoch - 69ms/step\n",
      "Epoch 14/100\n",
      "818/818 - 57s - loss: 0.0138 - binary_accuracy: 0.9952 - val_loss: 0.0151 - val_binary_accuracy: 0.9949 - 57s/epoch - 69ms/step\n",
      "Epoch 15/100\n",
      "818/818 - 57s - loss: 0.0118 - binary_accuracy: 0.9959 - val_loss: 0.0135 - val_binary_accuracy: 0.9952 - 57s/epoch - 69ms/step\n",
      "Epoch 16/100\n",
      "818/818 - 57s - loss: 0.0103 - binary_accuracy: 0.9964 - val_loss: 0.0129 - val_binary_accuracy: 0.9958 - 57s/epoch - 69ms/step\n",
      "Epoch 17/100\n",
      "818/818 - 57s - loss: 0.0089 - binary_accuracy: 0.9970 - val_loss: 0.0115 - val_binary_accuracy: 0.9962 - 57s/epoch - 69ms/step\n",
      "Epoch 18/100\n",
      "818/818 - 57s - loss: 0.0078 - binary_accuracy: 0.9974 - val_loss: 0.0106 - val_binary_accuracy: 0.9967 - 57s/epoch - 69ms/step\n",
      "Epoch 19/100\n",
      "818/818 - 57s - loss: 0.0068 - binary_accuracy: 0.9977 - val_loss: 0.0108 - val_binary_accuracy: 0.9964 - 57s/epoch - 69ms/step\n",
      "Epoch 20/100\n",
      "818/818 - 57s - loss: 0.0060 - binary_accuracy: 0.9980 - val_loss: 0.0099 - val_binary_accuracy: 0.9968 - 57s/epoch - 69ms/step\n",
      "Epoch 21/100\n",
      "818/818 - 57s - loss: 0.0053 - binary_accuracy: 0.9983 - val_loss: 0.0098 - val_binary_accuracy: 0.9970 - 57s/epoch - 69ms/step\n",
      "Epoch 22/100\n",
      "818/818 - 57s - loss: 0.0049 - binary_accuracy: 0.9984 - val_loss: 0.0093 - val_binary_accuracy: 0.9969 - 57s/epoch - 69ms/step\n",
      "Epoch 23/100\n",
      "818/818 - 57s - loss: 0.0043 - binary_accuracy: 0.9986 - val_loss: 0.0090 - val_binary_accuracy: 0.9972 - 57s/epoch - 69ms/step\n",
      "Epoch 24/100\n",
      "818/818 - 57s - loss: 0.0037 - binary_accuracy: 0.9988 - val_loss: 0.0085 - val_binary_accuracy: 0.9976 - 57s/epoch - 69ms/step\n",
      "Epoch 25/100\n",
      "818/818 - 57s - loss: 0.0035 - binary_accuracy: 0.9989 - val_loss: 0.0082 - val_binary_accuracy: 0.9976 - 57s/epoch - 69ms/step\n",
      "Epoch 26/100\n",
      "818/818 - 57s - loss: 0.0031 - binary_accuracy: 0.9990 - val_loss: 0.0088 - val_binary_accuracy: 0.9974 - 57s/epoch - 69ms/step\n",
      "Epoch 27/100\n",
      "818/818 - 57s - loss: 0.0029 - binary_accuracy: 0.9991 - val_loss: 0.0084 - val_binary_accuracy: 0.9976 - 57s/epoch - 69ms/step\n",
      "Epoch 28/100\n",
      "818/818 - 57s - loss: 0.0027 - binary_accuracy: 0.9992 - val_loss: 0.0078 - val_binary_accuracy: 0.9977 - 57s/epoch - 69ms/step\n",
      "Epoch 29/100\n",
      "818/818 - 57s - loss: 0.0024 - binary_accuracy: 0.9993 - val_loss: 0.0078 - val_binary_accuracy: 0.9978 - 57s/epoch - 69ms/step\n",
      "Epoch 30/100\n",
      "818/818 - 57s - loss: 0.0022 - binary_accuracy: 0.9993 - val_loss: 0.0075 - val_binary_accuracy: 0.9977 - 57s/epoch - 69ms/step\n",
      "Epoch 31/100\n",
      "818/818 - 57s - loss: 0.0021 - binary_accuracy: 0.9994 - val_loss: 0.0073 - val_binary_accuracy: 0.9979 - 57s/epoch - 69ms/step\n",
      "Epoch 32/100\n",
      "818/818 - 57s - loss: 0.0018 - binary_accuracy: 0.9995 - val_loss: 0.0073 - val_binary_accuracy: 0.9980 - 57s/epoch - 69ms/step\n",
      "Epoch 33/100\n",
      "818/818 - 57s - loss: 0.0018 - binary_accuracy: 0.9995 - val_loss: 0.0073 - val_binary_accuracy: 0.9980 - 57s/epoch - 69ms/step\n",
      "Epoch 34/100\n",
      "818/818 - 57s - loss: 0.0017 - binary_accuracy: 0.9995 - val_loss: 0.0069 - val_binary_accuracy: 0.9980 - 57s/epoch - 69ms/step\n",
      "Epoch 35/100\n",
      "818/818 - 57s - loss: 0.0015 - binary_accuracy: 0.9995 - val_loss: 0.0066 - val_binary_accuracy: 0.9981 - 57s/epoch - 69ms/step\n",
      "Epoch 36/100\n",
      "818/818 - 57s - loss: 0.0014 - binary_accuracy: 0.9996 - val_loss: 0.0071 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 37/100\n",
      "818/818 - 57s - loss: 0.0013 - binary_accuracy: 0.9996 - val_loss: 0.0068 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 38/100\n",
      "818/818 - 57s - loss: 0.0013 - binary_accuracy: 0.9996 - val_loss: 0.0073 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 39/100\n",
      "818/818 - 57s - loss: 0.0013 - binary_accuracy: 0.9996 - val_loss: 0.0070 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 40/100\n",
      "818/818 - 57s - loss: 0.0011 - binary_accuracy: 0.9997 - val_loss: 0.0075 - val_binary_accuracy: 0.9980 - 57s/epoch - 69ms/step\n",
      "Epoch 41/100\n",
      "818/818 - 57s - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 0.0071 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 42/100\n",
      "818/818 - 57s - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 0.0076 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 43/100\n",
      "818/818 - 57s - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 0.0073 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 44/100\n",
      "818/818 - 57s - loss: 9.6506e-04 - binary_accuracy: 0.9997 - val_loss: 0.0067 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 45/100\n",
      "818/818 - 57s - loss: 9.1848e-04 - binary_accuracy: 0.9998 - val_loss: 0.0074 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 46/100\n",
      "818/818 - 57s - loss: 8.3976e-04 - binary_accuracy: 0.9998 - val_loss: 0.0071 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 47/100\n",
      "818/818 - 57s - loss: 7.4708e-04 - binary_accuracy: 0.9998 - val_loss: 0.0080 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 48/100\n",
      "818/818 - 57s - loss: 7.5376e-04 - binary_accuracy: 0.9998 - val_loss: 0.0080 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 49/100\n",
      "818/818 - 57s - loss: 8.0115e-04 - binary_accuracy: 0.9998 - val_loss: 0.0070 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 50/100\n",
      "818/818 - 57s - loss: 7.3194e-04 - binary_accuracy: 0.9998 - val_loss: 0.0076 - val_binary_accuracy: 0.9981 - 57s/epoch - 69ms/step\n",
      "Epoch 51/100\n",
      "818/818 - 57s - loss: 7.8865e-04 - binary_accuracy: 0.9998 - val_loss: 0.0072 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 52/100\n",
      "818/818 - 57s - loss: 6.3773e-04 - binary_accuracy: 0.9998 - val_loss: 0.0078 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 53/100\n",
      "818/818 - 57s - loss: 6.1707e-04 - binary_accuracy: 0.9998 - val_loss: 0.0076 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 54/100\n",
      "818/818 - 57s - loss: 6.8284e-04 - binary_accuracy: 0.9998 - val_loss: 0.0071 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 55/100\n",
      "818/818 - 57s - loss: 6.0190e-04 - binary_accuracy: 0.9998 - val_loss: 0.0085 - val_binary_accuracy: 0.9981 - 57s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "818/818 - 57s - loss: 5.5288e-04 - binary_accuracy: 0.9998 - val_loss: 0.0075 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 57/100\n",
      "818/818 - 57s - loss: 6.0367e-04 - binary_accuracy: 0.9998 - val_loss: 0.0073 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 58/100\n",
      "818/818 - 57s - loss: 4.9890e-04 - binary_accuracy: 0.9999 - val_loss: 0.0072 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 59/100\n",
      "818/818 - 57s - loss: 5.6990e-04 - binary_accuracy: 0.9998 - val_loss: 0.0071 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 60/100\n",
      "818/818 - 57s - loss: 5.7657e-04 - binary_accuracy: 0.9998 - val_loss: 0.0075 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 61/100\n",
      "818/818 - 57s - loss: 4.7440e-04 - binary_accuracy: 0.9999 - val_loss: 0.0072 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 62/100\n",
      "818/818 - 57s - loss: 4.7080e-04 - binary_accuracy: 0.9999 - val_loss: 0.0079 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 63/100\n",
      "818/818 - 57s - loss: 4.5282e-04 - binary_accuracy: 0.9999 - val_loss: 0.0078 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 64/100\n",
      "818/818 - 57s - loss: 4.6128e-04 - binary_accuracy: 0.9999 - val_loss: 0.0077 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 65/100\n",
      "818/818 - 57s - loss: 4.4300e-04 - binary_accuracy: 0.9999 - val_loss: 0.0072 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 66/100\n",
      "818/818 - 57s - loss: 5.1884e-04 - binary_accuracy: 0.9998 - val_loss: 0.0070 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 67/100\n",
      "818/818 - 57s - loss: 3.7877e-04 - binary_accuracy: 0.9999 - val_loss: 0.0067 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 68/100\n",
      "818/818 - 57s - loss: 4.2570e-04 - binary_accuracy: 0.9999 - val_loss: 0.0076 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 69/100\n",
      "818/818 - 57s - loss: 3.8865e-04 - binary_accuracy: 0.9999 - val_loss: 0.0072 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 70/100\n",
      "818/818 - 57s - loss: 3.6176e-04 - binary_accuracy: 0.9999 - val_loss: 0.0074 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 71/100\n",
      "818/818 - 57s - loss: 3.6497e-04 - binary_accuracy: 0.9999 - val_loss: 0.0072 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 72/100\n",
      "818/818 - 57s - loss: 3.7876e-04 - binary_accuracy: 0.9999 - val_loss: 0.0069 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 73/100\n",
      "818/818 - 57s - loss: 3.2176e-04 - binary_accuracy: 0.9999 - val_loss: 0.0087 - val_binary_accuracy: 0.9981 - 57s/epoch - 69ms/step\n",
      "Epoch 74/100\n",
      "818/818 - 57s - loss: 2.9088e-04 - binary_accuracy: 0.9999 - val_loss: 0.0076 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 75/100\n",
      "818/818 - 57s - loss: 3.2972e-04 - binary_accuracy: 0.9999 - val_loss: 0.0076 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 76/100\n",
      "818/818 - 57s - loss: 3.9510e-04 - binary_accuracy: 0.9999 - val_loss: 0.0070 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 77/100\n",
      "818/818 - 57s - loss: 4.0945e-04 - binary_accuracy: 0.9999 - val_loss: 0.0070 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 78/100\n",
      "818/818 - 57s - loss: 2.9296e-04 - binary_accuracy: 0.9999 - val_loss: 0.0075 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 79/100\n",
      "818/818 - 57s - loss: 3.6521e-04 - binary_accuracy: 0.9999 - val_loss: 0.0083 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 80/100\n",
      "818/818 - 57s - loss: 3.1945e-04 - binary_accuracy: 0.9999 - val_loss: 0.0085 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 81/100\n",
      "818/818 - 57s - loss: 3.5283e-04 - binary_accuracy: 0.9999 - val_loss: 0.0078 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 82/100\n",
      "818/818 - 57s - loss: 2.9092e-04 - binary_accuracy: 0.9999 - val_loss: 0.0074 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 83/100\n",
      "818/818 - 57s - loss: 3.4144e-04 - binary_accuracy: 0.9999 - val_loss: 0.0080 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 84/100\n",
      "818/818 - 57s - loss: 2.4937e-04 - binary_accuracy: 0.9999 - val_loss: 0.0079 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 85/100\n",
      "818/818 - 57s - loss: 2.2393e-04 - binary_accuracy: 0.9999 - val_loss: 0.0084 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 86/100\n",
      "818/818 - 57s - loss: 3.2934e-04 - binary_accuracy: 0.9999 - val_loss: 0.0085 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 87/100\n",
      "818/818 - 57s - loss: 3.0101e-04 - binary_accuracy: 0.9999 - val_loss: 0.0080 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 88/100\n",
      "818/818 - 57s - loss: 2.3341e-04 - binary_accuracy: 0.9999 - val_loss: 0.0067 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 89/100\n",
      "818/818 - 57s - loss: 2.6989e-04 - binary_accuracy: 0.9999 - val_loss: 0.0083 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 90/100\n",
      "818/818 - 57s - loss: 2.4138e-04 - binary_accuracy: 0.9999 - val_loss: 0.0078 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 91/100\n",
      "818/818 - 57s - loss: 3.0279e-04 - binary_accuracy: 0.9999 - val_loss: 0.0075 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 92/100\n",
      "818/818 - 57s - loss: 2.7970e-04 - binary_accuracy: 0.9999 - val_loss: 0.0085 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 93/100\n",
      "818/818 - 57s - loss: 2.2365e-04 - binary_accuracy: 0.9999 - val_loss: 0.0080 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "818/818 - 57s - loss: 2.5609e-04 - binary_accuracy: 0.9999 - val_loss: 0.0080 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 95/100\n",
      "818/818 - 57s - loss: 2.3487e-04 - binary_accuracy: 0.9999 - val_loss: 0.0071 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 96/100\n",
      "818/818 - 57s - loss: 2.2752e-04 - binary_accuracy: 0.9999 - val_loss: 0.0080 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 97/100\n",
      "818/818 - 57s - loss: 2.2075e-04 - binary_accuracy: 0.9999 - val_loss: 0.0087 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 98/100\n",
      "818/818 - 57s - loss: 2.4277e-04 - binary_accuracy: 0.9999 - val_loss: 0.0077 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 99/100\n",
      "818/818 - 57s - loss: 2.6553e-04 - binary_accuracy: 0.9999 - val_loss: 0.0075 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 100/100\n",
      "818/818 - 57s - loss: 2.8498e-04 - binary_accuracy: 0.9999 - val_loss: 0.0081 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.999916672706604\n",
      "binary_accuracy validation:  0.9985381960868835\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.05007551\n",
      "train attribution time:  829.894268989563\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.04901236\n",
      "validation attribution time:  92.42377185821533\n",
      "time:  7487.506891012192\n",
      "----- loop 1 :  [1162]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  20.002835035324097\n",
      "train data delta_a time:  757.3708100318909\n",
      "train data time:  777.37464594841\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  2.2814369201660156\n",
      "validation data delta_a time:  81.15084886550903\n",
      "validation data time:  83.4332869052887\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "818/818 - 64s - loss: 0.0144 - binary_accuracy: 0.9969 - val_loss: 0.0116 - val_binary_accuracy: 0.9969 - 64s/epoch - 79ms/step\n",
      "Epoch 2/100\n",
      "818/818 - 56s - loss: 0.0056 - binary_accuracy: 0.9983 - val_loss: 0.0091 - val_binary_accuracy: 0.9978 - 56s/epoch - 69ms/step\n",
      "Epoch 3/100\n",
      "818/818 - 57s - loss: 0.0034 - binary_accuracy: 0.9989 - val_loss: 0.0077 - val_binary_accuracy: 0.9981 - 57s/epoch - 69ms/step\n",
      "Epoch 4/100\n",
      "818/818 - 57s - loss: 0.0024 - binary_accuracy: 0.9992 - val_loss: 0.0068 - val_binary_accuracy: 0.9982 - 57s/epoch - 69ms/step\n",
      "Epoch 5/100\n",
      "818/818 - 57s - loss: 0.0019 - binary_accuracy: 0.9993 - val_loss: 0.0064 - val_binary_accuracy: 0.9983 - 57s/epoch - 69ms/step\n",
      "Epoch 6/100\n",
      "818/818 - 57s - loss: 0.0014 - binary_accuracy: 0.9995 - val_loss: 0.0062 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 7/100\n",
      "818/818 - 57s - loss: 0.0012 - binary_accuracy: 0.9996 - val_loss: 0.0063 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "818/818 - 57s - loss: 9.6108e-04 - binary_accuracy: 0.9997 - val_loss: 0.0063 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 9/100\n",
      "818/818 - 57s - loss: 8.2642e-04 - binary_accuracy: 0.9997 - val_loss: 0.0059 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 10/100\n",
      "818/818 - 57s - loss: 7.0023e-04 - binary_accuracy: 0.9998 - val_loss: 0.0068 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 11/100\n",
      "818/818 - 57s - loss: 5.7763e-04 - binary_accuracy: 0.9998 - val_loss: 0.0064 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 12/100\n",
      "818/818 - 57s - loss: 5.5866e-04 - binary_accuracy: 0.9998 - val_loss: 0.0060 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 13/100\n",
      "818/818 - 57s - loss: 4.7231e-04 - binary_accuracy: 0.9999 - val_loss: 0.0066 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 14/100\n",
      "818/818 - 57s - loss: 3.9780e-04 - binary_accuracy: 0.9999 - val_loss: 0.0059 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 15/100\n",
      "818/818 - 57s - loss: 4.5190e-04 - binary_accuracy: 0.9999 - val_loss: 0.0056 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 16/100\n",
      "818/818 - 57s - loss: 3.8454e-04 - binary_accuracy: 0.9999 - val_loss: 0.0064 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 17/100\n",
      "818/818 - 57s - loss: 3.0341e-04 - binary_accuracy: 0.9999 - val_loss: 0.0066 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 18/100\n",
      "818/818 - 57s - loss: 3.8030e-04 - binary_accuracy: 0.9999 - val_loss: 0.0057 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 19/100\n",
      "818/818 - 57s - loss: 2.5243e-04 - binary_accuracy: 0.9999 - val_loss: 0.0058 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 20/100\n",
      "818/818 - 57s - loss: 2.5978e-04 - binary_accuracy: 0.9999 - val_loss: 0.0061 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 21/100\n",
      "818/818 - 57s - loss: 2.5450e-04 - binary_accuracy: 0.9999 - val_loss: 0.0058 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 22/100\n",
      "818/818 - 57s - loss: 3.0029e-04 - binary_accuracy: 0.9999 - val_loss: 0.0056 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 23/100\n",
      "818/818 - 57s - loss: 2.4020e-04 - binary_accuracy: 0.9999 - val_loss: 0.0060 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 24/100\n",
      "818/818 - 57s - loss: 2.5235e-04 - binary_accuracy: 0.9999 - val_loss: 0.0060 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 25/100\n",
      "818/818 - 57s - loss: 2.8347e-04 - binary_accuracy: 0.9999 - val_loss: 0.0066 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 26/100\n",
      "818/818 - 57s - loss: 1.8714e-04 - binary_accuracy: 0.9999 - val_loss: 0.0061 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 27/100\n",
      "818/818 - 57s - loss: 1.6103e-04 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 28/100\n",
      "818/818 - 57s - loss: 1.8690e-04 - binary_accuracy: 0.9999 - val_loss: 0.0066 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 29/100\n",
      "818/818 - 57s - loss: 2.9145e-04 - binary_accuracy: 0.9999 - val_loss: 0.0062 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 30/100\n",
      "818/818 - 57s - loss: 1.7472e-04 - binary_accuracy: 0.9999 - val_loss: 0.0060 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 31/100\n",
      "818/818 - 57s - loss: 1.5964e-04 - binary_accuracy: 1.0000 - val_loss: 0.0060 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 32/100\n",
      "818/818 - 57s - loss: 1.6862e-04 - binary_accuracy: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 33/100\n",
      "818/818 - 57s - loss: 1.4091e-04 - binary_accuracy: 1.0000 - val_loss: 0.0060 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 34/100\n",
      "818/818 - 57s - loss: 1.9248e-04 - binary_accuracy: 0.9999 - val_loss: 0.0067 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 35/100\n",
      "818/818 - 57s - loss: 1.8118e-04 - binary_accuracy: 0.9999 - val_loss: 0.0060 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 36/100\n",
      "818/818 - 57s - loss: 1.9274e-04 - binary_accuracy: 0.9999 - val_loss: 0.0057 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 37/100\n",
      "818/818 - 57s - loss: 1.3133e-04 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 38/100\n",
      "818/818 - 57s - loss: 1.5104e-04 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 39/100\n",
      "818/818 - 57s - loss: 1.9115e-04 - binary_accuracy: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 0.9989 - 57s/epoch - 70ms/step\n",
      "Epoch 40/100\n",
      "818/818 - 57s - loss: 1.2050e-04 - binary_accuracy: 1.0000 - val_loss: 0.0060 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 41/100\n",
      "818/818 - 57s - loss: 1.2998e-04 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 42/100\n",
      "818/818 - 57s - loss: 1.1841e-04 - binary_accuracy: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 43/100\n",
      "818/818 - 57s - loss: 1.1881e-04 - binary_accuracy: 1.0000 - val_loss: 0.0060 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 44/100\n",
      "818/818 - 57s - loss: 1.2191e-04 - binary_accuracy: 1.0000 - val_loss: 0.0058 - val_binary_accuracy: 0.9990 - 57s/epoch - 70ms/step\n",
      "Epoch 45/100\n",
      "818/818 - 57s - loss: 1.4126e-04 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 46/100\n",
      "818/818 - 57s - loss: 9.9700e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 47/100\n",
      "818/818 - 57s - loss: 1.3564e-04 - binary_accuracy: 1.0000 - val_loss: 0.0056 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 48/100\n",
      "818/818 - 57s - loss: 6.3230e-05 - binary_accuracy: 1.0000 - val_loss: 0.0056 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 49/100\n",
      "818/818 - 57s - loss: 9.1959e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 50/100\n",
      "818/818 - 57s - loss: 9.5824e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 51/100\n",
      "818/818 - 57s - loss: 1.1666e-04 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 52/100\n",
      "818/818 - 57s - loss: 1.3208e-04 - binary_accuracy: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 53/100\n",
      "818/818 - 57s - loss: 9.4949e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 54/100\n",
      "818/818 - 57s - loss: 9.7576e-05 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 55/100\n",
      "818/818 - 57s - loss: 8.6430e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 56/100\n",
      "818/818 - 57s - loss: 1.1305e-04 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9987 - 57s/epoch - 70ms/step\n",
      "Epoch 57/100\n",
      "818/818 - 57s - loss: 1.1812e-04 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 58/100\n",
      "818/818 - 57s - loss: 7.0176e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 59/100\n",
      "818/818 - 57s - loss: 1.0737e-04 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9989 - 57s/epoch - 70ms/step\n",
      "Epoch 60/100\n",
      "818/818 - 57s - loss: 8.6769e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 61/100\n",
      "818/818 - 57s - loss: 4.8436e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 62/100\n",
      "818/818 - 57s - loss: 7.5437e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 63/100\n",
      "818/818 - 57s - loss: 6.7523e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 64/100\n",
      "818/818 - 57s - loss: 7.9816e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "818/818 - 57s - loss: 7.2949e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 66/100\n",
      "818/818 - 57s - loss: 7.6638e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 67/100\n",
      "818/818 - 57s - loss: 9.3373e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 68/100\n",
      "818/818 - 57s - loss: 7.9033e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 69/100\n",
      "818/818 - 57s - loss: 6.1221e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 70/100\n",
      "818/818 - 57s - loss: 3.8199e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 71/100\n",
      "818/818 - 57s - loss: 4.0204e-05 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 72/100\n",
      "818/818 - 57s - loss: 1.0323e-04 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 73/100\n",
      "818/818 - 57s - loss: 6.7701e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 74/100\n",
      "818/818 - 57s - loss: 6.3755e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 75/100\n",
      "818/818 - 57s - loss: 5.8956e-05 - binary_accuracy: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 76/100\n",
      "818/818 - 57s - loss: 6.6866e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 77/100\n",
      "818/818 - 57s - loss: 5.8603e-05 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 78/100\n",
      "818/818 - 57s - loss: 1.0071e-04 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9990 - 57s/epoch - 70ms/step\n",
      "Epoch 79/100\n",
      "818/818 - 57s - loss: 3.0877e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 80/100\n",
      "818/818 - 57s - loss: 1.0776e-04 - binary_accuracy: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 81/100\n",
      "818/818 - 57s - loss: 2.5062e-05 - binary_accuracy: 1.0000 - val_loss: 0.0061 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 82/100\n",
      "818/818 - 57s - loss: 7.3911e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 83/100\n",
      "818/818 - 57s - loss: 3.3728e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 84/100\n",
      "818/818 - 57s - loss: 5.6558e-05 - binary_accuracy: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 85/100\n",
      "818/818 - 57s - loss: 7.0168e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 86/100\n",
      "818/818 - 57s - loss: 6.1464e-05 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9991 - 57s/epoch - 70ms/step\n",
      "Epoch 87/100\n",
      "818/818 - 57s - loss: 5.0651e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9990 - 57s/epoch - 70ms/step\n",
      "Epoch 88/100\n",
      "818/818 - 57s - loss: 2.5138e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9990 - 57s/epoch - 70ms/step\n",
      "Epoch 89/100\n",
      "818/818 - 57s - loss: 8.8459e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 90/100\n",
      "818/818 - 57s - loss: 5.7299e-05 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 91/100\n",
      "818/818 - 57s - loss: 4.2344e-05 - binary_accuracy: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 0.9991 - 57s/epoch - 70ms/step\n",
      "Epoch 92/100\n",
      "818/818 - 57s - loss: 8.0466e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 93/100\n",
      "818/818 - 57s - loss: 6.7063e-05 - binary_accuracy: 1.0000 - val_loss: 0.0062 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "818/818 - 57s - loss: 5.7170e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 95/100\n",
      "818/818 - 57s - loss: 5.1575e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 96/100\n",
      "818/818 - 57s - loss: 3.5684e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 97/100\n",
      "818/818 - 57s - loss: 5.5595e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 98/100\n",
      "818/818 - 57s - loss: 1.8453e-05 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 99/100\n",
      "818/818 - 57s - loss: 2.3133e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 100/100\n",
      "818/818 - 57s - loss: 6.7676e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.9999768733978271\n",
      "binary_accuracy validation:  0.9990444183349609\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049090393\n",
      "train attribution time:  832.0631282329559\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.04806227\n",
      "validation attribution time:  92.74185276031494\n",
      "time:  7470.038645744324\n",
      "----- loop 2 :  [1133]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  20.00956106185913\n",
      "train data delta_a time:  758.6310648918152\n",
      "train data time:  778.6416268348694\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  2.2860758304595947\n",
      "validation data delta_a time:  81.46275019645691\n",
      "validation data time:  83.74982714653015\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "818/818 - 65s - loss: 0.0051 - binary_accuracy: 0.9990 - val_loss: 0.0097 - val_binary_accuracy: 0.9982 - 65s/epoch - 79ms/step\n",
      "Epoch 2/100\n",
      "818/818 - 56s - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 0.0083 - val_binary_accuracy: 0.9985 - 56s/epoch - 69ms/step\n",
      "Epoch 3/100\n",
      "818/818 - 56s - loss: 9.9513e-04 - binary_accuracy: 0.9997 - val_loss: 0.0077 - val_binary_accuracy: 0.9987 - 56s/epoch - 69ms/step\n",
      "Epoch 4/100\n",
      "818/818 - 57s - loss: 6.3210e-04 - binary_accuracy: 0.9998 - val_loss: 0.0084 - val_binary_accuracy: 0.9984 - 57s/epoch - 69ms/step\n",
      "Epoch 5/100\n",
      "818/818 - 57s - loss: 4.9032e-04 - binary_accuracy: 0.9998 - val_loss: 0.0076 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 6/100\n",
      "818/818 - 57s - loss: 3.7192e-04 - binary_accuracy: 0.9999 - val_loss: 0.0076 - val_binary_accuracy: 0.9986 - 57s/epoch - 69ms/step\n",
      "Epoch 7/100\n",
      "818/818 - 57s - loss: 2.9465e-04 - binary_accuracy: 0.9999 - val_loss: 0.0076 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 8/100\n",
      "818/818 - 57s - loss: 2.3846e-04 - binary_accuracy: 0.9999 - val_loss: 0.0072 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 9/100\n",
      "818/818 - 57s - loss: 2.0950e-04 - binary_accuracy: 0.9999 - val_loss: 0.0076 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 10/100\n",
      "818/818 - 57s - loss: 1.6644e-04 - binary_accuracy: 0.9999 - val_loss: 0.0076 - val_binary_accuracy: 0.9987 - 57s/epoch - 69ms/step\n",
      "Epoch 11/100\n",
      "818/818 - 57s - loss: 1.5038e-04 - binary_accuracy: 0.9999 - val_loss: 0.0075 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 12/100\n",
      "818/818 - 57s - loss: 1.5404e-04 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 13/100\n",
      "818/818 - 56s - loss: 1.2752e-04 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9987 - 56s/epoch - 69ms/step\n",
      "Epoch 14/100\n",
      "818/818 - 57s - loss: 1.3842e-04 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9985 - 57s/epoch - 69ms/step\n",
      "Epoch 15/100\n",
      "818/818 - 57s - loss: 1.2897e-04 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 16/100\n",
      "818/818 - 57s - loss: 1.6503e-04 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "818/818 - 57s - loss: 7.9799e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 18/100\n",
      "818/818 - 57s - loss: 3.7210e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 19/100\n",
      "818/818 - 57s - loss: 1.2635e-04 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 20/100\n",
      "818/818 - 57s - loss: 8.7888e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 21/100\n",
      "818/818 - 57s - loss: 1.1507e-04 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 22/100\n",
      "818/818 - 57s - loss: 4.1058e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 23/100\n",
      "818/818 - 57s - loss: 5.5224e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 24/100\n",
      "818/818 - 57s - loss: 9.4444e-05 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 25/100\n",
      "818/818 - 56s - loss: 4.3781e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 26/100\n",
      "818/818 - 56s - loss: 7.8129e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 27/100\n",
      "818/818 - 57s - loss: 8.8538e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 28/100\n",
      "818/818 - 57s - loss: 3.6055e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 29/100\n",
      "818/818 - 57s - loss: 5.2695e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 30/100\n",
      "818/818 - 57s - loss: 2.4434e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 31/100\n",
      "818/818 - 57s - loss: 7.4941e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 32/100\n",
      "818/818 - 57s - loss: 5.3803e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 33/100\n",
      "818/818 - 57s - loss: 1.8099e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 34/100\n",
      "818/818 - 56s - loss: 4.8329e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 35/100\n",
      "818/818 - 57s - loss: 7.4879e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 36/100\n",
      "818/818 - 57s - loss: 1.0538e-04 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 37/100\n",
      "818/818 - 57s - loss: 2.5949e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 38/100\n",
      "818/818 - 57s - loss: 2.7992e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 39/100\n",
      "818/818 - 57s - loss: 3.7522e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 40/100\n",
      "818/818 - 56s - loss: 4.5348e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 41/100\n",
      "818/818 - 57s - loss: 5.9387e-05 - binary_accuracy: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 42/100\n",
      "818/818 - 57s - loss: 7.3809e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9988 - 57s/epoch - 69ms/step\n",
      "Epoch 43/100\n",
      "818/818 - 57s - loss: 4.8739e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 44/100\n",
      "818/818 - 57s - loss: 7.2634e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 45/100\n",
      "818/818 - 57s - loss: 8.4558e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 46/100\n",
      "818/818 - 56s - loss: 1.7482e-05 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 47/100\n",
      "818/818 - 57s - loss: 1.2229e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 48/100\n",
      "818/818 - 57s - loss: 2.3622e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 49/100\n",
      "818/818 - 57s - loss: 7.4821e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 50/100\n",
      "818/818 - 57s - loss: 2.6776e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 51/100\n",
      "818/818 - 56s - loss: 2.2818e-05 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9987 - 56s/epoch - 69ms/step\n",
      "Epoch 52/100\n",
      "818/818 - 57s - loss: 1.0011e-04 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 53/100\n",
      "818/818 - 57s - loss: 6.0193e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 54/100\n",
      "818/818 - 57s - loss: 1.1234e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 55/100\n",
      "818/818 - 57s - loss: 5.9458e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 56/100\n",
      "818/818 - 57s - loss: 4.0629e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 57/100\n",
      "818/818 - 57s - loss: 3.1706e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 58/100\n",
      "818/818 - 56s - loss: 5.5562e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 59/100\n",
      "818/818 - 57s - loss: 1.8143e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 60/100\n",
      "818/818 - 56s - loss: 4.4560e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 61/100\n",
      "818/818 - 56s - loss: 4.6191e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 62/100\n",
      "818/818 - 57s - loss: 8.3236e-06 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 63/100\n",
      "818/818 - 57s - loss: 8.2599e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 64/100\n",
      "818/818 - 57s - loss: 2.9896e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 65/100\n",
      "818/818 - 56s - loss: 1.6971e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 66/100\n",
      "818/818 - 57s - loss: 4.3409e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 67/100\n",
      "818/818 - 56s - loss: 2.5754e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 68/100\n",
      "818/818 - 57s - loss: 5.1025e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 69/100\n",
      "818/818 - 57s - loss: 6.8921e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 70/100\n",
      "818/818 - 57s - loss: 1.6566e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 71/100\n",
      "818/818 - 57s - loss: 3.8687e-05 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 72/100\n",
      "818/818 - 57s - loss: 3.0000e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 73/100\n",
      "818/818 - 57s - loss: 2.5494e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "818/818 - 56s - loss: 8.2020e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 75/100\n",
      "818/818 - 56s - loss: 3.5436e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 76/100\n",
      "818/818 - 56s - loss: 7.9029e-06 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 77/100\n",
      "818/818 - 57s - loss: 1.1081e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 78/100\n",
      "818/818 - 57s - loss: 8.9989e-06 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 79/100\n",
      "818/818 - 56s - loss: 8.7151e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 80/100\n",
      "818/818 - 57s - loss: 2.9082e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 81/100\n",
      "818/818 - 56s - loss: 1.2813e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 82/100\n",
      "818/818 - 56s - loss: 1.4701e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 83/100\n",
      "818/818 - 56s - loss: 5.8491e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 84/100\n",
      "818/818 - 57s - loss: 3.4867e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 85/100\n",
      "818/818 - 56s - loss: 4.7726e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 86/100\n",
      "818/818 - 57s - loss: 6.1256e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 87/100\n",
      "818/818 - 56s - loss: 1.1903e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 88/100\n",
      "818/818 - 56s - loss: 9.9515e-06 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 89/100\n",
      "818/818 - 56s - loss: 2.1366e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 90/100\n",
      "818/818 - 56s - loss: 1.1381e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 91/100\n",
      "818/818 - 56s - loss: 1.6663e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 92/100\n",
      "818/818 - 56s - loss: 4.3610e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 93/100\n",
      "818/818 - 56s - loss: 3.4805e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "818/818 - 56s - loss: 7.0270e-06 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 95/100\n",
      "818/818 - 56s - loss: 6.6494e-06 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 96/100\n",
      "818/818 - 56s - loss: 4.5968e-06 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 97/100\n",
      "818/818 - 56s - loss: 4.4936e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 98/100\n",
      "818/818 - 56s - loss: 1.6687e-05 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 99/100\n",
      "818/818 - 56s - loss: 1.1090e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 100/100\n",
      "818/818 - 56s - loss: 3.5169e-06 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.999998927116394\n",
      "binary_accuracy validation:  0.9991018772125244\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.049643695\n",
      "train attribution time:  831.9495902061462\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.04874734\n",
      "validation attribution time:  92.73520135879517\n",
      "time:  7450.529189348221\n",
      "----- loop 3 :  [1090]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  19.97718119621277\n",
      "train data delta_a time:  759.6220293045044\n",
      "train data time:  779.6002116203308\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  2.2780685424804688\n",
      "validation data delta_a time:  81.55721974372864\n",
      "validation data time:  83.83628916740417\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "818/818 - 65s - loss: 0.0023 - binary_accuracy: 0.9995 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 65s/epoch - 80ms/step\n",
      "Epoch 2/100\n",
      "818/818 - 57s - loss: 8.3903e-04 - binary_accuracy: 0.9998 - val_loss: 0.0069 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 3/100\n",
      "818/818 - 57s - loss: 5.7435e-04 - binary_accuracy: 0.9998 - val_loss: 0.0071 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 4/100\n",
      "818/818 - 57s - loss: 3.9106e-04 - binary_accuracy: 0.9999 - val_loss: 0.0061 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 5/100\n",
      "818/818 - 57s - loss: 2.8093e-04 - binary_accuracy: 0.9999 - val_loss: 0.0067 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 6/100\n",
      "818/818 - 57s - loss: 1.9150e-04 - binary_accuracy: 0.9999 - val_loss: 0.0063 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 7/100\n",
      "818/818 - 57s - loss: 1.6134e-04 - binary_accuracy: 0.9999 - val_loss: 0.0068 - val_binary_accuracy: 0.9990 - 57s/epoch - 70ms/step\n",
      "Epoch 8/100\n",
      "818/818 - 57s - loss: 1.5127e-04 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 9/100\n",
      "818/818 - 57s - loss: 1.1505e-04 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 10/100\n",
      "818/818 - 57s - loss: 9.6161e-05 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 11/100\n",
      "818/818 - 57s - loss: 5.6942e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 12/100\n",
      "818/818 - 57s - loss: 9.6343e-05 - binary_accuracy: 1.0000 - val_loss: 0.0055 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 13/100\n",
      "818/818 - 57s - loss: 5.2390e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 14/100\n",
      "818/818 - 57s - loss: 5.4444e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 15/100\n",
      "818/818 - 57s - loss: 5.7300e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 16/100\n",
      "818/818 - 57s - loss: 7.7202e-05 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 17/100\n",
      "818/818 - 57s - loss: 4.3545e-05 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 18/100\n",
      "818/818 - 57s - loss: 5.5046e-05 - binary_accuracy: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 19/100\n",
      "818/818 - 57s - loss: 4.9058e-05 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 20/100\n",
      "818/818 - 57s - loss: 5.0302e-05 - binary_accuracy: 1.0000 - val_loss: 0.0060 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 21/100\n",
      "818/818 - 57s - loss: 8.8942e-05 - binary_accuracy: 1.0000 - val_loss: 0.0064 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 22/100\n",
      "818/818 - 57s - loss: 1.4871e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 23/100\n",
      "818/818 - 57s - loss: 2.0359e-05 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 24/100\n",
      "818/818 - 57s - loss: 3.4629e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 25/100\n",
      "818/818 - 57s - loss: 6.8529e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "818/818 - 57s - loss: 7.4043e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 27/100\n",
      "818/818 - 57s - loss: 9.8080e-06 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 28/100\n",
      "818/818 - 57s - loss: 2.3894e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 29/100\n",
      "818/818 - 57s - loss: 2.5012e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 30/100\n",
      "818/818 - 57s - loss: 4.1409e-05 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 31/100\n",
      "818/818 - 57s - loss: 1.2244e-05 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 32/100\n",
      "818/818 - 57s - loss: 8.6897e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 33/100\n",
      "818/818 - 57s - loss: 5.3762e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 34/100\n",
      "818/818 - 57s - loss: 2.3955e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 35/100\n",
      "818/818 - 57s - loss: 2.5991e-05 - binary_accuracy: 1.0000 - val_loss: 0.0065 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 36/100\n",
      "818/818 - 57s - loss: 7.7354e-06 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 37/100\n",
      "818/818 - 57s - loss: 2.5164e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 38/100\n",
      "818/818 - 57s - loss: 2.5717e-05 - binary_accuracy: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 39/100\n",
      "818/818 - 57s - loss: 4.7458e-06 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 40/100\n",
      "818/818 - 57s - loss: 3.7858e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 41/100\n",
      "818/818 - 57s - loss: 1.2881e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 42/100\n",
      "818/818 - 57s - loss: 5.7339e-05 - binary_accuracy: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9990 - 57s/epoch - 70ms/step\n",
      "Epoch 43/100\n",
      "818/818 - 57s - loss: 2.0462e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 44/100\n",
      "818/818 - 57s - loss: 1.8977e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 45/100\n",
      "818/818 - 57s - loss: 4.1541e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 46/100\n",
      "818/818 - 57s - loss: 1.1722e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 47/100\n",
      "818/818 - 57s - loss: 3.8063e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 48/100\n",
      "818/818 - 57s - loss: 1.6861e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 49/100\n",
      "818/818 - 57s - loss: 2.2242e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 50/100\n",
      "818/818 - 57s - loss: 8.6979e-06 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 51/100\n",
      "818/818 - 57s - loss: 6.0924e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 52/100\n",
      "818/818 - 57s - loss: 2.1415e-05 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 53/100\n",
      "818/818 - 57s - loss: 8.4325e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 54/100\n",
      "818/818 - 57s - loss: 1.0246e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 55/100\n",
      "818/818 - 57s - loss: 1.7137e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 56/100\n",
      "818/818 - 57s - loss: 1.6700e-05 - binary_accuracy: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 57/100\n",
      "818/818 - 57s - loss: 3.2456e-05 - binary_accuracy: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 58/100\n",
      "818/818 - 57s - loss: 6.1671e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 59/100\n",
      "818/818 - 57s - loss: 2.9927e-05 - binary_accuracy: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 60/100\n",
      "818/818 - 57s - loss: 7.6542e-06 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 61/100\n",
      "818/818 - 57s - loss: 3.0412e-06 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 62/100\n",
      "818/818 - 57s - loss: 1.1670e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 63/100\n",
      "818/818 - 57s - loss: 2.1255e-06 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 64/100\n",
      "818/818 - 57s - loss: 2.9984e-06 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 65/100\n",
      "818/818 - 57s - loss: 1.2477e-06 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 66/100\n",
      "818/818 - 57s - loss: 9.1660e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 67/100\n",
      "818/818 - 57s - loss: 8.7221e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 68/100\n",
      "818/818 - 57s - loss: 1.0618e-05 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 69/100\n",
      "818/818 - 57s - loss: 1.6107e-05 - binary_accuracy: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 70/100\n",
      "818/818 - 57s - loss: 1.2698e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 71/100\n",
      "818/818 - 57s - loss: 5.7033e-06 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 72/100\n",
      "818/818 - 57s - loss: 1.6793e-05 - binary_accuracy: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 73/100\n",
      "818/818 - 57s - loss: 5.2012e-05 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 74/100\n",
      "818/818 - 57s - loss: 3.1375e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 75/100\n",
      "818/818 - 57s - loss: 2.9324e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 76/100\n",
      "818/818 - 57s - loss: 1.1303e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 77/100\n",
      "818/818 - 57s - loss: 1.3541e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 78/100\n",
      "818/818 - 57s - loss: 8.4352e-06 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 79/100\n",
      "818/818 - 57s - loss: 3.8902e-06 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 80/100\n",
      "818/818 - 57s - loss: 2.2739e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 81/100\n",
      "818/818 - 57s - loss: 9.4818e-06 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 82/100\n",
      "818/818 - 57s - loss: 2.0855e-05 - binary_accuracy: 1.0000 - val_loss: 0.0095 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "818/818 - 57s - loss: 2.0691e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 84/100\n",
      "818/818 - 57s - loss: 5.7423e-06 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 85/100\n",
      "818/818 - 57s - loss: 9.8335e-06 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 86/100\n",
      "818/818 - 57s - loss: 6.6708e-05 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 87/100\n",
      "818/818 - 57s - loss: 7.1546e-06 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 88/100\n",
      "818/818 - 57s - loss: 9.7383e-06 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 89/100\n",
      "818/818 - 57s - loss: 1.0883e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 90/100\n",
      "818/818 - 57s - loss: 2.5881e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 91/100\n",
      "818/818 - 57s - loss: 2.4517e-05 - binary_accuracy: 1.0000 - val_loss: 0.0099 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 92/100\n",
      "818/818 - 57s - loss: 1.0718e-05 - binary_accuracy: 1.0000 - val_loss: 0.0097 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 93/100\n",
      "818/818 - 57s - loss: 8.1960e-06 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "818/818 - 57s - loss: 5.6250e-06 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 95/100\n",
      "818/818 - 57s - loss: 6.7026e-06 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 96/100\n",
      "818/818 - 57s - loss: 4.9026e-06 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 97/100\n",
      "818/818 - 57s - loss: 2.0472e-05 - binary_accuracy: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 98/100\n",
      "818/818 - 57s - loss: 2.1650e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 99/100\n",
      "818/818 - 57s - loss: 2.4856e-05 - binary_accuracy: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 100/100\n",
      "818/818 - 57s - loss: 3.0450e-05 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.9999937415122986\n",
      "binary_accuracy validation:  0.999025285243988\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.04955695\n",
      "train attribution time:  833.3714108467102\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.048589494\n",
      "validation attribution time:  92.69416403770447\n",
      "time:  7472.8497948646545\n",
      "----- loop 4 :  [1062]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  20.05927586555481\n",
      "train data delta_a time:  759.359610080719\n",
      "train data time:  779.4188859462738\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  2.2800700664520264\n",
      "validation data delta_a time:  81.75823473930359\n",
      "validation data time:  84.03930568695068\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "818/818 - 64s - loss: 0.0022 - binary_accuracy: 0.9995 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 64s/epoch - 79ms/step\n",
      "Epoch 2/100\n",
      "818/818 - 56s - loss: 8.5447e-04 - binary_accuracy: 0.9998 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 3/100\n",
      "818/818 - 57s - loss: 5.8265e-04 - binary_accuracy: 0.9998 - val_loss: 0.0073 - val_binary_accuracy: 0.9989 - 57s/epoch - 69ms/step\n",
      "Epoch 4/100\n",
      "818/818 - 57s - loss: 3.5425e-04 - binary_accuracy: 0.9999 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 5/100\n",
      "818/818 - 57s - loss: 2.6466e-04 - binary_accuracy: 0.9999 - val_loss: 0.0074 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 6/100\n",
      "818/818 - 56s - loss: 1.6800e-04 - binary_accuracy: 0.9999 - val_loss: 0.0065 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 7/100\n",
      "818/818 - 56s - loss: 1.3561e-04 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 8/100\n",
      "818/818 - 57s - loss: 1.0783e-04 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 9/100\n",
      "818/818 - 57s - loss: 8.0672e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 10/100\n",
      "818/818 - 57s - loss: 1.0003e-04 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 11/100\n",
      "818/818 - 57s - loss: 4.4132e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 12/100\n",
      "818/818 - 57s - loss: 7.2878e-05 - binary_accuracy: 1.0000 - val_loss: 0.0066 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 13/100\n",
      "818/818 - 57s - loss: 7.9195e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 14/100\n",
      "818/818 - 56s - loss: 1.5992e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 15/100\n",
      "818/818 - 56s - loss: 5.1753e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 16/100\n",
      "818/818 - 57s - loss: 3.8145e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 17/100\n",
      "818/818 - 57s - loss: 3.7691e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 18/100\n",
      "818/818 - 56s - loss: 6.9280e-05 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 19/100\n",
      "818/818 - 57s - loss: 5.7051e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 20/100\n",
      "818/818 - 56s - loss: 6.1544e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 21/100\n",
      "818/818 - 56s - loss: 1.5837e-05 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 22/100\n",
      "818/818 - 56s - loss: 2.4211e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 23/100\n",
      "818/818 - 56s - loss: 2.5390e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 24/100\n",
      "818/818 - 57s - loss: 4.5602e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 25/100\n",
      "818/818 - 57s - loss: 1.3865e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 26/100\n",
      "818/818 - 57s - loss: 7.7796e-06 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 27/100\n",
      "818/818 - 57s - loss: 8.3933e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 28/100\n",
      "818/818 - 57s - loss: 4.4219e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 29/100\n",
      "818/818 - 56s - loss: 5.3062e-06 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 30/100\n",
      "818/818 - 57s - loss: 2.0484e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 31/100\n",
      "818/818 - 56s - loss: 1.8119e-05 - binary_accuracy: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 32/100\n",
      "818/818 - 57s - loss: 3.4649e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 33/100\n",
      "818/818 - 57s - loss: 1.3133e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 34/100\n",
      "818/818 - 57s - loss: 8.9954e-06 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "818/818 - 57s - loss: 4.7401e-06 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 36/100\n",
      "818/818 - 56s - loss: 3.7681e-06 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 37/100\n",
      "818/818 - 56s - loss: 5.7667e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 38/100\n",
      "818/818 - 56s - loss: 1.7970e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 39/100\n",
      "818/818 - 57s - loss: 1.1861e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 40/100\n",
      "818/818 - 57s - loss: 1.9261e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 41/100\n",
      "818/818 - 57s - loss: 3.9525e-06 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 42/100\n",
      "818/818 - 57s - loss: 1.9993e-06 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 43/100\n",
      "818/818 - 56s - loss: 2.3611e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 44/100\n",
      "818/818 - 56s - loss: 7.3179e-06 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 45/100\n",
      "818/818 - 57s - loss: 3.7788e-06 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 46/100\n",
      "818/818 - 56s - loss: 3.1706e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 47/100\n",
      "818/818 - 56s - loss: 1.0372e-05 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 48/100\n",
      "818/818 - 56s - loss: 2.1085e-06 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9993 - 56s/epoch - 69ms/step\n",
      "Epoch 49/100\n",
      "818/818 - 56s - loss: 6.0827e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 50/100\n",
      "818/818 - 57s - loss: 3.1248e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 51/100\n",
      "818/818 - 57s - loss: 2.0463e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9993 - 57s/epoch - 69ms/step\n",
      "Epoch 52/100\n",
      "818/818 - 57s - loss: 4.3305e-06 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 53/100\n",
      "818/818 - 56s - loss: 1.4275e-06 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 54/100\n",
      "818/818 - 57s - loss: 1.8779e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 55/100\n",
      "818/818 - 57s - loss: 6.6045e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 56/100\n",
      "818/818 - 57s - loss: 8.7633e-06 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 57/100\n",
      "818/818 - 56s - loss: 2.0412e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 58/100\n",
      "818/818 - 57s - loss: 4.8953e-06 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9993 - 57s/epoch - 69ms/step\n",
      "Epoch 59/100\n",
      "818/818 - 57s - loss: 2.7280e-06 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9993 - 57s/epoch - 69ms/step\n",
      "Epoch 60/100\n",
      "818/818 - 56s - loss: 1.4173e-06 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 61/100\n",
      "818/818 - 56s - loss: 5.0365e-05 - binary_accuracy: 1.0000 - val_loss: 0.0068 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 62/100\n",
      "818/818 - 56s - loss: 3.0856e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 63/100\n",
      "818/818 - 56s - loss: 7.9721e-06 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9993 - 56s/epoch - 69ms/step\n",
      "Epoch 64/100\n",
      "818/818 - 56s - loss: 8.0758e-06 - binary_accuracy: 1.0000 - val_loss: 0.0063 - val_binary_accuracy: 0.9993 - 56s/epoch - 69ms/step\n",
      "Epoch 65/100\n",
      "818/818 - 56s - loss: 5.2156e-06 - binary_accuracy: 1.0000 - val_loss: 0.0067 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 66/100\n",
      "818/818 - 56s - loss: 1.2402e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 67/100\n",
      "818/818 - 57s - loss: 5.6061e-06 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 68/100\n",
      "818/818 - 56s - loss: 4.7023e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 69/100\n",
      "818/818 - 56s - loss: 3.3977e-05 - binary_accuracy: 1.0000 - val_loss: 0.0072 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 70/100\n",
      "818/818 - 56s - loss: 2.2183e-05 - binary_accuracy: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 71/100\n",
      "818/818 - 57s - loss: 4.8056e-05 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 72/100\n",
      "818/818 - 57s - loss: 1.0396e-05 - binary_accuracy: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 73/100\n",
      "818/818 - 57s - loss: 8.5052e-06 - binary_accuracy: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 74/100\n",
      "818/818 - 57s - loss: 1.5556e-06 - binary_accuracy: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 75/100\n",
      "818/818 - 57s - loss: 1.1706e-06 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 76/100\n",
      "818/818 - 57s - loss: 3.8200e-06 - binary_accuracy: 1.0000 - val_loss: 0.0099 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 77/100\n",
      "818/818 - 57s - loss: 4.1451e-05 - binary_accuracy: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 78/100\n",
      "818/818 - 57s - loss: 2.8532e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 79/100\n",
      "818/818 - 57s - loss: 1.3155e-05 - binary_accuracy: 1.0000 - val_loss: 0.0087 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 80/100\n",
      "818/818 - 56s - loss: 1.5097e-05 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 81/100\n",
      "818/818 - 57s - loss: 1.3126e-05 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 82/100\n",
      "818/818 - 57s - loss: 3.3699e-06 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 83/100\n",
      "818/818 - 57s - loss: 5.7044e-06 - binary_accuracy: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 84/100\n",
      "818/818 - 56s - loss: 1.1802e-06 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9991 - 56s/epoch - 69ms/step\n",
      "Epoch 85/100\n",
      "818/818 - 57s - loss: 1.5183e-06 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 86/100\n",
      "818/818 - 57s - loss: 4.5502e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 87/100\n",
      "818/818 - 57s - loss: 1.6950e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 88/100\n",
      "818/818 - 57s - loss: 2.3317e-05 - binary_accuracy: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 89/100\n",
      "818/818 - 57s - loss: 3.5482e-05 - binary_accuracy: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 90/100\n",
      "818/818 - 57s - loss: 3.0991e-05 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 91/100\n",
      "818/818 - 56s - loss: 6.2494e-06 - binary_accuracy: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "818/818 - 57s - loss: 3.4768e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 93/100\n",
      "818/818 - 56s - loss: 5.4970e-06 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "818/818 - 57s - loss: 1.5412e-05 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 95/100\n",
      "818/818 - 56s - loss: 6.9312e-06 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9992 - 56s/epoch - 69ms/step\n",
      "Epoch 96/100\n",
      "818/818 - 57s - loss: 5.1859e-06 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 97/100\n",
      "818/818 - 57s - loss: 1.5702e-06 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9991 - 57s/epoch - 69ms/step\n",
      "Epoch 98/100\n",
      "818/818 - 57s - loss: 8.9930e-07 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9992 - 57s/epoch - 69ms/step\n",
      "Epoch 99/100\n",
      "818/818 - 57s - loss: 3.6544e-05 - binary_accuracy: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "Epoch 100/100\n",
      "818/818 - 57s - loss: 4.1054e-05 - binary_accuracy: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9990 - 57s/epoch - 69ms/step\n",
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.9999862909317017\n",
      "binary_accuracy validation:  0.999025285243988\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.05121044\n",
      "train attribution time:  832.5682928562164\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.050430465\n",
      "validation attribution time:  92.9013524055481\n",
      "time:  7451.352583646774\n",
      "----- loop 5 :  [1035]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  20.067243814468384\n",
      "train data delta_a time:  758.4224090576172\n",
      "train data time:  778.4896528720856\n",
      "########## validation data ##########\n",
      "validation data delta_l time:  2.2884347438812256\n",
      "validation data delta_a time:  81.2374575138092\n",
      "validation data time:  83.52589225769043\n",
      "########## training new model ##########\n",
      "Epoch 1/100\n",
      "818/818 - 65s - loss: 0.0072 - binary_accuracy: 0.9982 - val_loss: 0.0112 - val_binary_accuracy: 0.9980 - 65s/epoch - 79ms/step\n",
      "Epoch 2/100\n",
      "818/818 - 56s - loss: 0.0031 - binary_accuracy: 0.9991 - val_loss: 0.0096 - val_binary_accuracy: 0.9983 - 56s/epoch - 69ms/step\n",
      "Epoch 3/100\n",
      "818/818 - 56s - loss: 0.0019 - binary_accuracy: 0.9994 - val_loss: 0.0089 - val_binary_accuracy: 0.9985 - 56s/epoch - 68ms/step\n",
      "Epoch 4/100\n",
      "818/818 - 56s - loss: 0.0013 - binary_accuracy: 0.9996 - val_loss: 0.0085 - val_binary_accuracy: 0.9986 - 56s/epoch - 69ms/step\n",
      "Epoch 5/100\n",
      "818/818 - 56s - loss: 9.8672e-04 - binary_accuracy: 0.9997 - val_loss: 0.0095 - val_binary_accuracy: 0.9985 - 56s/epoch - 69ms/step\n",
      "Epoch 6/100\n",
      "818/818 - 56s - loss: 8.6185e-04 - binary_accuracy: 0.9997 - val_loss: 0.0087 - val_binary_accuracy: 0.9986 - 56s/epoch - 69ms/step\n",
      "Epoch 7/100\n",
      "818/818 - 56s - loss: 5.3448e-04 - binary_accuracy: 0.9998 - val_loss: 0.0077 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 8/100\n",
      "818/818 - 56s - loss: 4.0285e-04 - binary_accuracy: 0.9998 - val_loss: 0.0079 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 9/100\n",
      "818/818 - 56s - loss: 3.0331e-04 - binary_accuracy: 0.9999 - val_loss: 0.0078 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 10/100\n",
      "818/818 - 56s - loss: 2.5985e-04 - binary_accuracy: 0.9999 - val_loss: 0.0075 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 11/100\n",
      "818/818 - 56s - loss: 1.7582e-04 - binary_accuracy: 0.9999 - val_loss: 0.0077 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 12/100\n",
      "818/818 - 56s - loss: 1.9996e-04 - binary_accuracy: 0.9999 - val_loss: 0.0084 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 13/100\n",
      "818/818 - 56s - loss: 1.5211e-04 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 14/100\n",
      "818/818 - 56s - loss: 1.1622e-04 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 15/100\n",
      "818/818 - 56s - loss: 1.2659e-04 - binary_accuracy: 0.9999 - val_loss: 0.0083 - val_binary_accuracy: 0.9988 - 56s/epoch - 68ms/step\n",
      "Epoch 16/100\n",
      "818/818 - 56s - loss: 9.1073e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 17/100\n",
      "818/818 - 56s - loss: 6.6469e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9988 - 56s/epoch - 68ms/step\n",
      "Epoch 18/100\n",
      "818/818 - 56s - loss: 9.2238e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 19/100\n",
      "818/818 - 56s - loss: 6.6315e-05 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 20/100\n",
      "818/818 - 56s - loss: 1.1048e-04 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 21/100\n",
      "818/818 - 56s - loss: 6.9773e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9987 - 56s/epoch - 69ms/step\n",
      "Epoch 22/100\n",
      "818/818 - 56s - loss: 6.0830e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 23/100\n",
      "818/818 - 56s - loss: 4.3555e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 24/100\n",
      "818/818 - 56s - loss: 4.8344e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 25/100\n",
      "818/818 - 56s - loss: 5.4656e-05 - binary_accuracy: 1.0000 - val_loss: 0.0073 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 26/100\n",
      "818/818 - 56s - loss: 6.9788e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 27/100\n",
      "818/818 - 56s - loss: 3.0461e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 28/100\n",
      "818/818 - 56s - loss: 3.4662e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 29/100\n",
      "818/818 - 56s - loss: 6.4157e-05 - binary_accuracy: 1.0000 - val_loss: 0.0076 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 30/100\n",
      "818/818 - 56s - loss: 2.8882e-05 - binary_accuracy: 1.0000 - val_loss: 0.0069 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 31/100\n",
      "818/818 - 56s - loss: 2.1901e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 32/100\n",
      "818/818 - 56s - loss: 4.0861e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 33/100\n",
      "818/818 - 56s - loss: 4.5393e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 34/100\n",
      "818/818 - 56s - loss: 3.5930e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 35/100\n",
      "818/818 - 56s - loss: 1.7100e-05 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 36/100\n",
      "818/818 - 56s - loss: 6.0137e-05 - binary_accuracy: 1.0000 - val_loss: 0.0070 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 37/100\n",
      "818/818 - 56s - loss: 3.4395e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 38/100\n",
      "818/818 - 56s - loss: 1.3352e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 39/100\n",
      "818/818 - 56s - loss: 3.7750e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 40/100\n",
      "818/818 - 56s - loss: 5.5326e-05 - binary_accuracy: 1.0000 - val_loss: 0.0078 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 41/100\n",
      "818/818 - 56s - loss: 3.3838e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 42/100\n",
      "818/818 - 56s - loss: 6.7622e-06 - binary_accuracy: 1.0000 - val_loss: 0.0088 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 43/100\n",
      "818/818 - 56s - loss: 3.8007e-05 - binary_accuracy: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "818/818 - 56s - loss: 1.6481e-05 - binary_accuracy: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 45/100\n",
      "818/818 - 56s - loss: 2.9731e-05 - binary_accuracy: 1.0000 - val_loss: 0.0075 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 46/100\n",
      "818/818 - 56s - loss: 1.2454e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 47/100\n",
      "818/818 - 56s - loss: 1.2164e-05 - binary_accuracy: 1.0000 - val_loss: 0.0095 - val_binary_accuracy: 0.9987 - 56s/epoch - 68ms/step\n",
      "Epoch 48/100\n",
      "818/818 - 56s - loss: 3.0189e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 49/100\n",
      "818/818 - 56s - loss: 4.0917e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 50/100\n",
      "818/818 - 56s - loss: 3.9011e-05 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 51/100\n",
      "818/818 - 56s - loss: 3.5243e-05 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 52/100\n",
      "818/818 - 56s - loss: 2.3970e-05 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 53/100\n",
      "818/818 - 56s - loss: 2.4642e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 54/100\n",
      "818/818 - 56s - loss: 2.0242e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 55/100\n",
      "818/818 - 56s - loss: 1.6633e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 56/100\n",
      "818/818 - 56s - loss: 4.7323e-06 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 57/100\n",
      "818/818 - 56s - loss: 1.9775e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 58/100\n",
      "818/818 - 56s - loss: 1.1327e-05 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 59/100\n",
      "818/818 - 56s - loss: 4.3802e-05 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 60/100\n",
      "818/818 - 56s - loss: 6.9009e-06 - binary_accuracy: 1.0000 - val_loss: 0.0079 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 61/100\n",
      "818/818 - 56s - loss: 2.1038e-06 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 62/100\n",
      "818/818 - 56s - loss: 3.3929e-06 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 63/100\n",
      "818/818 - 56s - loss: 7.6692e-05 - binary_accuracy: 1.0000 - val_loss: 0.0102 - val_binary_accuracy: 0.9985 - 56s/epoch - 69ms/step\n",
      "Epoch 64/100\n",
      "818/818 - 56s - loss: 2.5401e-05 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 65/100\n",
      "818/818 - 56s - loss: 3.9672e-06 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 66/100\n",
      "818/818 - 56s - loss: 5.0392e-06 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 67/100\n",
      "818/818 - 56s - loss: 2.0377e-05 - binary_accuracy: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 68/100\n",
      "818/818 - 56s - loss: 6.7306e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 69/100\n",
      "818/818 - 56s - loss: 1.0374e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 70/100\n",
      "818/818 - 56s - loss: 1.3389e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 71/100\n",
      "818/818 - 56s - loss: 1.3124e-05 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9990 - 56s/epoch - 68ms/step\n",
      "Epoch 72/100\n",
      "818/818 - 56s - loss: 3.6102e-05 - binary_accuracy: 1.0000 - val_loss: 0.0081 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 73/100\n",
      "818/818 - 56s - loss: 6.6713e-06 - binary_accuracy: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 74/100\n",
      "818/818 - 56s - loss: 6.1404e-06 - binary_accuracy: 1.0000 - val_loss: 0.0074 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 75/100\n",
      "818/818 - 56s - loss: 5.3554e-05 - binary_accuracy: 1.0000 - val_loss: 0.0085 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 76/100\n",
      "818/818 - 56s - loss: 1.4926e-05 - binary_accuracy: 1.0000 - val_loss: 0.0082 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 77/100\n",
      "818/818 - 56s - loss: 3.8710e-06 - binary_accuracy: 1.0000 - val_loss: 0.0077 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 78/100\n",
      "818/818 - 56s - loss: 1.8702e-05 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 79/100\n",
      "818/818 - 56s - loss: 4.1380e-05 - binary_accuracy: 1.0000 - val_loss: 0.0080 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 80/100\n",
      "818/818 - 56s - loss: 7.6001e-06 - binary_accuracy: 1.0000 - val_loss: 0.0084 - val_binary_accuracy: 0.9987 - 56s/epoch - 69ms/step\n",
      "Epoch 81/100\n",
      "818/818 - 56s - loss: 1.6462e-05 - binary_accuracy: 1.0000 - val_loss: 0.0083 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 82/100\n",
      "818/818 - 56s - loss: 2.5865e-06 - binary_accuracy: 1.0000 - val_loss: 0.0092 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 83/100\n",
      "818/818 - 56s - loss: 2.3465e-05 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 84/100\n",
      "818/818 - 56s - loss: 2.6234e-05 - binary_accuracy: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 0.9988 - 56s/epoch - 68ms/step\n",
      "Epoch 85/100\n",
      "818/818 - 56s - loss: 8.9984e-06 - binary_accuracy: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 86/100\n",
      "818/818 - 56s - loss: 1.7079e-05 - binary_accuracy: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 87/100\n",
      "818/818 - 56s - loss: 4.3545e-05 - binary_accuracy: 1.0000 - val_loss: 0.0095 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n",
      "Epoch 88/100\n",
      "818/818 - 56s - loss: 1.0514e-05 - binary_accuracy: 1.0000 - val_loss: 0.0095 - val_binary_accuracy: 0.9987 - 56s/epoch - 69ms/step\n",
      "Epoch 89/100\n",
      "818/818 - 56s - loss: 7.2664e-06 - binary_accuracy: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 0.9989 - 56s/epoch - 68ms/step\n",
      "Epoch 90/100\n",
      "818/818 - 56s - loss: 3.6508e-05 - binary_accuracy: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 91/100\n",
      "818/818 - 56s - loss: 1.3502e-05 - binary_accuracy: 1.0000 - val_loss: 0.0088 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 92/100\n",
      "818/818 - 56s - loss: 1.3349e-05 - binary_accuracy: 1.0000 - val_loss: 0.0096 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 93/100\n",
      "818/818 - 56s - loss: 1.0678e-05 - binary_accuracy: 1.0000 - val_loss: 0.0093 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 94/100\n",
      "818/818 - 56s - loss: 1.4338e-05 - binary_accuracy: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 95/100\n",
      "818/818 - 56s - loss: 5.0288e-05 - binary_accuracy: 1.0000 - val_loss: 0.0091 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 96/100\n",
      "818/818 - 56s - loss: 1.8516e-05 - binary_accuracy: 1.0000 - val_loss: 0.0090 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 97/100\n",
      "818/818 - 56s - loss: 4.7591e-06 - binary_accuracy: 1.0000 - val_loss: 0.0089 - val_binary_accuracy: 0.9990 - 56s/epoch - 69ms/step\n",
      "Epoch 98/100\n",
      "818/818 - 56s - loss: 7.3731e-06 - binary_accuracy: 1.0000 - val_loss: 0.0086 - val_binary_accuracy: 0.9990 - 56s/epoch - 68ms/step\n",
      "Epoch 99/100\n",
      "818/818 - 56s - loss: 6.6284e-05 - binary_accuracy: 1.0000 - val_loss: 0.0094 - val_binary_accuracy: 0.9989 - 56s/epoch - 69ms/step\n",
      "Epoch 100/100\n",
      "818/818 - 56s - loss: 7.7708e-05 - binary_accuracy: 1.0000 - val_loss: 0.0097 - val_binary_accuracy: 0.9988 - 56s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## binary acc & mse ##########\n",
      "binary_accuracy train:  0.9999852180480957\n",
      "binary_accuracy validation:  0.9988247156143188\n",
      "---- attribution train -----\n",
      "attr_mse train:  0.0495432\n",
      "train attribution time:  830.7272202968597\n",
      "---- attribution validation -----\n",
      "attr_mse validation:  0.048719242\n",
      "validation attribution time:  92.6201343536377\n",
      "time:  7407.340275526047\n",
      "----- loop 6 :  [1004]  -----\n",
      "########## train data ##########\n",
      "train data delta_l time:  19.991868257522583\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[400400] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Sum]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 308>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[38;5;66;03m#print(\"Model saving completed...\")\u001b[39;00m\n\u001b[0;32m    307\u001b[0m x\u001b[38;5;241m=\u001b[39mTestTranslate()\n\u001b[1;32m--> 308\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mTestTranslate.test_translate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m         gg\u001b[38;5;241m.\u001b[39mwatch(x)\n\u001b[0;32m     87\u001b[0m         loss \u001b[38;5;241m=\u001b[39m new_model(x)\n\u001b[1;32m---> 88\u001b[0m     ggt \u001b[38;5;241m=\u001b[39m \u001b[43mgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m gt \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mgradient(ggt, x)\n\u001b[0;32m     90\u001b[0m ans \u001b[38;5;241m=\u001b[39m gt \u001b[38;5;241m*\u001b[39m (mk[j] \u001b[38;5;241m*\u001b[39m mk[j])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1348\u001b[0m, in \u001b[0;36m_SubGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1346\u001b[0m   gy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mgrad\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m   gy \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mmath_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mry\u001b[49m\u001b[43m)\u001b[49m, sy)\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (gx, gy)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[400400] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Sum]"
     ]
    }
   ],
   "source": [
    "class TestTranslate(unittest.TestCase):\n",
    "\n",
    "    def test_translate(self):\n",
    "\n",
    "        s1 = 75\n",
    "        s2 = 75\n",
    "        s3 = 75\n",
    "        new_model = newmodel(model)\n",
    "        # method = 'riemann_left', 'riemann_right', 'riemann_middle', 'riemann_trapezoid', 'gausslegendre'\n",
    "        n_steps = 6\n",
    "        ig  = IntegratedGradients1(new_model,\n",
    "                    layer=new_model.layers[1],\n",
    "                    n_steps=n_steps,\n",
    "                    method='riemann_trapezoid',\n",
    "                    internal_batch_size=32)\n",
    "        type_weight = 1\n",
    "        learning_rate_value = 0.0001\n",
    "        batch_size_num = 32\n",
    "        epochs_value = 100\n",
    "        losses = {\"classifier_model\": \"binary_crossentropy\"}\n",
    "        lossWeights = {\"classifier_model\": type_weight}\n",
    "        metrics = {\"classifier_model\": \"binary_accuracy\"}\n",
    "        alpha = 0.5\n",
    "        eta = 0.5\n",
    "        print('Start: ', get_gpu_memory())\n",
    "        for i in range(30):\n",
    "            print('----- loop', i, ': ', get_gpu_memory(), ' -----')\n",
    "            start = time.time()\n",
    "        #---產生資料---\n",
    "            # --- train data---\n",
    "            print('########## train data ##########')\n",
    "            start_train = time.time()\n",
    "            start_delta_l = time.time()\n",
    "            for b in range(0,num_train,s1):\n",
    "                e = b + s1\n",
    "                if e>num_train: e = num_train\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('xtrain[b:e] shape: ', xtrain[b:e].shape) #(s,1001,32)\n",
    "                #print('ytrain[b:e] shape: ', ytrain[b:e].shape) #(s,36)\n",
    "\n",
    "                # delta_l = -alpha * grad_loss\n",
    "                with tf.GradientTape() as g:\n",
    "                    x = xtrain[b:e]\n",
    "                    y = ytrain[b:e]\n",
    "                    g.watch(x)\n",
    "                    y_true = y\n",
    "                    y_pred = new_model(x)\n",
    "                    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "                    #print('loss: ', loss)\n",
    "                gt = g.gradient(loss, x)\n",
    "                #print('gt: ', gt)\n",
    "                delta_l = -alpha * gt\n",
    "                #print('delta_l shape: ', delta_l.shape) #(s,1001,32)\n",
    "                newtrain[b:e] = xtrain[b:e] + delta_l\n",
    "            end_delta_l = time.time()\n",
    "            print('train data delta_l time: ', end_delta_l-start_delta_l)\n",
    "\n",
    "            start_delta_a = time.time()\n",
    "            for b in range(0,num_train,s2):\n",
    "                e = b + s2\n",
    "                if e>num_train: e = num_train\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('xtrain[b:e] shape: ', xtrain[b:e].shape) #(s,1001,32)\n",
    "                #print('ytrain[b:e] shape: ', ytrain[b:e].shape) #(s,36)\n",
    "\n",
    "                # delta_a = -eta * ( attrx - attrx_ ) * attrx_gradient\n",
    "                x = np.asarray(xtrain).astype('float32')\n",
    "                predictions = new_model(xtrain[b:e]).numpy()\n",
    "                #print('86: ', get_gpu_memory())\n",
    "                explanation = ig.explain(x[b:e], baselines=None, target=predictions, attribute_to_layer_inputs=False).attributions[0]\n",
    "                #print('88: ', get_gpu_memory())\n",
    "                attrx = explanation\n",
    "                #print('attrx shape: ', attrx.shape) #(s,1001,32)\n",
    "                attrx_ = xtrain_attr[b:e]\n",
    "                #print('attrx_ shape: ', attrx_.shape) #(s,1001,32)\n",
    "                mk = ig._mk()\n",
    "                #attrx_gradient = attrx_grad(xtrain[b:e], attrx, mk, new_model, n_steps)\n",
    "                zk_grad_x = attrx / xtrain[b:e]\n",
    "                zk_grad2_zk = 0\n",
    "                for j in range(n_steps):\n",
    "                    zk = xtrain[b:e] * mk[j]\n",
    "                    with tf.GradientTape() as g:\n",
    "                        x = xtrain[b:e]\n",
    "                        g.watch(x)\n",
    "                        with tf.GradientTape() as gg:\n",
    "                            gg.watch(x)\n",
    "                            loss = new_model(x)\n",
    "                        ggt = gg.gradient(loss, x)\n",
    "                    gt = g.gradient(ggt, x)\n",
    "                    ans = gt * (mk[j] * mk[j])\n",
    "                    zk_grad2_zk += ans\n",
    "                attrx_gradient = zk_grad_x + (xtrain[b:e]/n_steps) + zk_grad2_zk\n",
    "                #print('attrx_gradient shape: ', attrx_gradient.shape) #(s,1001,32)\n",
    "                delta_a = -eta * ( attrx - attrx_ ) * attrx_gradient\n",
    "                #print('delta_a shape: ', delta_a.shape) #(s,1001,32)\n",
    "                newtrain[b:e] = newtrain[b:e] + delta_a\n",
    "            end_delta_a = time.time()\n",
    "            print('train data delta_a time: ', end_delta_a-start_delta_a)\n",
    "            #saveTestTrainData('D:/00/train.npy', newx0)\n",
    "            #print(newx)\n",
    "            end_train = time.time()\n",
    "            print('train data time: ', end_train-start_train)\n",
    "            '''\n",
    "            new_model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "            x = np.asarray(newtrain).astype('float32')\n",
    "            y = np.asarray(ytrain[0:num_train]).astype('float32')\n",
    "            new_model.evaluate(x, y)\n",
    "            '''\n",
    "\n",
    "            # --- validation data ---\n",
    "            print('########## validation data ##########')\n",
    "            start_validation = time.time()\n",
    "            start_delta_l = time.time()\n",
    "            for b in range(0,num_validation,s1):\n",
    "                e = b + s1\n",
    "                if e>num_validation: e = num_validation\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('xvalidation[b:e] shape: ', xvalidation[b:e].shape) #(s,1001,32)\n",
    "                #print('yvalidation[b:e] shape: ', yvalidation[b:e].shape) #(s,36)\n",
    "\n",
    "                # delta_l = -alpha * grad_loss\n",
    "                with tf.GradientTape() as g:\n",
    "                    x = xvalidation[b:e]\n",
    "                    y = yvalidation[b:e]\n",
    "                    g.watch(x)\n",
    "                    y_true = y\n",
    "                    y_pred = new_model(x)\n",
    "                    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "                    #print('loss: ', loss)\n",
    "                #print('149: ', get_gpu_memory())\n",
    "                gt = g.gradient(loss, x)\n",
    "                #print('151: ', get_gpu_memory())\n",
    "                #print('gt: ', gt)\n",
    "                delta_l = -alpha * gt\n",
    "                #print('delta_l shape: ', delta_l.shape) #(s,1001,32)\n",
    "                newvalidation[b:e] = xvalidation[b:e] + delta_l\n",
    "            end_delta_l = time.time()\n",
    "            print('validation data delta_l time: ', end_delta_l-start_delta_l)\n",
    "\n",
    "            start_delta_a = time.time()\n",
    "            for b in range(0,num_validation,s2):\n",
    "                e = b + s2\n",
    "                if e>num_validation: e = num_validation\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('xvalidation[b:e] shape: ', xvalidation[b:e].shape) #(s,1001,32)\n",
    "                #print('yvalidation[b:e] shape: ', yvalidation[b:e].shape) #(s,36)\n",
    "\n",
    "                # delta_a = -eta * ( attrx - attrx_ ) * attrx_gradient\n",
    "                x = np.asarray(xvalidation).astype('float32')\n",
    "                predictions = new_model(xvalidation[b:e]).numpy()\n",
    "                #print('166: ', get_gpu_memory())\n",
    "                explanation = ig.explain(x[b:e], baselines=None, target=predictions, attribute_to_layer_inputs=False).attributions[0]\n",
    "                #print('168: ', get_gpu_memory())\n",
    "                attrx = explanation\n",
    "                #print('attrx shape: ', attrx.shape) #(s,1001,32)\n",
    "                attrx_ = xvalidation_attr[b:e]\n",
    "                #print('attrx_ shape: ', attrx_.shape) #(s,1001,32)\n",
    "                mk = ig._mk()\n",
    "                #attrx_gradient = attrx_grad(xvalidation[b:e], attrx, mk, new_model, n_steps)\n",
    "                zk_grad_x = attrx / xvalidation[b:e]\n",
    "                zk_grad2_zk = 0\n",
    "                for j in range(n_steps):\n",
    "                    zk = xvalidation[b:e] * mk[j]\n",
    "                    with tf.GradientTape() as g:\n",
    "                        x = xvalidation[b:e]\n",
    "                        g.watch(x)\n",
    "                        with tf.GradientTape() as gg:\n",
    "                            gg.watch(x)\n",
    "                            loss = new_model(x)\n",
    "                        ggt = gg.gradient(loss, x)\n",
    "                    gt = g.gradient(ggt, x)\n",
    "                    ans = gt * (mk[j] * mk[j])\n",
    "                    zk_grad2_zk += ans\n",
    "                attrx_gradient = zk_grad_x + (xvalidation[b:e]/n_steps) + zk_grad2_zk\n",
    "                #print('attrx_gradient shape: ', attrx_gradient.shape) #(s,1001,32)\n",
    "                delta_a = -eta * ( attrx - attrx_ ) * attrx_gradient\n",
    "                #print('delta_a shape: ', delta_a.shape) #(s,1001,32)\n",
    "                newvalidation[b:e] = newvalidation[b:e] + delta_a\n",
    "            end_delta_a = time.time()\n",
    "            print('validation data delta_a time: ', end_delta_a-start_delta_a)\n",
    "            #saveTestvalidationData('D:/00/validation.npy', newx0)\n",
    "            #print(newx)\n",
    "            end_validation = time.time()\n",
    "            print('validation data time: ', end_validation-start_validation)\n",
    "            '''\n",
    "            new_model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "            x = np.asarray(newvalidation).astype('float32')\n",
    "            y = np.asarray(yvalidation[0:num_validation]).astype('float32')\n",
    "            new_model.evaluate(x, y)\n",
    "            '''\n",
    "\n",
    "        #----- training new model -----\n",
    "            print('########## training new model ##########')\n",
    "            xtrain0 = xtrain[0:num_train]\n",
    "            ytrain0 = ytrain[0:num_train]\n",
    "            x_train = np.concatenate((xtrain0, newtrain), axis=0)\n",
    "            x_train = np.asarray(x_train).astype('float32')\n",
    "            y_train = np.concatenate((ytrain0, ytrain0), axis=0)\n",
    "            xvalidation0 = xvalidation[0:num_validation]\n",
    "            yvalidation0 = yvalidation[0:num_validation]\n",
    "            x_validation = np.concatenate((xvalidation0, newvalidation), axis=0)\n",
    "            x_validation = np.asarray(x_validation).astype('float32')\n",
    "            y_validation = np.concatenate((yvalidation0, yvalidation0), axis=0)\n",
    "            #print('x_train shape: ', x_train.shape) #(num_train*2,1001,32)\n",
    "            #print('y_train shape: ', y_train.shape) #(num_train*2,36)\n",
    "            #print('x_validation shape: ', x_validation.shape) #(num_validation*2,1001,32)\n",
    "            #print('y_validation shape: ', y_validation.shape) #(num_validation*2,36)\n",
    "            new_model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "\n",
    "            history = new_model.fit(\n",
    "                          x = x_train,\n",
    "                          y = y_train,\n",
    "                          epochs = epochs_value, #100 200 500 3000\n",
    "                          verbose = 2, #set visibility\n",
    "                          #callbacks = [model_checkpoint_callback],\n",
    "                          validation_data = (x_validation, y_validation), #-> has issue \n",
    "                          batch_size = batch_size_num\n",
    "                          )\n",
    "\n",
    "        #----- binary acc & mse -----\n",
    "            print('########## binary acc & mse ##########')\n",
    "\n",
    "            binary_acc_train .append(history.history['binary_accuracy'][epochs_value-1])\n",
    "            binary_acc_validation .append(history.history['val_binary_accuracy'][epochs_value-1])\n",
    "            print('binary_accuracy train: ', history.history['binary_accuracy'][epochs_value-1])\n",
    "            print('binary_accuracy validation: ', history.history['val_binary_accuracy'][epochs_value-1])\n",
    "\n",
    "            # ---- attribution train -----\n",
    "            print('---- attribution train -----')\n",
    "            start_att = time.time()\n",
    "            for b in range(0,num_train*2,s3):\n",
    "                e = b + s3\n",
    "                if e>num_train*2: e = num_train*2\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('x_train[b:e] shape: ', x_train[b:e].shape)\n",
    "                #print('y_train[b:e] shape: ', y_train[b:e].shape)\n",
    "\n",
    "                predictions = y_train[b:e]\n",
    "                #print('254: ', get_gpu_memory())\n",
    "                explanation = ig.explain(x_train[b:e], baselines=None, target=predictions, attribute_to_layer_inputs=False)\n",
    "                #print('256: ', get_gpu_memory())\n",
    "                attr_train[b:e] = explanation.attributions[0]\n",
    "\n",
    "            attr_train_pred = tf.abs(attr_train)\n",
    "            attr_train_pred = tf.reduce_sum(attr_train_pred, axis=2).numpy()/32\n",
    "            #print('attr_train_pred shape: ', attr_train_pred.shape) #(num_train*2,1001)\n",
    "            attr_train_true = xtrain_attr[0:num_train]\n",
    "            attr_train_true = tf.reduce_sum(attr_train_true, axis=2).numpy()/32\n",
    "            attr_train_true = tf.concat([attr_train_true, attr_train_true], 0)\n",
    "            #print('attr_train_true shape: ', attr_train_true.shape) #(num_train*2,1001)\n",
    "            #average = tf.reduce_sum(attrx_pred, axis=1).numpy()/1001\n",
    "            #print('average: ', average)\n",
    "            mse = tf.keras.losses.MeanSquaredError()\n",
    "            attr_mse = mse(attr_train_true, attr_train_pred).numpy()\n",
    "            attr_mse_train.append(attr_mse)\n",
    "            print('attr_mse train: ', attr_mse)\n",
    "            end_att = time.time()\n",
    "            print('train attribution time: ', end_att-start_att)\n",
    "            # ---- attributoin validation -----\n",
    "            print('---- attribution validation -----')\n",
    "            start_att = time.time()\n",
    "            for b in range(0,num_validation*2,s3):\n",
    "                e = b + s3\n",
    "                if e>num_validation*2: e = num_validation*2\n",
    "                #print('-----', b, '-----', e, '-----')\n",
    "                #print('x_validation[b:e] shape: ', x_validation[b:e].shape)\n",
    "                #print('y_validation[b:e] shape: ', y_validation[b:e].shape)\n",
    "\n",
    "                predictions = y_validation[b:e]\n",
    "                #print('285: ', get_gpu_memory())\n",
    "                explanation = ig.explain(x_validation[b:e], baselines=None, target=predictions, attribute_to_layer_inputs=False)\n",
    "                #print('287: ', get_gpu_memory())\n",
    "                attr_validation[b:e] = explanation.attributions[0]\n",
    "            attr_validation_pred = tf.abs(attr_validation)\n",
    "            attr_validation_pred = tf.reduce_sum(attr_validation_pred, axis=2).numpy()/32\n",
    "            #print('attr_validation_pred shape: ', attr_validation_pred.shape) #(num_validation*2,1001)\n",
    "            attr_validation_true = xvalidation_attr[0:num_validation]\n",
    "            attr_validation_true = tf.reduce_sum(attr_validation_true, axis=2).numpy()/32\n",
    "            attr_validation_true = tf.concat([attr_validation_true, attr_validation_true], 0)\n",
    "            #print('attr_validation_true shape: ', attr_validation_true.shape) #(num_validation*2,1001)\n",
    "            mse = tf.keras.losses.MeanSquaredError()\n",
    "            attr_mse = mse(attr_validation_true, attr_validation_pred).numpy()\n",
    "            attr_mse_validation.append(attr_mse)\n",
    "            print('attr_mse validation: ', attr_mse)\n",
    "            end_att = time.time()\n",
    "            print('validation attribution time: ', end_att-start_att)\n",
    "            end = time.time()\n",
    "            print('time: ', end-start)\n",
    "        plotAttributionAcc(attr_mse_train)\n",
    "        print('----- train acc -----')\n",
    "        print('binary_acc_train: ', binary_acc_train)\n",
    "        print('attr_mse_train: ', attr_mse_train)\n",
    "        print('----- validation acc -----')\n",
    "        print('binary_acc_validation: ', binary_acc_validation)\n",
    "        print('attr_mse_validation: ', attr_mse_validation)\n",
    "            #print(\"Model training completed...\")\n",
    "            #save history\n",
    "            #print(\"Saving history...\")\n",
    "        saveDictionary(history.history, \"D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000\" + \"/\" + \"model_history\")\n",
    "            #print(\"History saving completed...\")\n",
    "\n",
    "            #save model\n",
    "            #print(\"Saving model...\")\n",
    "        new_model.save(\"D:/Code/Project-AI-JAVA-ANNOTATION-2021/Side-Project/0000\" + \"/\" + \"test_model1.h5\")\n",
    "            #print(\"Model saving completed...\")\n",
    "\n",
    "x=TestTranslate()\n",
    "x.test_translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "# Data\n",
    "x1 = loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Max-len-1000/x_train[0]_0.npy')\n",
    "x2 = loadTestTrainData('D:/00/train.npy')\n",
    "x1 = np.asarray(x1)\n",
    "x2 = np.asarray(x2).astype('float32')\n",
    "print('x1 shape: ', x1.shape)\n",
    "print('x2 shape: ', x2.shape)\n",
    "y0 = list(loadTestTrainData('C:/Users/YOLOHsu/Desktop/10366046/Max-len-1000/y_train[0]_0.npy'))\n",
    "y0 = np.asarray(y0)\n",
    "print('y0 shape: ', y0.shape)\n",
    "# model\n",
    "new_model = newmodel(model)\n",
    "type_weight = 1\n",
    "learning_rate_value = 0.0001\n",
    "batch_size_num = 32\n",
    "epochs_value = 10\n",
    "losses = {\"classifier_model\": \"binary_crossentropy\"}\n",
    "lossWeights = {\"classifier_model\": type_weight}\n",
    "metrics = {\"classifier_model\": \"binary_accuracy\"}\n",
    "# evaluate\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "new_model.compile(optimizer=Adam(learning_rate=learning_rate_value), loss=losses, loss_weights=lossWeights, metrics=metrics)\n",
    "result1 = model.evaluate(x1, y0)\n",
    "result2 = new_model.evaluate(x2, y0)\n",
    "print('result1: ', result1)\n",
    "print('result2: ', result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_gpu_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "achZsSjjc6hw",
    "U4NG1PGqXQkm"
   ],
   "name": "attribution_train_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
